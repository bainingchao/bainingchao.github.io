<!DOCTYPE html>












  




<html class="theme-next gemini use-motion" lang="zh-CN">
<head>
  <!-- hexo-inject:begin --><!-- hexo-inject:end --><meta charset="UTF-8"/>
<meta name="google-site-verification" content="o9IkI77-fxkhBZW-n0ww9JALMCqdDbeTgdcXO_Bw4Zc" />
<meta name="baidu-site-verification" content="3frqY9KiVO" />
<meta http-equiv="X-UA-Compatible" content="IE=edge" />
<meta name="viewport" content="width=device-width, initial-scale=1, maximum-scale=2"/>
<meta name="theme-color" content="#222">



  
  
  <link rel="stylesheet" href="/lib/needsharebutton/needsharebutton.css">










<meta http-equiv="Cache-Control" content="no-transform" />
<meta http-equiv="Cache-Control" content="no-siteapp" />



















  
  
  
  

  
    
    
  

  
    
      
    

    
  

  

  
    
      
    

    
  

  
    
      
    

    
  

  
    
    
    <link href="//fonts.googleapis.com/css?family=Monda:300,300italic,400,400italic,700,700italic|Roboto Slab:300,300italic,400,400italic,700,700italic|Lobster Two:300,300italic,400,400italic,700,700italic|PT Mono:300,300italic,400,400italic,700,700italic&subset=latin,latin-ext" rel="stylesheet" type="text/css">
  






<link href="/lib/font-awesome/css/font-awesome.min.css?v=4.6.2" rel="stylesheet" type="text/css" />

<link href="/css/main.css?v=6.4.1" rel="stylesheet" type="text/css" />


  <link rel="apple-touch-icon" sizes="180x180" href="/images/logo.png?v=6.4.1">


  <link rel="icon" type="image/png" sizes="32x32" href="/images/logo.png?v=6.4.1">


  <link rel="icon" type="image/png" sizes="16x16" href="/images/logo.png?v=6.4.1">


  <link rel="mask-icon" href="/images/logo.svg?v=6.4.1" color="#222">









<script type="text/javascript" id="hexo.configurations">
  var NexT = window.NexT || {};
  var CONFIG = {
    root: '/',
    scheme: 'Gemini',
    version: '6.4.1',
    sidebar: {"position":"left","display":"post","offset":12,"b2t":false,"scrollpercent":false,"onmobile":false},
    fancybox: false,
    fastclick: false,
    lazyload: false,
    tabs: true,
    motion: {"enable":true,"async":false,"transition":{"post_block":"fadeIn","post_header":"slideDownIn","post_body":"slideDownIn","coll_header":"slideLeftIn","sidebar":"slideUpIn"}},
    algolia: {
      applicationID: '',
      apiKey: '',
      indexName: '',
      hits: {"per_page":10},
      labels: {"input_placeholder":"Search for Posts","hits_empty":"We didn't find any results for the search: ${query}","hits_stats":"${hits} results found in ${time} ms"}
    }
  };
</script>


  




  <meta name="description" content="摘要：朴素贝叶斯模型是机器学习常用的模型算法之一，其在文本分类方面简单易行，且取得不错的分类效果。所以很受欢迎，对于朴素贝叶斯的学习，本文首先介绍理论知识即朴素贝叶斯相关概念和公式推导，为了加深理解，采用一个维基百科上面性别分类例子进行形式化描述。然后通过编程实现朴素贝叶斯分类算法，并在屏蔽社区言论、垃圾邮件、个人广告中获取区域倾向等几个方面进行应用，包括创建数据集、数据预处理、词集模型和词袋模">
<meta name="keywords" content="Python,文本分类,Naive Bayes,ML,实战案例">
<meta property="og:type" content="article">
<meta property="og:title" content="一步步教你轻松学朴素贝叶斯模型算法实现篇2">
<meta property="og:url" content="https://bainingchao.github.io/2018/09/19/一步步教你轻松学朴素贝叶斯模型算法实现篇2/index.html">
<meta property="og:site_name" content="白宁超的官网">
<meta property="og:description" content="摘要：朴素贝叶斯模型是机器学习常用的模型算法之一，其在文本分类方面简单易行，且取得不错的分类效果。所以很受欢迎，对于朴素贝叶斯的学习，本文首先介绍理论知识即朴素贝叶斯相关概念和公式推导，为了加深理解，采用一个维基百科上面性别分类例子进行形式化描述。然后通过编程实现朴素贝叶斯分类算法，并在屏蔽社区言论、垃圾邮件、个人广告中获取区域倾向等几个方面进行应用，包括创建数据集、数据预处理、词集模型和词袋模">
<meta property="og:locale" content="zh-CN">
<meta property="og:image" content="https://i.imgur.com/guO78D4.png">
<meta property="og:image" content="http://latex.codecogs.com/gif.latex?\dpi{90}&space;P(C|F_1,F_2...F_n)&space;=&space;\frac{&space;P(F_1,F_2...F_n|C)P(C)}&space;{&space;P(F_1,F_2,...,F_n)}">
<meta property="og:image" content="http://latex.codecogs.com/gif.latex?\dpi{100}&space;\\&space;P(F_1|C)*P(F_2|C)....P(F_n|C)P(C)&space;\\&space;\Rightarrow&space;\\&space;log(P(F_1|C))+log(P(F_2|C))+....+log(P(F_n|C))+log(P(C))">
<meta property="og:image" content="https://i.imgur.com/ur4LMd3.png">
<meta property="og:image" content="https://i.imgur.com/Fl1W5mB.png">
<meta property="og:updated_time" content="2018-10-19T07:38:47.423Z">
<meta name="twitter:card" content="summary">
<meta name="twitter:title" content="一步步教你轻松学朴素贝叶斯模型算法实现篇2">
<meta name="twitter:description" content="摘要：朴素贝叶斯模型是机器学习常用的模型算法之一，其在文本分类方面简单易行，且取得不错的分类效果。所以很受欢迎，对于朴素贝叶斯的学习，本文首先介绍理论知识即朴素贝叶斯相关概念和公式推导，为了加深理解，采用一个维基百科上面性别分类例子进行形式化描述。然后通过编程实现朴素贝叶斯分类算法，并在屏蔽社区言论、垃圾邮件、个人广告中获取区域倾向等几个方面进行应用，包括创建数据集、数据预处理、词集模型和词袋模">
<meta name="twitter:image" content="https://i.imgur.com/guO78D4.png">



  <link rel="alternate" href="/atom.xml" title="白宁超的官网" type="application/atom+xml" />




  <link rel="canonical" href="https://bainingchao.github.io/2018/09/19/一步步教你轻松学朴素贝叶斯模型算法实现篇2/"/>



<script type="text/javascript" id="page.configurations">
  CONFIG.page = {
    sidebar: "",
  };
</script>

  <title>一步步教你轻松学朴素贝叶斯模型算法实现篇2 | 白宁超的官网</title>
  









  <noscript>
  <style type="text/css">
    .use-motion .motion-element,
    .use-motion .brand,
    .use-motion .menu-item,
    .sidebar-inner,
    .use-motion .post-block,
    .use-motion .pagination,
    .use-motion .comments,
    .use-motion .post-header,
    .use-motion .post-body,
    .use-motion .collection-title { opacity: initial; }

    .use-motion .logo,
    .use-motion .site-title,
    .use-motion .site-subtitle {
      opacity: initial;
      top: initial;
    }

    .use-motion {
      .logo-line-before i { left: initial; }
      .logo-line-after i { right: initial; }
    }
  </style>
</noscript><!-- hexo-inject:begin --><!-- hexo-inject:end -->

</head>

<body itemscope itemtype="http://schema.org/WebPage" lang="zh-CN">

  
  
    
  

  <!-- hexo-inject:begin --><!-- hexo-inject:end --><div class="container sidebar-position-left page-post-detail">
    <div class="headband"></div>

	<!-- <a href="https://github.com/bainingchao"><img style="position: absolute; top: 0; right: 0; border: 0;" src="https://s3.amazonaws.com/github/ribbons/forkme_right_red_aa0000.png" alt="Fork me on GitHub"></a> !-->
	
    <header id="header" class="header" itemscope itemtype="http://schema.org/WPHeader">
      <div class="header-inner"><div class="site-brand-wrapper">
  <div class="site-meta ">
    

    <div class="custom-logo-site-title">
      <a href="/" class="brand" rel="start">
        <span class="logo-line-before"><i></i></span>
        <span class="site-title">白宁超的官网</span>
        <span class="logo-line-after"><i></i></span>
      </a>
    </div>
    
      
        <h1 class="site-subtitle" itemprop="description">专注人工智能领域研究</h1>
      
    
  </div>

  <div class="site-nav-toggle">
    <button aria-label="切换导航栏">
      <span class="btn-bar"></span>
      <span class="btn-bar"></span>
      <span class="btn-bar"></span>
    </button>
  </div>
</div>



<nav class="site-nav">
  
    <ul id="menu" class="menu">
      
        
        
        
          
          <li class="menu-item menu-item-首页">
    <a href="/" rel="section">
      <i class="menu-item-icon fa fa-fw fa-home"></i> <br />首页</a>
  </li>
        
        
        
          
          <li class="menu-item menu-item-标签">
    <a href="/tags/" rel="section">
      <i class="menu-item-icon fa fa-fw fa-tags"></i> <br />标签</a>
  </li>
        
        
        
          
          <li class="menu-item menu-item-分类">
    <a href="/categories/" rel="section">
      <i class="menu-item-icon fa fa-fw fa-th"></i> <br />分类</a>
  </li>
        
        
        
          
          <li class="menu-item menu-item-归档">
    <a href="/archives/" rel="section">
      <i class="menu-item-icon fa fa-fw fa-archive"></i> <br />归档</a>
  </li>
        
        
        
          
          <li class="menu-item menu-item-视频">
    <a href="/videos/" rel="section">
      <i class="menu-item-icon fa fa-fw fa-sitemap"></i> <br />视频</a>
  </li>
        
        
        
          
          <li class="menu-item menu-item-书籍">
    <a href="/books/" rel="section">
      <i class="menu-item-icon fa fa-fw fa-th"></i> <br />书籍</a>
  </li>
        
        
        
          
          <li class="menu-item menu-item-链接">
    <a href="/links/" rel="section">
      <i class="menu-item-icon fa fa-fw fa-question-circle"></i> <br />链接</a>
  </li>
        
        
        
          
          <li class="menu-item menu-item-关于">
    <a href="/about/" rel="section">
      <i class="menu-item-icon fa fa-fw fa-user"></i> <br />关于</a>
  </li>

      
      
        <li class="menu-item menu-item-search">
          
            <a href="javascript:;" class="popup-trigger">
          
            
              <i class="menu-item-icon fa fa-search fa-fw"></i> <br />搜索</a>
        </li>
      
    </ul>
  

  

  
    <div class="site-search">
      
  <div class="popup search-popup local-search-popup">
  <div class="local-search-header clearfix">
    <span class="search-icon">
      <i class="fa fa-search"></i>
    </span>
    <span class="popup-btn-close">
      <i class="fa fa-times-circle"></i>
    </span>
    <div class="local-search-input-wrapper">
      <input autocomplete="off"
             placeholder="搜索..." spellcheck="false"
             type="text" id="local-search-input">
    </div>
  </div>
  <div id="local-search-result"></div>
</div>



    </div>
  
</nav>



  



</div>
    </header>

    


    <main id="main" class="main">
      <div class="main-inner">
        <div class="content-wrap">
          
            

          
          <div id="content" class="content">
            

  <div id="posts" class="posts-expand">
    

  

  
  
  

  

  <article class="post post-type-normal" itemscope itemtype="http://schema.org/Article">
  
  
  
  <div class="post-block">
    <link itemprop="mainEntityOfPage" href="https://bainingchao.github.io/2018/09/19/一步步教你轻松学朴素贝叶斯模型算法实现篇2/">

    <span hidden itemprop="author" itemscope itemtype="http://schema.org/Person">
      <meta itemprop="name" content="白宁超">
      <meta itemprop="description" content="本站主要研究深度学习、机器学习、自然语言处理等前沿技术。ML&NLP交流群：436303759 <span><a target="_blank" href="http://shang.qq.com/wpa/qunwpa?idkey=ef3bbb679b06ac59b136c57ba9e7935ff9d3b10faeabde6e4efcafe523bbbf4d"><img border="0" src="http://pub.idqqimg.com/wpa/images/group.png" alt="自然语言处理和机器学习技术QQ交流：436303759 " title="自然语言处理和机器学习技术交流"></a></span>">
      <meta itemprop="image" content="/../images/header.png">
    </span>

    <span hidden itemprop="publisher" itemscope itemtype="http://schema.org/Organization">
      <meta itemprop="name" content="白宁超的官网">
    </span>

    
      <header class="post-header">

        
        
          <h2 class="post-title" itemprop="name headline">一步步教你轻松学朴素贝叶斯模型算法实现篇2
              
            
          </h2>
        

        <div class="post-meta">
          <span class="post-time">

            
            
            

            
              <span class="post-meta-item-icon">
                <i class="fa fa-calendar-o"></i>
              </span>
              
                <span class="post-meta-item-text">发表于</span>
              

              
                
              

              <time title="创建时间：2018-09-19 10:50:47" itemprop="dateCreated datePublished" datetime="2018-09-19T10:50:47+08:00">2018-09-19</time>
            

            
              

              
                
                <span class="post-meta-divider">|</span>
                

                <span class="post-meta-item-icon">
                  <i class="fa fa-calendar-check-o"></i>
                </span>
                
                  <span class="post-meta-item-text">更新于</span>
                
                <time title="修改时间：2018-10-19 15:38:47" itemprop="dateModified" datetime="2018-10-19T15:38:47+08:00">2018-10-19</time>
              
            
          </span>

          
            <span class="post-category" >
            
              <span class="post-meta-divider">|</span>
            
              <span class="post-meta-item-icon">
                <i class="fa fa-folder-o"></i>
              </span>
              
                <span class="post-meta-item-text">分类于</span>
              
              
                <span itemprop="about" itemscope itemtype="http://schema.org/Thing"><a href="/categories/机器学习/" itemprop="url" rel="index"><span itemprop="name">机器学习</span></a></span>

                
                
                  ，
                
              
                <span itemprop="about" itemscope itemtype="http://schema.org/Thing"><a href="/categories/机器学习/朴素贝叶斯/" itemprop="url" rel="index"><span itemprop="name">朴素贝叶斯</span></a></span>

                
                
              
            </span>
          

          
            
          

          
          

          
            <span class="post-meta-divider">|</span>
            <span class="post-meta-item-icon"
            >
            <i class="fa fa-eye"></i>
             阅读次数： 
            <span class="busuanzi-value" id="busuanzi_value_page_pv" ></span>
            </span>
          
		  

          

          

        </div>
      </header>
    

    
    
    
    <div class="post-body" itemprop="articleBody">

      
      

      
        <blockquote>
<p>摘要：朴素贝叶斯模型是机器学习常用的模型算法之一，其在文本分类方面简单易行，且取得不错的分类效果。所以很受欢迎，对于朴素贝叶斯的学习，本文首先介绍理论知识即朴素贝叶斯相关概念和公式推导，为了加深理解，采用一个维基百科上面性别分类例子进行形式化描述。然后通过编程实现朴素贝叶斯分类算法，并在屏蔽社区言论、垃圾邮件、个人广告中获取区域倾向等几个方面进行应用，包括创建数据集、数据预处理、词集模型和词袋模型、朴素贝叶斯模型训练和优化等。然后结合复旦大学新闻语料进行朴素贝叶斯的应用。最后，大家熟悉其原理和实现之后，采用机器学习sklearn包进行实现和优化。由于篇幅较长，采用理论理解、案例实现、sklearn优化三个部分进行学习。（本文原创，转载必须注明出处.）</p>
</blockquote>
<a id="more"></a>
<h2 id="案例场景1-屏蔽社区留言板的侮辱性言论"><a href="#案例场景1-屏蔽社区留言板的侮辱性言论" class="headerlink" title="案例场景1: 屏蔽社区留言板的侮辱性言论"></a>案例场景1: 屏蔽社区留言板的侮辱性言论</h2><h3 id="项目概述"><a href="#项目概述" class="headerlink" title="项目概述"></a>项目概述</h3><p>构建一个快速过滤器来屏蔽在线社区留言板上的侮辱性言论。如果某条留言使用了负面或者侮辱性的语言，那么就将该留言标识为内容不当。对此问题建立两个类别: 侮辱类和非侮辱类，使用 1 和 0 分别表示。</p>
<p>本案例开发流程如下：</p>
<ol>
<li>收集数据: 可以是文本数据、数据库数据、网络爬取的数据、自定义数据等等</li>
<li>数据预处理: 对采集数据进行格式化处理，文本数据的格式一致化，网络数据的分析抽取等，包括中文分词、停用词处理、词袋模型、构建词向量等。</li>
<li>分析数据: 检查词条确保解析的正确性，根据特征进行模型选择、特征抽取等。</li>
<li>训练算法: 从词向量计算概率</li>
<li>测试算法: 根据现实情况修改分类器</li>
<li>使用算法: 对社区留言板言论进行分类</li>
</ol>
<h3 id="收集数据"><a href="#收集数据" class="headerlink" title="收集数据"></a>收集数据</h3><p>本案例我们采用自定义的数据集，我们选择6条社区评论，然后进行数据处理后以list形式存储在文档列表postingList中。其中每个词代表一个特征。将每条评论进行分类（即1代表侮辱性文字,0代表非侮辱文字）存在在类别列表classVec中。最后返回数据集和类标签。代码实现如下：<br><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br></pre></td><td class="code"><pre><span class="line"><span class="string">'''创建数据集：单词列表postingList, 所属类别classVec'''</span></span><br><span class="line"><span class="function"><span class="keyword">def</span> <span class="title">loadDataSet</span><span class="params">()</span>:</span></span><br><span class="line">    postingList = [[<span class="string">'my'</span>, <span class="string">'dog'</span>, <span class="string">'has'</span>, <span class="string">'flea'</span>, <span class="string">'problems'</span>, <span class="string">'help'</span>, <span class="string">'please'</span>],</span><br><span class="line">                   [<span class="string">'maybe'</span>, <span class="string">'not'</span>, <span class="string">'take'</span>, <span class="string">'him'</span>, <span class="string">'to'</span>, <span class="string">'dog'</span>, <span class="string">'park'</span>, <span class="string">'stupid'</span>],</span><br><span class="line">                   [<span class="string">'my'</span>, <span class="string">'dalmation'</span>, <span class="string">'is'</span>, <span class="string">'so'</span>, <span class="string">'cute'</span>, <span class="string">'I'</span>, <span class="string">'love'</span>, <span class="string">'him'</span>],</span><br><span class="line">                   [<span class="string">'stop'</span>, <span class="string">'posting'</span>, <span class="string">'stupid'</span>, <span class="string">'worthless'</span>, <span class="string">'garbage'</span>],</span><br><span class="line">                   [<span class="string">'mr'</span>, <span class="string">'licks'</span>, <span class="string">'ate'</span>, <span class="string">'my'</span>, <span class="string">'steak'</span>, <span class="string">'how'</span>, <span class="string">'to'</span>, <span class="string">'stop'</span>, <span class="string">'him'</span>],</span><br><span class="line">                   [<span class="string">'quit'</span>, <span class="string">'buying'</span>, <span class="string">'worthless'</span>, <span class="string">'dog'</span>, <span class="string">'food'</span>, <span class="string">'stupid'</span>]]</span><br><span class="line">    classVec = [<span class="number">0</span>, <span class="number">1</span>, <span class="number">0</span>, <span class="number">1</span>, <span class="number">0</span>, <span class="number">1</span>]  <span class="comment"># 1代表侮辱性文字,0代表非侮辱文字</span></span><br><span class="line">    <span class="keyword">return</span> postingList, classVec</span><br></pre></td></tr></table></figure></p>
<p>代码分析：postingList列表存储6条评论信息，classVec列表存储每条信息类别（1代表侮辱性文字,0代表非侮辱文字）。最后返回文档列表和类别列表。</p>
<h3 id="数据预处理"><a href="#数据预处理" class="headerlink" title="数据预处理"></a>数据预处理</h3><p>数据预处理包括对样本进行分词、词性筛选、停用词处理等，最后形成规范化干净的数据样本。由于本案例收集数据时默认进行了数据预处理，所以本节不在介绍（复旦新闻语料文本分类案例会详细介绍）。目前，我们采集的数据还是文本类型，计算机还不能直接处理，需要将文本数据转化成词向量进行处理。这里面需要获取特征的词汇集合（如果暂时不理解，先看看代码实现，下面会进行形式化描述）。其实现过程如下：<br><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br></pre></td><td class="code"><pre><span class="line"><span class="string">'''获取所有单词的集合:返回不含重复元素的单词列表'''</span></span><br><span class="line"><span class="function"><span class="keyword">def</span> <span class="title">createVocabList</span><span class="params">(dataSet)</span>:</span></span><br><span class="line">    vocabSet = set([])</span><br><span class="line">    <span class="keyword">for</span> document <span class="keyword">in</span> dataSet:</span><br><span class="line">        vocabSet = vocabSet | set(document)  <span class="comment"># 操作符 | 用于求两个集合的并集</span></span><br><span class="line">    <span class="comment"># print(vocabSet)</span></span><br><span class="line">    <span class="keyword">return</span> list(vocabSet)</span><br></pre></td></tr></table></figure></p>
<p>代码分析：方法参数dataSet即加载数据集返回的文档列表。vocabSet是定义的不重复的数据集合。然后for循环对文档列表每条数据进行遍历处理，将不重复的词汇添加到vocabSet中，最终形成整个文档的词汇集，然后以list形式返回。</p>
<p>上面的方法已经获取了整个文档词汇集合，接着构建数据矩阵，代码实现如下：<br><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br></pre></td><td class="code"><pre><span class="line"><span class="string">'''词集模型构建数据矩阵'''</span></span><br><span class="line"><span class="function"><span class="keyword">def</span> <span class="title">setOfWords2Vec</span><span class="params">(vocabList, inputSet)</span>:</span></span><br><span class="line">    <span class="comment"># 创建一个和词汇表等长的向量，并将其元素都设置为0</span></span><br><span class="line">    returnVec = [<span class="number">0</span>] * len(vocabList)</span><br><span class="line">    <span class="comment"># 遍历文档中的所有单词，如果出现了词汇表中的单词，则将输出的文档向量中的对应值设为1</span></span><br><span class="line">    <span class="keyword">for</span> word <span class="keyword">in</span> inputSet:</span><br><span class="line">        <span class="keyword">if</span> word <span class="keyword">in</span> vocabList:</span><br><span class="line">            returnVec[vocabList.index(word)] = <span class="number">1</span></span><br><span class="line">        <span class="keyword">else</span>:</span><br><span class="line">            print(<span class="string">"单词: %s 不在词汇表之中!"</span> % word)</span><br><span class="line">    <span class="comment"># print(returnVec)</span></span><br><span class="line">    <span class="keyword">return</span> returnVec</span><br></pre></td></tr></table></figure></p>
<p>代码分析：本方法提供两个参数分别是整个训练文档词汇集（即全部训练文档6条评论不重复的单词集合），输入的数据列表。以整个词汇集等长的0向量。我们遍历输入数据列表，如果词特征在词汇集则标记1，不在词汇集保持为0.最后返回词向量矩阵。</p>
<p>与词集模型对应的，有个词袋模型。两者都是构建词向量，只是方式不一样，词袋模型也是推荐使用的词向量化方法，其实现如下：<br><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br></pre></td><td class="code"><pre><span class="line"><span class="string">'''文档词袋模型构建数据矩阵'''</span></span><br><span class="line"><span class="function"><span class="keyword">def</span> <span class="title">bagOfWords2VecMN</span><span class="params">(vocabList, inputSet)</span>:</span></span><br><span class="line">    returnVec = [<span class="number">0</span>] * len(vocabList)</span><br><span class="line">    <span class="keyword">for</span> word <span class="keyword">in</span> inputSet:</span><br><span class="line">        <span class="keyword">if</span> word <span class="keyword">in</span> vocabList:</span><br><span class="line">            returnVec[vocabList.index(word)] += <span class="number">1</span></span><br><span class="line">    <span class="comment"># print(returnVec)</span></span><br><span class="line">    <span class="keyword">return</span> returnVec</span><br></pre></td></tr></table></figure></p>
<h3 id="分析数据"><a href="#分析数据" class="headerlink" title="分析数据"></a>分析数据</h3><p>运行词集模型setOfWords2Vec(vocabList, dataSet[0])运行结果如下：</p>
<pre><code>[&#39;dog&#39;, &#39;to&#39;, &#39;take&#39;, &#39;park&#39;, &#39;licks&#39;, &#39;has&#39;, &#39;help&#39;, &#39;stupid&#39;, &#39;him&#39;, &#39;so&#39;, &#39;not&#39;, &#39;love&#39;, &#39;buying&#39;, &#39;problems&#39;, &#39;cute&#39;, &#39;stop&#39;, &#39;steak&#39;, &#39;how&#39;, &#39;flea&#39;, &#39;maybe&#39;, &#39;food&#39;, &#39;I&#39;, &#39;please&#39;, &#39;dalmation&#39;, &#39;mr&#39;, &#39;posting&#39;, &#39;ate&#39;, &#39;garbage&#39;, &#39;worthless&#39;, &#39;my&#39;, &#39;is&#39;, &#39;quit&#39;]
[1, 0, 0, 0, 0, 1, 1, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 1, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 1, 0, 0]
</code></pre><p>结果分析：我们将dataSet[0]即第一条信息[‘my’, ‘dog’, ‘has’, ‘flea’, ‘problems’, ‘help’, ‘please’]构建词集模型，词特征集为[‘dog’, ‘to’, ‘take’, ‘park’, ‘licks’, ‘has’, ‘help’, ‘stupid’, ‘him’, ‘so’, ‘not’, ‘love’, ‘buying’, ‘problems’, ‘cute’, ‘stop’, ‘steak’, ‘how’, ‘flea’, ‘maybe’, ‘food’, ‘I’, ‘please’, ‘dalmation’, ‘mr’, ‘posting’, ‘ate’, ‘garbage’, ‘worthless’, ‘my’, ‘is’, ‘quit’]。结果显示[1, 0, 0, 0, 0, 1, 1, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 1, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 1, 0, 0]。即词特征集dog在dataSet[0]中，标记为1，to不在则保留原始的0.以此类推。我们也可以查看dataSet[1]等数据结果。</p>
<p>数据样本分析仅仅如上所述？当然不是，本例子中数据量比较小，容易分析。当数据量比较大，特征数以万计之时，人工分析就显得捉襟见肘了。我们可以采用图形化分析方法，根据具体业务需求，可以选择基于python自带的matplotlib可视化分析、或者其他图形可视化工具进行平面或多维数据分析，然后便于特征的选择。</p>
<p>如果是中文分词，我们还可以对词性进行分析，然后选择相应的词性特征，比如名词、动词、地名、人名、机构名等等，对虚词、助词等进行过滤，一方面达到数据降维另一方面防止模型训练拟合化等问题。</p>
<h3 id="训练模型"><a href="#训练模型" class="headerlink" title="训练模型"></a>训练模型</h3><p>现在已经知道了一个词是否出现在一篇文档中，也知道该文档所属的类别。接下来我们重写贝叶斯准则，将之前的 x, y 替换为 w. 粗体的 w 表示这是一个向量，即它由多个值组成。在这个例子中，数值个数与词汇表中的词个数相同。</p>
<script type="math/tex; mode=display">p(c_i|w)= \frac{p(w \mid c_i)p(c)} {p(w)}</script><p>我们使用上述公式，对每个类计算该值，然后比较这两个概率值的大小。根据上述公式可知，我们右边的式子等同于左边的式子，由于对于每个\(c_i\)，\(P(w)\)是固定的。并且我们只需要比较左边式子值的大小来决策分类，那么我们就可以简化为通过比较右边分子值得大小来做决策分类。<br>首先可以通过类别 i (侮辱性留言或者非侮辱性留言)中的文档数除以总的文档数来计算概率\(p(c_i)\)。接下来计算\(p(w|c_i)\)，这里就要用到朴素贝叶斯假设。如果将 w 展开为一个个独立特征，那么就可以将上述概率写作\(p(w_0,w_1,w_2…w_n|c_i)\)。这里假设所有词都互相独立，该假设也称作条件独立性假设（例如 A 和 B 两个人抛骰子，概率是互不影响的，也就是相互独立的，A 抛 2点的同时 B 抛 3 点的概率就是 1/6 * 1/6），它意味着可以使用\( p(w_0|c_i)p(w_1|c_i)p(w_2|;c_i)…p(w_n|c_i)\)来计算上述概率，这样就极大地简化了计算的过程。具体代码实现如下：<br><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br></pre></td><td class="code"><pre><span class="line"><span class="string">'''朴素贝叶斯分类器训练函数'''</span></span><br><span class="line"><span class="function"><span class="keyword">def</span> <span class="title">_trainNB0</span><span class="params">(trainMatrix, trainCategory)</span>:</span></span><br><span class="line">    numTrainDocs = len(trainMatrix) <span class="comment"># 文件数</span></span><br><span class="line">    numWords = len(trainMatrix[<span class="number">0</span>]) <span class="comment"># 单词数</span></span><br><span class="line">    <span class="comment"># 侮辱性文件的出现概率，即trainCategory中所有的1的个数，</span></span><br><span class="line">    <span class="comment"># 代表的就是多少个侮辱性文件，与文件的总数相除就得到了侮辱性文件的出现概率</span></span><br><span class="line">    pAbusive = sum(trainCategory) / float(numTrainDocs)</span><br><span class="line"></span><br><span class="line">    <span class="comment"># 构造单词出现次数列表</span></span><br><span class="line">    p0Num = zeros(numWords) <span class="comment"># [0,0,0,.....]</span></span><br><span class="line">    p1Num = zeros(numWords) <span class="comment"># [0,0,0,.....]</span></span><br><span class="line">    p0Denom = <span class="number">0.0</span>;p1Denom = <span class="number">0.0</span> <span class="comment"># 整个数据集单词出现总数</span></span><br><span class="line">    <span class="keyword">for</span> i <span class="keyword">in</span> range(numTrainDocs):</span><br><span class="line">        <span class="comment"># 遍历所有的文件，如果是侮辱性文件，就计算此侮辱性文件中出现的侮辱性单词的个数</span></span><br><span class="line">        <span class="keyword">if</span> trainCategory[i] == <span class="number">1</span>:</span><br><span class="line">            p1Num += trainMatrix[i] <span class="comment">#[0,1,1,....]-&gt;[0,1,1,...]</span></span><br><span class="line">            p1Denom += sum(trainMatrix[i])</span><br><span class="line">        <span class="keyword">else</span>:</span><br><span class="line">            <span class="comment"># 如果不是侮辱性文件，则计算非侮辱性文件中出现的侮辱性单词的个数</span></span><br><span class="line">            p0Num += trainMatrix[i]</span><br><span class="line">            p0Denom += sum(trainMatrix[i])</span><br><span class="line">    <span class="comment"># 类别1，即侮辱性文档的[P(F1|C1),P(F2|C1),P(F3|C1),P(F4|C1),P(F5|C1)....]列表</span></span><br><span class="line">    <span class="comment"># 即 在1类别下，每个单词出现次数的占比</span></span><br><span class="line">    p1Vect = p1Num / p1Denom<span class="comment"># [1,2,3,5]/90-&gt;[1/90,...]</span></span><br><span class="line">    <span class="comment"># 类别0，即正常文档的[P(F1|C0),P(F2|C0),P(F3|C0),P(F4|C0),P(F5|C0)....]列表</span></span><br><span class="line">    <span class="comment"># 即 在0类别下，每个单词出现次数的占比</span></span><br><span class="line">    p0Vect = p0Num / p0Denom</span><br><span class="line">    <span class="keyword">return</span> p0Vect, p1Vect, pAbusive</span><br></pre></td></tr></table></figure></p>
<p>代码分析：本方法参数分别是文档特征向量矩阵和文档类别向量矩阵。首先计算侮辱性文档占总文档的概率，然后计算正常文档下特征词的概率向量和侮辱性特征词的向量，为了更好理解上面的代码我们看下运行p0V,p1V,pAb=_trainNB0(trainMatrix,Classlabels)结果：</p>
<pre><code>词汇表集
[&#39;I&#39;, &#39;cute&#39;, &#39;help&#39;, &#39;dalmation&#39;, &#39;please&#39;, &#39;has&#39;, &#39;my&#39;, &#39;him&#39;, &#39;worthless&#39;, &#39;problems&#39;, &#39;so&#39;, &#39;mr&#39;, &#39;flea&#39;, &#39;love&#39;, &#39;take&#39;, &#39;stupid&#39;, &#39;dog&#39;, &#39;park&#39;, &#39;how&#39;, &#39;quit&#39;, &#39;buying&#39;, &#39;posting&#39;, &#39;steak&#39;, &#39;maybe&#39;, &#39;to&#39;, &#39;is&#39;, &#39;ate&#39;, &#39;not&#39;, &#39;garbage&#39;, &#39;food&#39;, &#39;stop&#39;, &#39;licks&#39;]
各条评论特征向量，其中1,3,5条为类别0；2,4,6条为类别1
[0, 0, 1, 0, 1, 1, 1, 0, 0, 1, 0, 0, 1, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0]
[0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 1, 1, 1, 1, 0, 0, 0, 0, 0, 1, 1, 0, 0, 1, 0, 0, 0, 0]
[1, 1, 0, 1, 0, 0, 1, 1, 0, 0, 1, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0]
[0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 1, 0, 1, 0]
[0, 0, 0, 0, 0, 0, 1, 1, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 1, 0, 1, 0, 1, 0, 0, 0, 1, 1]
[0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 1, 1, 0, 0, 1, 1, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0]
类别0下特征词条件概率
[0.04166667 0.04166667 0.04166667 0.04166667 0.04166667 0.04166667
 0.125      0.08333333 0.         0.04166667 0.04166667 0.04166667
 0.04166667 0.04166667 0.         0.         0.04166667 0.
 0.04166667 0.         0.         0.         0.04166667 0.
 0.04166667 0.04166667 0.04166667 0.         0.         0.
 0.04166667 0.04166667] 
 类别1下特征词条件概率
[0.         0.         0.         0.         0.         0.
 0.         0.05263158 0.10526316 0.         0.         0.
 0.         0.         0.05263158 0.15789474 0.10526316 0.05263158
 0.         0.05263158 0.05263158 0.05263158 0.         0.05263158
 0.05263158 0.         0.         0.05263158 0.05263158 0.05263158
 0.05263158 0.        ] 
 0.5
</code></pre><p>结果分析：结合结果我们去理解上面的训练模型代码。首先最后一个是0.5代表侮辱性文档占全部文档的50%即一半，实际上我们标记3个正常评论词条，3个非正常的，这个显然正确。其次，第一次词I在类别1中出现0次，在类别0中出现1次。对应的条件概率分别是0.04166667和0</p>
<h3 id="测试算法"><a href="#测试算法" class="headerlink" title="测试算法"></a>测试算法</h3><p>在利用贝叶斯分类器对文档进行分类时，要计算多个概率的乘积以获得文档属于某个类别的概率，即计算\(p(w_0|1)<em>p(w_1|1)</em>p(w_2|1)\)。如果其中一个概率值为 0，那么最后的乘积也为 0。为降低这种影响，可以将所有词的出现数初始化为 1，并将分母初始化为 2 （取1 或 2 的目的主要是为了保证分子和分母不为0，大家可以根据业务需求进行更改）。<br>另一个遇到的问题是下溢出，这是由于太多很小的数相乘造成的。当计算乘积 \( p(w_0|c_i)<em>p(w_1|c_i)</em>p(w_2|c_i)…p(w_n|c_i)\)时，由于大部分因子都非常小，所以程序会下溢出或者得到不正确的答案。（用 Python 尝试相乘许多很小的数，最后四舍五入后会得到 0）。一种解决办法是对乘积取自然对数。在代数中有 ln(a * b) = ln(a) + ln(b), 于是通过求对数可以避免下溢出或者浮点数舍入导致的错误。同时，采用自然对数进行处理不会有任何损失。</p>
<p>下图给出了函数 f(x) 与 ln(f(x)) 的曲线。可以看出，它们在相同区域内同时增加或者减少，并且在相同点上取到极值。它们的取值虽然不同，但不影响最终结果。</p>
<p><img src="https://i.imgur.com/guO78D4.png" alt=""></p>
<p>根据朴素贝叶斯公式，我们观察分子\(p(w_i|c_i)P(c_i)\)进行条件概率连乘时候，由于有条件概率极小或者为0，最后导致结果为0 ，显然不符合我们预期结果，因此对训练模型进行优化，其优化代码如下：<br><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br></pre></td><td class="code"><pre><span class="line"><span class="string">'''训练数据优化版本'''</span></span><br><span class="line"><span class="function"><span class="keyword">def</span> <span class="title">trainNB0</span><span class="params">(trainMatrix, trainCategory)</span>:</span></span><br><span class="line">    numTrainDocs = len(trainMatrix) <span class="comment"># 总文件数</span></span><br><span class="line">    numWords = len(trainMatrix[<span class="number">0</span>]) <span class="comment"># 总单词数</span></span><br><span class="line">    pAbusive = sum(trainCategory) / float(numTrainDocs) <span class="comment"># 侮辱性文件的出现概率</span></span><br><span class="line">    <span class="comment"># 构造单词出现次数列表,p0Num 正常的统计,p1Num 侮辱的统计</span></span><br><span class="line">    <span class="comment"># 避免单词列表中的任何一个单词为0，而导致最后的乘积为0，所以将每个单词的出现次数初始化为 1</span></span><br><span class="line">    p0Num = ones(numWords)<span class="comment">#[0,0......]-&gt;[1,1,1,1,1.....],ones初始化1的矩阵</span></span><br><span class="line">    p1Num = ones(numWords)</span><br><span class="line"></span><br><span class="line">    <span class="comment"># 整个数据集单词出现总数，2.0根据样本实际调查结果调整分母的值（2主要是避免分母为0，当然值可以调整）</span></span><br><span class="line">    <span class="comment"># p0Denom 正常的统计</span></span><br><span class="line">    <span class="comment"># p1Denom 侮辱的统计</span></span><br><span class="line">    p0Denom = <span class="number">2.0</span></span><br><span class="line">    p1Denom = <span class="number">2.0</span></span><br><span class="line">    <span class="keyword">for</span> i <span class="keyword">in</span> range(numTrainDocs):</span><br><span class="line">        <span class="keyword">if</span> trainCategory[i] == <span class="number">1</span>:</span><br><span class="line">            p1Num += trainMatrix[i]  <span class="comment"># 累加辱骂词的频次</span></span><br><span class="line">            p1Denom += sum(trainMatrix[i]) <span class="comment"># 对每篇文章的辱骂的频次 进行统计汇总</span></span><br><span class="line">        <span class="keyword">else</span>:</span><br><span class="line">            p0Num += trainMatrix[i]</span><br><span class="line">            p0Denom += sum(trainMatrix[i])</span><br><span class="line">    <span class="comment"># 类别1，即侮辱性文档的[log(P(F1|C1)),log(P(F2|C1)),log(P(F3|C1)),log(P(F4|C1)),log(P(F5|C1))....]列表,取对数避免下溢出或浮点舍入出错</span></span><br><span class="line">    p1Vect = log(p1Num / p1Denom)</span><br><span class="line">    <span class="comment"># 类别0，即正常文档的[log(P(F1|C0)),log(P(F2|C0)),log(P(F3|C0)),log(P(F4|C0)),log(P(F5|C0))....]列表</span></span><br><span class="line">    p0Vect = log(p0Num / p0Denom)</span><br><span class="line">    <span class="keyword">return</span> p0Vect, p1Vect, pAbusive</span><br></pre></td></tr></table></figure></p>
<p>我们再看生成条件概率结果如下：</p>
<pre><code>[-2.56494936 -2.15948425 -3.25809654 -2.56494936 -3.25809654 -3.25809654
 -2.56494936 -2.56494936 -3.25809654 -2.56494936 -3.25809654 -3.25809654
 -2.56494936 -2.56494936 -2.56494936 -3.25809654 -2.56494936 -2.56494936
 -2.56494936 -2.56494936 -1.87180218 -2.56494936 -3.25809654 -2.56494936
 -2.56494936 -2.56494936 -2.56494936 -3.25809654 -3.25809654 -2.56494936
 -3.25809654 -2.56494936] 
 [-3.04452244 -2.35137526 -2.35137526 -3.04452244 -2.35137526 -2.35137526
 -3.04452244 -3.04452244 -1.94591015 -2.35137526 -2.35137526 -2.35137526
 -3.04452244 -2.35137526 -3.04452244 -1.65822808 -1.94591015 -3.04452244
 -3.04452244 -3.04452244 -3.04452244 -3.04452244 -2.35137526 -3.04452244
 -3.04452244 -3.04452244 -3.04452244 -2.35137526 -2.35137526 -3.04452244
 -2.35137526 -3.04452244] 
 0.5
</code></pre><h3 id="使用算法对社区留言板言论进行分类"><a href="#使用算法对社区留言板言论进行分类" class="headerlink" title="使用算法对社区留言板言论进行分类"></a>使用算法对社区留言板言论进行分类</h3><blockquote>
<p>构建朴素贝叶斯分类函数</p>
</blockquote>
<p>将乘法转换为加法<br>乘法：<br><a href="http://www.codecogs.com/eqnedit.php?latex=\dpi{100}&space;P(C|F_1,F_2...F_n)&space;=&space;\frac{&space;P(F_1,F_2...F_n|C)P(C)}&space;{&space;P(F_1,F_2,...,F_n)}" target="_blank"><img src="http://latex.codecogs.com/gif.latex?\dpi{90}&space;P(C|F_1,F_2...F_n)&space;=&space;\frac{&space;P(F_1,F_2...F_n|C)P(C)}&space;{&space;P(F_1,F_2,...,F_n)}" title="P(C|F_1,F_2...F_n) = \frac{ P(F_1,F_2...F_n|C)P(C)} { P(F_1,F_2,...,F_n)}"></a></p>
<p>加法：<br><a href="http://www.codecogs.com/eqnedit.php?latex=\dpi{100}&space;\\&space;P(F_1|C)*P(F_2|C)....P(F_n|C)P(C)&space;\\&space;\Rightarrow&space;\\&space;log(P(F_1|C))&plus;log(P(F_2|C))&plus;....&plus;log(P(F_n|C))&plus;log(P(C))" target="_blank"><img src="http://latex.codecogs.com/gif.latex?\dpi{100}&space;\\&space;P(F_1|C)*P(F_2|C)....P(F_n|C)P(C)&space;\\&space;\Rightarrow&space;\\&space;log(P(F_1|C))&plus;log(P(F_2|C))&plus;....&plus;log(P(F_n|C))&plus;log(P(C))" title="\\ P(F_1|C)*P(F_2|C)....P(F_n|C)P(C) \\ \Rightarrow \\ log(P(F_1|C))+log(P(F_2|C))+....+log(P(F_n|C))+log(P(C))"></a></p>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br></pre></td><td class="code"><pre><span class="line"><span class="string">'''</span></span><br><span class="line"><span class="string">def classifyNB(vec2Classify, p0Vec, p1Vec, pClass1):</span></span><br><span class="line"><span class="string">    # 计算公式  log(P(F1|C))+log(P(F2|C))+....+log(P(Fn|C))+log(P(C))</span></span><br><span class="line"><span class="string">    # 使用 NumPy 数组来计算两个向量相乘的结果，这里的相乘是指对应元素相乘，即先将两个向量中的第一个元素相乘，然后将第2个元素相乘，以此类推。这里的 vec2Classify * p1Vec 的意思就是将每个词与其对应的概率相关联起来</span></span><br><span class="line"><span class="string">    p1 = sum(vec2Classify * p1Vec) + log(pClass1)</span></span><br><span class="line"><span class="string">    p0 = sum(vec2Classify * p0Vec) + log(1.0 - pClass1)</span></span><br><span class="line"><span class="string">    if p1 &gt; p0:</span></span><br><span class="line"><span class="string">        return 1</span></span><br><span class="line"><span class="string">    else:</span></span><br><span class="line"><span class="string">        return 0</span></span><br></pre></td></tr></table></figure>
<blockquote>
<p>测试朴素贝叶斯算法</p>
</blockquote>
<p>结合上面分析流程和实现方法，我们综合测试朴素贝叶斯对评论信息分类如下：<br><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br></pre></td><td class="code"><pre><span class="line"><span class="string">'''朴素贝叶斯算法屏蔽社区留言板的侮辱性言论的应用'''</span></span><br><span class="line"><span class="function"><span class="keyword">def</span> <span class="title">testingNB</span><span class="params">()</span>:</span></span><br><span class="line">    <span class="comment"># 1. 加载数据集</span></span><br><span class="line">    dataSet, Classlabels = loadDataSet()</span><br><span class="line">    <span class="comment"># 2. 创建单词集合</span></span><br><span class="line">    myVocabList = createVocabList(dataSet)</span><br><span class="line">    <span class="comment"># 3. 计算单词是否出现并创建数据矩阵</span></span><br><span class="line">    trainMat = []</span><br><span class="line">    <span class="keyword">for</span> postinDoc <span class="keyword">in</span> dataSet:</span><br><span class="line">        <span class="comment"># 返回m*len(myVocabList)的矩阵， 记录的都是0，1信息</span></span><br><span class="line">        trainMat.append(setOfWords2Vec(myVocabList, postinDoc))</span><br><span class="line">    <span class="comment"># print('test',len(array(trainMat)[0]))</span></span><br><span class="line">    <span class="comment"># 4. 训练数据</span></span><br><span class="line">    p0V, p1V, pAb = trainNB0(array(trainMat), array(Classlabels))</span><br><span class="line">    <span class="comment"># 5. 测试数据</span></span><br><span class="line">    testEntry = [<span class="string">'love'</span>, <span class="string">'my'</span>, <span class="string">'dalmation'</span>]</span><br><span class="line">    thisDoc = array(setOfWords2Vec(myVocabList, testEntry))</span><br><span class="line">    print(testEntry, <span class="string">'分类结果是: '</span>, classifyNB(thisDoc, p0V, p1V, pAb))</span><br><span class="line">    testEntry = [<span class="string">'stupid'</span>, <span class="string">'garbage'</span>]</span><br><span class="line">    thisDoc = array(setOfWords2Vec(myVocabList, testEntry))</span><br><span class="line">    print(testEntry, <span class="string">'分类结果是: '</span>, classifyNB(thisDoc, p0V, p1V, pAb))</span><br></pre></td></tr></table></figure></p>
<p>运行结果如下：</p>
<pre><code>[&#39;love&#39;, &#39;my&#39;, &#39;dalmation&#39;] 分类结果是:  0
[&#39;stupid&#39;, &#39;garbage&#39;] 分类结果是:  1
</code></pre><h2 id="案例场景2-对社区留言板言论进行分类"><a href="#案例场景2-对社区留言板言论进行分类" class="headerlink" title="案例场景2: 对社区留言板言论进行分类"></a>案例场景2: 对社区留言板言论进行分类</h2><h3 id="项目概述-1"><a href="#项目概述-1" class="headerlink" title="项目概述"></a>项目概述</h3><p>我们运行朴素贝叶斯分类进行电子邮件垃圾过滤。在文档分类中，整个文档（如一封电子邮件）是实例，而电子邮件中的某些元素则构成特征。我们可以观察文档中出现的词，并把每个词作为一个特征，而每个词的出现或者不出现作为该特征的值，这样得到的特征数目就会跟词汇表中的词的数目一样多。</p>
<p>本项目开发流程如下：</p>
<pre><code>收集数据: 提供文本文件
准备数据: 将文本文件解析成词条向量
分析数据: 检查词条确保解析的正确性
训练算法: 使用我们之前建立的 trainNB() 函数
测试算法: 使用朴素贝叶斯进行交叉验证
使用算法: 构建一个完整的程序对一组文档进行分类，将错分的文档输出到屏幕上
</code></pre><h3 id="收集数据并预处理"><a href="#收集数据并预处理" class="headerlink" title="收集数据并预处理"></a>收集数据并预处理</h3><p>邮件格式内容如下：</p>
<p><img src="https://i.imgur.com/ur4LMd3.png" alt=""></p>
<p>对邮件进行读取实现如下：<br><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br></pre></td><td class="code"><pre><span class="line"><span class="string">'''读取文本'''</span></span><br><span class="line"><span class="function"><span class="keyword">def</span> <span class="title">testParseTest</span><span class="params">()</span>:</span></span><br><span class="line">    print(textParse(open(<span class="string">'./email/ham/1.txt'</span>).read()))</span><br></pre></td></tr></table></figure></p>
<h3 id="准备数据"><a href="#准备数据" class="headerlink" title="准备数据"></a>准备数据</h3><p>对读取的文本进行词条向量化，其实现如下：<br><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br></pre></td><td class="code"><pre><span class="line"><span class="string">'''接收一个大字符串并将其解析为字符串列表'''</span></span><br><span class="line"><span class="function"><span class="keyword">def</span> <span class="title">textParse</span><span class="params">(bigString)</span>:</span></span><br><span class="line">    <span class="keyword">import</span> re</span><br><span class="line">    <span class="comment"># 使用正则表达式来切分句子，其中分隔符是除单词、数字外的任意字符串</span></span><br><span class="line">    listOfTokens = re.split(<span class="string">r'\W*'</span>, bigString)</span><br><span class="line">    <span class="keyword">return</span> [tok.lower() <span class="keyword">for</span> tok <span class="keyword">in</span> listOfTokens <span class="keyword">if</span> len(tok) &gt; <span class="number">2</span>]</span><br></pre></td></tr></table></figure></p>
<h3 id="分析数据-1"><a href="#分析数据-1" class="headerlink" title="分析数据"></a>分析数据</h3><p>这个部分在案例场景1进行了详细描述，此处不在赘述。</p>
<h3 id="训练算法"><a href="#训练算法" class="headerlink" title="训练算法"></a>训练算法</h3><p>此处，我们去调用在场景1优化过的朴素贝叶斯训练模型trainNB0() 函数，这里也是一劳永逸的方法。还可以对数据预处理等进行封装。</p>
<h3 id="测试算法-1"><a href="#测试算法-1" class="headerlink" title="测试算法"></a>测试算法</h3><p>本测试方法中使用的数据集，即文档可以参见下文代码下载。采用方法跟场景1基本类似，这里不作代码解析。具体实现代码如下：<br><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br><span class="line">37</span><br><span class="line">38</span><br></pre></td><td class="code"><pre><span class="line"><span class="string">'''对贝叶斯垃圾邮件分类器进行自动化处理。'''</span></span><br><span class="line"><span class="function"><span class="keyword">def</span> <span class="title">spamTest</span><span class="params">()</span>:</span></span><br><span class="line">    docList = [];classList = [];fullText = [] <span class="comment"># 文档列表、类别列表、文本特征</span></span><br><span class="line">    <span class="keyword">for</span> i <span class="keyword">in</span> range(<span class="number">1</span>, <span class="number">26</span>): <span class="comment"># 总共25个文档</span></span><br><span class="line">        <span class="comment"># 切分，解析数据，并归类为 1 类别</span></span><br><span class="line">        wordList = textParse(open(<span class="string">'./email/spam/%d.txt'</span> % i).read())</span><br><span class="line">        docList.append(wordList)</span><br><span class="line">        classList.append(<span class="number">1</span>)</span><br><span class="line">        <span class="comment"># 切分，解析数据，并归类为 0 类别</span></span><br><span class="line">        wordList = textParse(open(<span class="string">'./email/ham/%d.txt'</span> % i,encoding=<span class="string">'UTF-8'</span>).read())</span><br><span class="line">        docList.append(wordList)</span><br><span class="line">        classList.append(<span class="number">0</span>)</span><br><span class="line">        fullText.extend(wordList)</span><br><span class="line">    <span class="comment"># 创建词汇表</span></span><br><span class="line">    vocabList = createVocabList(docList)</span><br><span class="line">    trainingSet = list(range(<span class="number">50</span>)) <span class="comment"># 词汇表文档索引</span></span><br><span class="line">    testSet = []</span><br><span class="line">    <span class="comment"># 随机取 10 个邮件用来测试</span></span><br><span class="line">    <span class="keyword">for</span> i <span class="keyword">in</span> range(<span class="number">10</span>):</span><br><span class="line">        <span class="comment"># random.uniform(x, y) 随机生成一个范围为 x - y 的实数</span></span><br><span class="line">        randIndex = int(random.uniform(<span class="number">0</span>, len(trainingSet)))</span><br><span class="line">        testSet.append(trainingSet[randIndex]) <span class="comment"># 随机抽取测试样本</span></span><br><span class="line">        <span class="keyword">del</span>(trainingSet[randIndex]) <span class="comment"># 训练集中删除选择为测试集的文档</span></span><br><span class="line"></span><br><span class="line">    trainMat = [];trainClasses = [] <span class="comment"># 训练集合训练标签</span></span><br><span class="line">    <span class="keyword">for</span> docIndex <span class="keyword">in</span> trainingSet:</span><br><span class="line">        trainMat.append(setOfWords2Vec(vocabList, docList[docIndex]))</span><br><span class="line">        trainClasses.append(classList[docIndex])</span><br><span class="line"></span><br><span class="line">    p0V, p1V, pSpam = trainNB0(array(trainMat), array(trainClasses))</span><br><span class="line">    errorCount = <span class="number">0</span></span><br><span class="line">    <span class="keyword">for</span> docIndex <span class="keyword">in</span> testSet:</span><br><span class="line">        wordVector = setOfWords2Vec(vocabList, docList[docIndex])</span><br><span class="line">        <span class="keyword">if</span> classifyNB(array(wordVector), p0V, p1V, pSpam) != classList[docIndex]:</span><br><span class="line">            errorCount += <span class="number">1</span></span><br><span class="line">    print(<span class="string">'the errorCount is: '</span>, errorCount)</span><br><span class="line">    print(<span class="string">'the testSet length is :'</span>, len(testSet))</span><br><span class="line">    print(<span class="string">'the error rate is :'</span>, float(errorCount)/len(testSet))</span><br></pre></td></tr></table></figure></p>
<p>运行结果如下：</p>
<pre><code>the errorCount is:  2
the testSet length is : 10
the error rate is : 0.2
</code></pre><h2 id="案例场景3-使用朴素贝叶斯分类器从个人广告中获取区域倾向"><a href="#案例场景3-使用朴素贝叶斯分类器从个人广告中获取区域倾向" class="headerlink" title="案例场景3: 使用朴素贝叶斯分类器从个人广告中获取区域倾向"></a>案例场景3: 使用朴素贝叶斯分类器从个人广告中获取区域倾向</h2><h3 id="项目概述-2"><a href="#项目概述-2" class="headerlink" title="项目概述"></a>项目概述</h3><p>广告商往往想知道关于一个人的一些特定人口统计信息，以便能更好地定向推销广告。我们将分别从美国的两个城市中选取一些人，通过分析这些人发布的信息，来比较这两个城市的人们在广告用词上是否不同。如果结论确实不同，那么他们各自常用的词是哪些，从人们的用词当中，我们能否对不同城市的人所关心的内容有所了解。</p>
<p>开发流程如下：</p>
<pre><code>收集数据: 从 RSS 源收集内容，这里需要对 RSS 源构建一个接口
准备数据: 将文本文件解析成词条向量
分析数据: 检查词条确保解析的正确性
训练算法: 使用我们之前建立的 trainNB0() 函数
测试算法: 观察错误率，确保分类器可用。可以修改切分程序，以降低错误率，提高分类结果
使用算法: 构建一个完整的程序，封装所有内容。给定两个 RSS 源，改程序会显示最常用的公共词
</code></pre><h3 id="收集数据-1"><a href="#收集数据-1" class="headerlink" title="收集数据"></a>收集数据</h3><p>从 RSS 源收集内容，这里需要对 RSS 源构建一个接口，也就是导入 RSS 源，我们使用 python 下载文本，在 <a href="http://code.google.com/p/feedparser/" target="_blank" rel="noopener">点击下载地址</a> 下浏览相关文档，安装 feedparse，首先解压下载的包，并将当前目录切换到解压文件所在的文件夹，然后在 python 提示符下输入：python setup.py install</p>
<h3 id="准备数据-1"><a href="#准备数据-1" class="headerlink" title="准备数据"></a>准备数据</h3><blockquote>
<p>文档词袋模型</p>
</blockquote>
<p>我们将每个词的出现与否作为一个特征，这可以被描述为 词集模型(set-of-words model)。如果一个词在文档中出现不止一次，这可能意味着包含该词是否出现在文档中所不能表达的某种信息，这种方法被称为 词袋模型(bag-of-words model)。在词袋中，每个单词可以出现多次，而在词集中，每个词只能出现一次。为适应词袋模型，需要对函数 setOfWords2Vec() 稍加修改，修改后的函数为 bagOfWords2Vec() 。</p>
<p>如下给出了基于词袋模型的朴素贝叶斯代码。它与函数 setOfWords2Vec() 几乎完全相同，唯一不同的是每当遇到一个单词时，它会增加词向量中的对应值，而不只是将对应的数值设为 1 。</p>
<p>这部分在场景1中已经构建完成，并进行了阐述。</p>
<h3 id="分析数据-2"><a href="#分析数据-2" class="headerlink" title="分析数据"></a>分析数据</h3><p>这个部分在案例场景1进行了详细描述，此处不在赘述。</p>
<h3 id="训练算法-1"><a href="#训练算法-1" class="headerlink" title="训练算法"></a>训练算法</h3><p>此处，我们去调用在场景1优化过的朴素贝叶斯训练模型trainNB0() 函数，这里也是一劳永逸的方法。还可以对数据预处理等进行封装。</p>
<h3 id="测试算法-2"><a href="#测试算法-2" class="headerlink" title="测试算法"></a>测试算法</h3><p>观察错误率，确保分类器可用。可以修改切分程序，以降低错误率，提高分类结果。其具体实现如下：</p>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br><span class="line">37</span><br><span class="line">38</span><br><span class="line">39</span><br><span class="line">40</span><br><span class="line">41</span><br><span class="line">42</span><br><span class="line">43</span><br><span class="line">44</span><br><span class="line">45</span><br><span class="line">46</span><br></pre></td><td class="code"><pre><span class="line"><span class="string">'''RSS源分类器及高频词去除函数'''</span></span><br><span class="line"><span class="function"><span class="keyword">def</span> <span class="title">calcMostFreq</span><span class="params">(vocabList,fullText)</span>:</span></span><br><span class="line">    <span class="keyword">import</span> operator</span><br><span class="line">    freqDict=&#123;&#125;</span><br><span class="line">    <span class="keyword">for</span> token <span class="keyword">in</span> vocabList:  <span class="comment">#遍历词汇表中的每个词</span></span><br><span class="line">        freqDict[token]=fullText.count(token)  <span class="comment">#统计每个词在文本中出现的次数</span></span><br><span class="line">    sortedFreq=sorted(freqDict.items(),key=operator.itemgetter(<span class="number">1</span>),reverse=<span class="keyword">True</span>)  <span class="comment">#根据每个词出现的次数从高到底对字典进行排序</span></span><br><span class="line">    <span class="keyword">return</span> sortedFreq[:<span class="number">30</span>]   <span class="comment">#返回出现次数最高的30个单词</span></span><br><span class="line"></span><br><span class="line"></span><br><span class="line"></span><br><span class="line"><span class="function"><span class="keyword">def</span> <span class="title">localWords</span><span class="params">(feed1,feed0)</span>:</span></span><br><span class="line">    <span class="comment"># import feedparser # feedparser是python中最常用的RSS程序库</span></span><br><span class="line">    docList=[];classList=[];fullText=[]</span><br><span class="line">    minLen=min(len(feed1[<span class="string">'entries'</span>]),len(feed0[<span class="string">'entries'</span>])) <span class="comment"># entries内容无法抓取，网站涉及反爬虫技术</span></span><br><span class="line">    print(len(feed1[<span class="string">'entries'</span>]),len(feed0[<span class="string">'entries'</span>]))</span><br><span class="line">    <span class="keyword">for</span> i <span class="keyword">in</span> range(minLen):</span><br><span class="line">        wordList=textParse(feed1[<span class="string">'entries'</span>][i][<span class="string">'summary'</span>])   <span class="comment">#每次访问一条RSS源</span></span><br><span class="line">        docList.append(wordList)</span><br><span class="line">        fullText.extend(wordList)</span><br><span class="line">        classList.append(<span class="number">1</span>)</span><br><span class="line">        wordList=textParse(feed0[<span class="string">'entries'</span>][i][<span class="string">'summary'</span>])</span><br><span class="line">        docList.append(wordList)</span><br><span class="line">        fullText.extend(wordList)</span><br><span class="line">        classList.append(<span class="number">0</span>)</span><br><span class="line">    vocabList=createVocabList(docList)</span><br><span class="line">    top30Words=calcMostFreq(vocabList,fullText)</span><br><span class="line">    <span class="keyword">for</span> pairW <span class="keyword">in</span> top30Words:</span><br><span class="line">        <span class="keyword">if</span> pairW[<span class="number">0</span>] <span class="keyword">in</span> vocabList:vocabList.remove(pairW[<span class="number">0</span>])    <span class="comment">#去掉出现次数最高的那些词</span></span><br><span class="line">    trainingSet=range(<span class="number">2</span>*minLen);testSet=[]</span><br><span class="line">    <span class="keyword">for</span> i <span class="keyword">in</span> range(<span class="number">20</span>):</span><br><span class="line">        randIndex=int(random.uniform(<span class="number">0</span>,len(trainingSet)))</span><br><span class="line">        testSet.append(trainingSet[randIndex])</span><br><span class="line">        <span class="keyword">del</span>(trainingSet[randIndex])</span><br><span class="line">    trainMat=[];trainClasses=[]</span><br><span class="line">    <span class="keyword">for</span> docIndex <span class="keyword">in</span> trainingSet:</span><br><span class="line">        trainMat.append(bagOfWords2VecMN(vocabList,docList[docIndex]))</span><br><span class="line">        trainClasses.append(classList[docIndex])</span><br><span class="line">    p0V,p1V,pSpam=trainNB0(array(trainMat),array(trainClasses))</span><br><span class="line">    errorCount=<span class="number">0</span></span><br><span class="line">    <span class="keyword">for</span> docIndex <span class="keyword">in</span> testSet:</span><br><span class="line">        wordVector=bagOfWords2VecMN(vocabList,docList[docIndex])</span><br><span class="line">        <span class="keyword">if</span> classifyNB(array(wordVector),p0V,p1V,pSpam)!=classList[docIndex]:</span><br><span class="line">            errorCount+=<span class="number">1</span></span><br><span class="line">    print(<span class="string">'the error rate is:'</span>,float(errorCount)/len(testSet))</span><br><span class="line">    <span class="keyword">return</span> vocabList,p0V,p1V</span><br></pre></td></tr></table></figure>
<p>运行结果：</p>
<pre><code>ny = feedparser.parse(&#39;http://newyork.craigslist.org/stp/index.rss&#39;)
sf = feedparser.parse(&#39;http://sfbay.craigslist.org/stp/index.rss&#39;)
# print(ny)
vocabList,pSF,pNY=localWords(ny,sf)
</code></pre><p>由于如上两个地址抓取，得到feed0[‘entries’]为空，所以没有进行结果分析，读者可以试用其他rss地址进行处理。如下是采用之前网站反爬虫抓取前的分析结果：</p>
<pre><code>vocabList,pSF,pNY=bayes.localWords(ny,sf)
the error rate is: 0.2
vocabList,pSF,pNY=bayes.localWords(ny,sf)
the error rate is: 0.3
vocabList,pSF,pNY=bayes.localWords(ny,sf)
the error rate is: 0.55
</code></pre><h2 id="参考文献"><a href="#参考文献" class="headerlink" title="参考文献"></a>参考文献</h2><ol>
<li>scikit中文社区：<a href="http://sklearn.apachecn.org/cn/0.19.0/" target="_blank" rel="noopener">http://sklearn.apachecn.org/cn/0.19.0/</a></li>
<li>中文维基百科：<a href="https://zh.wikipedia.org/wiki/" target="_blank" rel="noopener">https://zh.wikipedia.org/wiki/</a></li>
<li>文本分类特征选择：<a href="https://www.cnblogs.com/june0507/p/7601001.html" target="_blank" rel="noopener">https://www.cnblogs.com/june0507/p/7601001.html</a></li>
<li>GitHub：<a href="https://github.com/BaiNingchao/MachineLearning-1" target="_blank" rel="noopener">https://github.com/BaiNingchao/MachineLearning-1</a></li>
<li>图书：《机器学习实战》</li>
<li><a href="https://baike.baidu.com/item/%E8%87%AA%E7%84%B6%E8%AF%AD%E8%A8%80%E5%A4%84%E7%90%86%E7%90%86%E8%AE%BA%E4%B8%8E%E5%AE%9E%E6%88%98" target="_blank" rel="noopener">图书：《自然语言处理理论与实战》</a></li>
</ol>
<h2 id="完整代码下载"><a href="#完整代码下载" class="headerlink" title="完整代码下载"></a>完整代码下载</h2><blockquote>
<p>源码请进【机器学习和自然语言QQ群：436303759】文件下载：</p>
</blockquote>
<p><img src="https://i.imgur.com/Fl1W5mB.png" alt=""></p>
<h2 id="作者声明"><a href="#作者声明" class="headerlink" title="作者声明"></a>作者声明</h2><blockquote>
<p>本文版权归作者所有，旨在技术交流使用。未经作者同意禁止转载，转载后需在文章页面明显位置给出原文连接，否则相关责任自行承担。</p>
</blockquote>

      
    </div>

    

    
    
    

    
      <div>
        <div id="wechat_subscriber" style="display: block; padding: 10px 0; margin: 20px auto; width: 100%; text-align: center">
    <img id="wechat_subscriber_qcode" src="/uploads/wechat.png" alt="白宁超 wechat" style="width: 200px; max-width: 100%;"/>
    <div>扫一扫关注微信公众号，机器学习和自然语言处理，订阅号datathinks！</div>
</div>

      </div>
    

    
      <div>
        <div style="padding: 10px 0; margin: 20px auto; width: 90%; text-align: center;">
  <div></div>
  <button id="rewardButton" disable="enable" onclick="var qr = document.getElementById('QR'); if (qr.style.display === 'none') {qr.style.display='block';} else {qr.style.display='none'}">
    <span>打赏</span>
  </button>
  <div id="QR" style="display: none;">

    
      <div id="wechat" style="display: inline-block">
        <img id="wechat_qr" src="/images/wechatpay.jpg" alt="白宁超 微信支付"/>
        <p>微信支付</p>
      </div>
    

    
      <div id="alipay" style="display: inline-block">
        <img id="alipay_qr" src="/images/alipay.jpg" alt="白宁超 支付宝"/>
        <p>支付宝</p>
      </div>
    

    

  </div>
</div>

      </div>
    

    

    <footer class="post-footer">
      
        <div class="post-tags">
          
            <a href="/tags/Python/" rel="tag"><i class="fa fa-tag"></i> Python</a>
          
            <a href="/tags/文本分类/" rel="tag"><i class="fa fa-tag"></i> 文本分类</a>
          
            <a href="/tags/Naive-Bayes/" rel="tag"><i class="fa fa-tag"></i> Naive Bayes</a>
          
            <a href="/tags/ML/" rel="tag"><i class="fa fa-tag"></i> ML</a>
          
            <a href="/tags/实战案例/" rel="tag"><i class="fa fa-tag"></i> 实战案例</a>
          
        </div>
      

      
      
        <div class="post-widgets">
        

        

        
          
          <div class="social_share">
            
               <div>
                 
  <div class="bdsharebuttonbox">
    <a href="#" class="bds_tsina" data-cmd="tsina" title="分享到新浪微博"></a>
    <a href="#" class="bds_douban" data-cmd="douban" title="分享到豆瓣网"></a>
    <a href="#" class="bds_sqq" data-cmd="sqq" title="分享到QQ好友"></a>
    <a href="#" class="bds_qzone" data-cmd="qzone" title="分享到QQ空间"></a>
    <a href="#" class="bds_weixin" data-cmd="weixin" title="分享到微信"></a>
    <a href="#" class="bds_tieba" data-cmd="tieba" title="分享到百度贴吧"></a>
    <a href="#" class="bds_twi" data-cmd="twi" title="分享到Twitter"></a>
    <a href="#" class="bds_fbook" data-cmd="fbook" title="分享到Facebook"></a>
    <a href="#" class="bds_more" data-cmd="more"></a>
    <a class="bds_count" data-cmd="count"></a>
  </div>
  <script>
    window._bd_share_config = {
      "common": {
        "bdText": "",
        "bdMini": "2",
        "bdMiniList": false,
        "bdPic": ""
      },
      "share": {
        "bdSize": "16",
        "bdStyle": "0"
      },
      "image": {
        "viewList": ["tsina", "douban", "sqq", "qzone", "weixin", "twi", "fbook"],
        "viewText": "分享到：",
        "viewSize": "16"
      }
    }
  </script>

<script>
  with(document)0[(getElementsByTagName('head')[0]||body).appendChild(createElement('script')).src='/static/api/js/share.js?cdnversion='+~(-new Date()/36e5)];
</script>

               </div>
            
            
               <div id="needsharebutton-postbottom">
                 <span class="btn">
                    <i class="fa fa-share-alt" aria-hidden="true"></i>
                 </span>
               </div>
            
          </div>
        
        </div>
      
      

      
        <div class="post-nav">
          <div class="post-nav-next post-nav-item">
            
              <a href="/2018/09/19/一步步教你轻松学朴素贝叶斯模型算法理论篇1/" rel="next" title="一步步教你轻松学朴素贝叶斯模型算法理论篇1">
                <i class="fa fa-chevron-left"></i> 一步步教你轻松学朴素贝叶斯模型算法理论篇1
              </a>
            
          </div>

          <span class="post-nav-divider"></span>

          <div class="post-nav-prev post-nav-item">
            
              <a href="/2018/09/19/一步步教你轻松学朴素贝叶斯模型算法Sklearn深度篇3/" rel="prev" title="一步步教你轻松学朴素贝叶斯模型算法Sklearn深度篇3">
                一步步教你轻松学朴素贝叶斯模型算法Sklearn深度篇3 <i class="fa fa-chevron-right"></i>
              </a>
            
          </div>
        </div>
      

      
      
    </footer>
  </div>
  
  
  
  </article>


  </div>


          </div>
          

  
    <div class="comments" id="comments">
      <div id="lv-container" data-id="city" data-uid="MTAyMC8zOTc5NC8xNjMyMQ=="></div>
    </div>

  
 





        </div>
        
          
  
  <div class="sidebar-toggle">
    <div class="sidebar-toggle-line-wrap">
      <span class="sidebar-toggle-line sidebar-toggle-line-first"></span>
      <span class="sidebar-toggle-line sidebar-toggle-line-middle"></span>
      <span class="sidebar-toggle-line sidebar-toggle-line-last"></span>
    </div>
  </div>

  <aside id="sidebar" class="sidebar">
    
    <div class="sidebar-inner">

      

      
        <ul class="sidebar-nav motion-element">
          <li class="sidebar-nav-toc sidebar-nav-active" data-target="post-toc-wrap">
            文章目录
          </li>
          <li class="sidebar-nav-overview" data-target="site-overview-wrap">
            站点概览
          </li>
        </ul>
      

      <section class="site-overview-wrap sidebar-panel">
        <div class="site-overview">
          <div class="site-author motion-element" itemprop="author" itemscope itemtype="http://schema.org/Person">
            
              <img class="site-author-image" itemprop="image"
                src="/../images/header.png"
                alt="白宁超" />
            
              <p class="site-author-name" itemprop="name">白宁超</p>
              <p class="site-description motion-element" itemprop="description">本站主要研究深度学习、机器学习、自然语言处理等前沿技术。ML&NLP交流群：436303759 <span><a target="_blank" href="http://shang.qq.com/wpa/qunwpa?idkey=ef3bbb679b06ac59b136c57ba9e7935ff9d3b10faeabde6e4efcafe523bbbf4d"><img border="0" src="http://pub.idqqimg.com/wpa/images/group.png" alt="自然语言处理和机器学习技术QQ交流：436303759 " title="自然语言处理和机器学习技术交流"></a></span></p>
          </div>

          
            <nav class="site-state motion-element">
              
                <div class="site-state-item site-state-posts">
                
                  <a href="/archives">
                
                    <span class="site-state-item-count">36</span>
                    <span class="site-state-item-name">日志</span>
                  </a>
                </div>
              

              
                
                
                <div class="site-state-item site-state-categories">
                  <a href="/categories/index.html">
                    
                    
                      
                    
                      
                    
                      
                    
                      
                    
                      
                    
                      
                    
                      
                    
                      
                    
                      
                    
                      
                    
                      
                    
                      
                    
                      
                    
                      
                    
                      
                    
                      
                    
                      
                    
                      
                    
                      
                    
                      
                    
                      
                    
                      
                    
                      
                    
                      
                    
                      
                    
                    <span class="site-state-item-count">25</span>
                    <span class="site-state-item-name">分类</span>
                  </a>
                </div>
              

              
                
                
                <div class="site-state-item site-state-tags">
                  <a href="/tags/index.html">
                    
                    
                      
                    
                      
                    
                      
                    
                      
                    
                      
                    
                      
                    
                      
                    
                      
                    
                      
                    
                      
                    
                      
                    
                      
                    
                      
                    
                      
                    
                      
                    
                      
                    
                      
                    
                      
                    
                      
                    
                      
                    
                      
                    
                      
                    
                      
                    
                      
                    
                      
                    
                      
                    
                      
                    
                      
                    
                      
                    
                      
                    
                      
                    
                      
                    
                      
                    
                      
                    
                      
                    
                      
                    
                      
                    
                      
                    
                      
                    
                      
                    
                      
                    
                      
                    
                      
                    
                      
                    
                      
                    
                      
                    
                      
                    
                      
                    
                      
                    
                      
                    
                      
                    
                      
                    
                      
                    
                      
                    
                      
                    
                      
                    
                      
                    
                      
                    
                      
                    
                      
                    
                      
                    
                      
                    
                      
                    
                      
                    
                      
                    
                      
                    
                      
                    
                      
                    
                      
                    
                      
                    
                      
                    
                      
                    
                      
                    
                      
                    
                      
                    
                      
                    
                    <span class="site-state-item-count">76</span>
                    <span class="site-state-item-name">标签</span>
                  </a>
                </div>
              
            </nav>
          

          
            <div class="feed-link motion-element">
              <a href="/atom.xml" rel="alternate">
                <i class="fa fa-rss"></i>
                RSS
              </a>
            </div>
          

          
            <div class="links-of-author motion-element">
              
                <span class="links-of-author-item">
                  <a href="https://github.com/bainingchao" target="_blank" title="GitHub" rel="external nofollow"><i class="fa fa-fw fa-github"></i>GitHub</a>
                  
                </span>
              
                <span class="links-of-author-item">
                  <a href="https://www.google.com.hk/" target="_blank" title="Google" rel="external nofollow"><i class="fa fa-fw fa-google"></i>Google</a>
                  
                </span>
              
                <span class="links-of-author-item">
                  <a href="https://www.baidu.com/" target="_blank" title="百度" rel="external nofollow"><i class="fa fa-fw fa-globe"></i>百度</a>
                  
                </span>
              
                <span class="links-of-author-item">
                  <a href="https://weibo.com/p/1005056002073632?is_all=1" target="_blank" title="微博" rel="external nofollow"><i class="fa fa-fw fa-weibo"></i>微博</a>
                  
                </span>
              
                <span class="links-of-author-item">
                  <a href="http://www.cnblogs.com/baiboy/" target="_blank" title="博客园" rel="external nofollow"><i class="fa fa-fw fa-globe"></i>博客园</a>
                  
                </span>
              
                <span class="links-of-author-item">
                  <a href="https://mp.weixin.qq.com/s/s97I4gtEJIt5rMivWMkPkQ" target="_blank" title="微信公众号" rel="external nofollow"><i class="fa fa-fw fa-weixin"></i>微信公众号</a>
                  
                </span>
              
            </div>
          

          
          

          
          

          
            
          
          

        </div>
      </section>

      
      <!--noindex-->
        <section class="post-toc-wrap motion-element sidebar-panel sidebar-panel-active">
          <div class="post-toc">

            
              
            

            
              <div class="post-toc-content"><ol class="nav"><li class="nav-item nav-level-2"><a class="nav-link" href="#案例场景1-屏蔽社区留言板的侮辱性言论"><span class="nav-number">1.</span> <span class="nav-text">案例场景1: 屏蔽社区留言板的侮辱性言论</span></a><ol class="nav-child"><li class="nav-item nav-level-3"><a class="nav-link" href="#项目概述"><span class="nav-number">1.1.</span> <span class="nav-text">项目概述</span></a></li><li class="nav-item nav-level-3"><a class="nav-link" href="#收集数据"><span class="nav-number">1.2.</span> <span class="nav-text">收集数据</span></a></li><li class="nav-item nav-level-3"><a class="nav-link" href="#数据预处理"><span class="nav-number">1.3.</span> <span class="nav-text">数据预处理</span></a></li><li class="nav-item nav-level-3"><a class="nav-link" href="#分析数据"><span class="nav-number">1.4.</span> <span class="nav-text">分析数据</span></a></li><li class="nav-item nav-level-3"><a class="nav-link" href="#训练模型"><span class="nav-number">1.5.</span> <span class="nav-text">训练模型</span></a></li><li class="nav-item nav-level-3"><a class="nav-link" href="#测试算法"><span class="nav-number">1.6.</span> <span class="nav-text">测试算法</span></a></li><li class="nav-item nav-level-3"><a class="nav-link" href="#使用算法对社区留言板言论进行分类"><span class="nav-number">1.7.</span> <span class="nav-text">使用算法对社区留言板言论进行分类</span></a></li></ol></li><li class="nav-item nav-level-2"><a class="nav-link" href="#案例场景2-对社区留言板言论进行分类"><span class="nav-number">2.</span> <span class="nav-text">案例场景2: 对社区留言板言论进行分类</span></a><ol class="nav-child"><li class="nav-item nav-level-3"><a class="nav-link" href="#项目概述-1"><span class="nav-number">2.1.</span> <span class="nav-text">项目概述</span></a></li><li class="nav-item nav-level-3"><a class="nav-link" href="#收集数据并预处理"><span class="nav-number">2.2.</span> <span class="nav-text">收集数据并预处理</span></a></li><li class="nav-item nav-level-3"><a class="nav-link" href="#准备数据"><span class="nav-number">2.3.</span> <span class="nav-text">准备数据</span></a></li><li class="nav-item nav-level-3"><a class="nav-link" href="#分析数据-1"><span class="nav-number">2.4.</span> <span class="nav-text">分析数据</span></a></li><li class="nav-item nav-level-3"><a class="nav-link" href="#训练算法"><span class="nav-number">2.5.</span> <span class="nav-text">训练算法</span></a></li><li class="nav-item nav-level-3"><a class="nav-link" href="#测试算法-1"><span class="nav-number">2.6.</span> <span class="nav-text">测试算法</span></a></li></ol></li><li class="nav-item nav-level-2"><a class="nav-link" href="#案例场景3-使用朴素贝叶斯分类器从个人广告中获取区域倾向"><span class="nav-number">3.</span> <span class="nav-text">案例场景3: 使用朴素贝叶斯分类器从个人广告中获取区域倾向</span></a><ol class="nav-child"><li class="nav-item nav-level-3"><a class="nav-link" href="#项目概述-2"><span class="nav-number">3.1.</span> <span class="nav-text">项目概述</span></a></li><li class="nav-item nav-level-3"><a class="nav-link" href="#收集数据-1"><span class="nav-number">3.2.</span> <span class="nav-text">收集数据</span></a></li><li class="nav-item nav-level-3"><a class="nav-link" href="#准备数据-1"><span class="nav-number">3.3.</span> <span class="nav-text">准备数据</span></a></li><li class="nav-item nav-level-3"><a class="nav-link" href="#分析数据-2"><span class="nav-number">3.4.</span> <span class="nav-text">分析数据</span></a></li><li class="nav-item nav-level-3"><a class="nav-link" href="#训练算法-1"><span class="nav-number">3.5.</span> <span class="nav-text">训练算法</span></a></li><li class="nav-item nav-level-3"><a class="nav-link" href="#测试算法-2"><span class="nav-number">3.6.</span> <span class="nav-text">测试算法</span></a></li></ol></li><li class="nav-item nav-level-2"><a class="nav-link" href="#参考文献"><span class="nav-number">4.</span> <span class="nav-text">参考文献</span></a></li><li class="nav-item nav-level-2"><a class="nav-link" href="#完整代码下载"><span class="nav-number">5.</span> <span class="nav-text">完整代码下载</span></a></li><li class="nav-item nav-level-2"><a class="nav-link" href="#作者声明"><span class="nav-number">6.</span> <span class="nav-text">作者声明</span></a></li></ol></div>
            

          </div>
        </section>
      <!--/noindex-->
      

      

    </div>
  </aside>


        
      </div>
    </main>

    <footer id="footer" class="footer">
      <div class="footer-inner">
        <script async src="https://dn-lbstatics.qbox.me/busuanzi/2.3/busuanzi.pure.mini.js">
</script>

<div class="copyright">&copy; <span itemprop="copyrightYear">2018</span>
  <span class="with-love" id="animate">
    <i class="fa fa-user"></i>
  </span>
  <span class="author" itemprop="copyrightHolder">白宁超</span>

  

  
</div>




  



  <!--<div class="powered-by">由 <a class="theme-link" target="_blank" rel="external nofollow" href="https://hexo.io">Hexo</a> 强力驱动 v3.7.1</div> -->



   <!--<span class="post-meta-divider">|</span>-->



   <!--<div class="theme-info">主题 – <a class="theme-link" target="_blank" rel="external nofollow" href="https://theme-next.org">NexT.Gemini</a> v6.4.1</div>-->




        <script async src="//busuanzi.ibruce.info/busuanzi/2.3/busuanzi.pure.mini.js"></script>



<div class="busuanzi-count">
  
    <span class="site-uv" title="总访客量">
      <i class="fa fa-user"></i>
      <span class="busuanzi-value" id="busuanzi_value_site_uv"></span>
    </span>
  

  
    <span class="site-pv" title="总访问量">
      <i class="fa fa-eye"></i>
      <span class="busuanzi-value" id="busuanzi_value_site_pv"></span>
    </span>
  
</div>









        
      </div>
    </footer>

    
      <div class="back-to-top">
        <i class="fa fa-arrow-up"></i>
        
      </div>
    

    
	
    

    
  </div>

  

<script type="text/javascript">
  if (Object.prototype.toString.call(window.Promise) !== '[object Function]') {
    window.Promise = null;
  }
</script>


























  
  
    <script type="text/javascript" src="/lib/jquery/index.js?v=2.1.3"></script>
  

  
  
    <script type="text/javascript" src="/lib/velocity/velocity.min.js?v=1.2.1"></script>
  

  
  
    <script type="text/javascript" src="/lib/velocity/velocity.ui.min.js?v=1.2.1"></script>
  


  


  <script type="text/javascript" src="/js/src/utils.js?v=6.4.1"></script>

  <script type="text/javascript" src="/js/src/motion.js?v=6.4.1"></script>



  
  


  <script type="text/javascript" src="/js/src/affix.js?v=6.4.1"></script>

  <script type="text/javascript" src="/js/src/schemes/pisces.js?v=6.4.1"></script>



  
  <script type="text/javascript" src="/js/src/scrollspy.js?v=6.4.1"></script>
<script type="text/javascript" src="/js/src/post-details.js?v=6.4.1"></script>



  


  <script type="text/javascript" src="/js/src/bootstrap.js?v=6.4.1"></script>



  



  
    <script type="text/javascript">
      window.livereOptions = {
        refer: '2018/09/19/一步步教你轻松学朴素贝叶斯模型算法实现篇2/'
      };
      (function(d, s) {
        var j, e = d.getElementsByTagName(s)[0];
        if (typeof LivereTower === 'function') { return; }
        j = d.createElement(s);
        j.src = 'https://cdn-city.livere.com/js/embed.dist.js';
        j.async = true;
        e.parentNode.insertBefore(j, e);
      })(document, 'script');
    </script>
  










  

  <script type="text/javascript">
    // Popup Window;
    var isfetched = false;
    var isXml = true;
    // Search DB path;
    var search_path = "search.xml";
    if (search_path.length === 0) {
      search_path = "search.xml";
    } else if (/json$/i.test(search_path)) {
      isXml = false;
    }
    var path = "/" + search_path;
    // monitor main search box;

    var onPopupClose = function (e) {
      $('.popup').hide();
      $('#local-search-input').val('');
      $('.search-result-list').remove();
      $('#no-result').remove();
      $(".local-search-pop-overlay").remove();
      $('body').css('overflow', '');
    }

    function proceedsearch() {
      $("body")
        .append('<div class="search-popup-overlay local-search-pop-overlay"></div>')
        .css('overflow', 'hidden');
      $('.search-popup-overlay').click(onPopupClose);
      $('.popup').toggle();
      var $localSearchInput = $('#local-search-input');
      $localSearchInput.attr("autocapitalize", "none");
      $localSearchInput.attr("autocorrect", "off");
      $localSearchInput.focus();
    }

    // search function;
    var searchFunc = function(path, search_id, content_id) {
      'use strict';

      // start loading animation
      $("body")
        .append('<div class="search-popup-overlay local-search-pop-overlay">' +
          '<div id="search-loading-icon">' +
          '<i class="fa fa-spinner fa-pulse fa-5x fa-fw"></i>' +
          '</div>' +
          '</div>')
        .css('overflow', 'hidden');
      $("#search-loading-icon").css('margin', '20% auto 0 auto').css('text-align', 'center');

      

      $.ajax({
        url: path,
        dataType: isXml ? "xml" : "json",
        async: true,
        success: function(res) {
          // get the contents from search data
          isfetched = true;
          $('.popup').detach().appendTo('.header-inner');
          var datas = isXml ? $("entry", res).map(function() {
            return {
              title: $("title", this).text(),
              content: $("content",this).text(),
              url: $("url" , this).text()
            };
          }).get() : res;
          var input = document.getElementById(search_id);
          var resultContent = document.getElementById(content_id);
          var inputEventFunction = function() {
            var searchText = input.value.trim().toLowerCase();
            var keywords = searchText.split(/[\s\-]+/);
            if (keywords.length > 1) {
              keywords.push(searchText);
            }
            var resultItems = [];
            if (searchText.length > 0) {
              // perform local searching
              datas.forEach(function(data) {
                var isMatch = false;
                var hitCount = 0;
                var searchTextCount = 0;
                var title = data.title.trim();
                var titleInLowerCase = title.toLowerCase();
                var content = data.content.trim().replace(/<[^>]+>/g,"");
                
                var contentInLowerCase = content.toLowerCase();
                var articleUrl = decodeURIComponent(data.url);
                var indexOfTitle = [];
                var indexOfContent = [];
                // only match articles with not empty titles
                if(title != '') {
                  keywords.forEach(function(keyword) {
                    function getIndexByWord(word, text, caseSensitive) {
                      var wordLen = word.length;
                      if (wordLen === 0) {
                        return [];
                      }
                      var startPosition = 0, position = [], index = [];
                      if (!caseSensitive) {
                        text = text.toLowerCase();
                        word = word.toLowerCase();
                      }
                      while ((position = text.indexOf(word, startPosition)) > -1) {
                        index.push({position: position, word: word});
                        startPosition = position + wordLen;
                      }
                      return index;
                    }

                    indexOfTitle = indexOfTitle.concat(getIndexByWord(keyword, titleInLowerCase, false));
                    indexOfContent = indexOfContent.concat(getIndexByWord(keyword, contentInLowerCase, false));
                  });
                  if (indexOfTitle.length > 0 || indexOfContent.length > 0) {
                    isMatch = true;
                    hitCount = indexOfTitle.length + indexOfContent.length;
                  }
                }

                // show search results

                if (isMatch) {
                  // sort index by position of keyword

                  [indexOfTitle, indexOfContent].forEach(function (index) {
                    index.sort(function (itemLeft, itemRight) {
                      if (itemRight.position !== itemLeft.position) {
                        return itemRight.position - itemLeft.position;
                      } else {
                        return itemLeft.word.length - itemRight.word.length;
                      }
                    });
                  });

                  // merge hits into slices

                  function mergeIntoSlice(text, start, end, index) {
                    var item = index[index.length - 1];
                    var position = item.position;
                    var word = item.word;
                    var hits = [];
                    var searchTextCountInSlice = 0;
                    while (position + word.length <= end && index.length != 0) {
                      if (word === searchText) {
                        searchTextCountInSlice++;
                      }
                      hits.push({position: position, length: word.length});
                      var wordEnd = position + word.length;

                      // move to next position of hit

                      index.pop();
                      while (index.length != 0) {
                        item = index[index.length - 1];
                        position = item.position;
                        word = item.word;
                        if (wordEnd > position) {
                          index.pop();
                        } else {
                          break;
                        }
                      }
                    }
                    searchTextCount += searchTextCountInSlice;
                    return {
                      hits: hits,
                      start: start,
                      end: end,
                      searchTextCount: searchTextCountInSlice
                    };
                  }

                  var slicesOfTitle = [];
                  if (indexOfTitle.length != 0) {
                    slicesOfTitle.push(mergeIntoSlice(title, 0, title.length, indexOfTitle));
                  }

                  var slicesOfContent = [];
                  while (indexOfContent.length != 0) {
                    var item = indexOfContent[indexOfContent.length - 1];
                    var position = item.position;
                    var word = item.word;
                    // cut out 100 characters
                    var start = position - 20;
                    var end = position + 80;
                    if(start < 0){
                      start = 0;
                    }
                    if (end < position + word.length) {
                      end = position + word.length;
                    }
                    if(end > content.length){
                      end = content.length;
                    }
                    slicesOfContent.push(mergeIntoSlice(content, start, end, indexOfContent));
                  }

                  // sort slices in content by search text's count and hits' count

                  slicesOfContent.sort(function (sliceLeft, sliceRight) {
                    if (sliceLeft.searchTextCount !== sliceRight.searchTextCount) {
                      return sliceRight.searchTextCount - sliceLeft.searchTextCount;
                    } else if (sliceLeft.hits.length !== sliceRight.hits.length) {
                      return sliceRight.hits.length - sliceLeft.hits.length;
                    } else {
                      return sliceLeft.start - sliceRight.start;
                    }
                  });

                  // select top N slices in content

                  var upperBound = parseInt('1');
                  if (upperBound >= 0) {
                    slicesOfContent = slicesOfContent.slice(0, upperBound);
                  }

                  // highlight title and content

                  function highlightKeyword(text, slice) {
                    var result = '';
                    var prevEnd = slice.start;
                    slice.hits.forEach(function (hit) {
                      result += text.substring(prevEnd, hit.position);
                      var end = hit.position + hit.length;
                      result += '<b class="search-keyword">' + text.substring(hit.position, end) + '</b>';
                      prevEnd = end;
                    });
                    result += text.substring(prevEnd, slice.end);
                    return result;
                  }

                  var resultItem = '';

                  if (slicesOfTitle.length != 0) {
                    resultItem += "<li><a href='" + articleUrl + "' class='search-result-title'>" + highlightKeyword(title, slicesOfTitle[0]) + "</a>";
                  } else {
                    resultItem += "<li><a href='" + articleUrl + "' class='search-result-title'>" + title + "</a>";
                  }

                  slicesOfContent.forEach(function (slice) {
                    resultItem += "<a href='" + articleUrl + "'>" +
                      "<p class=\"search-result\">" + highlightKeyword(content, slice) +
                      "...</p>" + "</a>";
                  });

                  resultItem += "</li>";
                  resultItems.push({
                    item: resultItem,
                    searchTextCount: searchTextCount,
                    hitCount: hitCount,
                    id: resultItems.length
                  });
                }
              })
            };
            if (keywords.length === 1 && keywords[0] === "") {
              resultContent.innerHTML = '<div id="no-result"><i class="fa fa-search fa-5x" /></div>'
            } else if (resultItems.length === 0) {
              resultContent.innerHTML = '<div id="no-result"><i class="fa fa-frown-o fa-5x" /></div>'
            } else {
              resultItems.sort(function (resultLeft, resultRight) {
                if (resultLeft.searchTextCount !== resultRight.searchTextCount) {
                  return resultRight.searchTextCount - resultLeft.searchTextCount;
                } else if (resultLeft.hitCount !== resultRight.hitCount) {
                  return resultRight.hitCount - resultLeft.hitCount;
                } else {
                  return resultRight.id - resultLeft.id;
                }
              });
              var searchResultList = '<ul class=\"search-result-list\">';
              resultItems.forEach(function (result) {
                searchResultList += result.item;
              })
              searchResultList += "</ul>";
              resultContent.innerHTML = searchResultList;
            }
          }

          if ('auto' === 'auto') {
            input.addEventListener('input', inputEventFunction);
          } else {
            $('.search-icon').click(inputEventFunction);
            input.addEventListener('keypress', function (event) {
              if (event.keyCode === 13) {
                inputEventFunction();
              }
            });
          }

          // remove loading animation
          $(".local-search-pop-overlay").remove();
          $('body').css('overflow', '');

          proceedsearch();
        }
      });
    }

    // handle and trigger popup window;
    $('.popup-trigger').click(function(e) {
      e.stopPropagation();
      if (isfetched === false) {
        searchFunc(path, 'local-search-input', 'local-search-result');
      } else {
        proceedsearch();
      };
    });

    $('.popup-btn-close').click(onPopupClose);
    $('.popup').click(function(e){
      e.stopPropagation();
    });
    $(document).on('keyup', function (event) {
      var shouldDismissSearchPopup = event.which === 27 &&
        $('.search-popup').is(':visible');
      if (shouldDismissSearchPopup) {
        onPopupClose();
      }
    });
  </script>





  

  

  
<script>
(function(){
    var bp = document.createElement('script');
    var curProtocol = window.location.protocol.split(':')[0];
    if (curProtocol === 'https') {
        bp.src = 'https://zz.bdstatic.com/linksubmit/push.js';        
    }
    else {
        bp.src = 'http://push.zhanzhang.baidu.com/push.js';
    }
    var s = document.getElementsByTagName("script")[0];
    s.parentNode.insertBefore(bp, s);
})();
</script>


  
  

  
  

  
    
      <script type="text/x-mathjax-config">
    MathJax.Hub.Config({
      tex2jax: {
        inlineMath: [ ['$','$'], ["\\(","\\)"]  ],
        processEscapes: true,
        skipTags: ['script', 'noscript', 'style', 'textarea', 'pre', 'code']
      },
      TeX: {equationNumbers: { autoNumber: "AMS" }}
    });
</script>

<script type="text/x-mathjax-config">
    MathJax.Hub.Queue(function() {
      var all = MathJax.Hub.getAllJax(), i;
        for (i=0; i < all.length; i += 1) {
          all[i].SourceElement().parentNode.className += ' has-jax';
        }
    });
</script>
<script type="text/javascript" src="//cdn.jsdelivr.net/npm/mathjax@2.7.1/MathJax.js?config=TeX-AMS-MML_HTMLorMML"></script>

    
  


  
  
  
  <script src="/lib/needsharebutton/needsharebutton.js"></script>

  <script>
    
      pbOptions = {};
      
          pbOptions.iconStyle = "box";
      
          pbOptions.boxForm = "horizontal";
      
          pbOptions.position = "bottomCenter";
      
          pbOptions.networks = "Weibo,Wechat,Douban,QQZone,Linkedin,Facebook";
      
      new needShareButton('#needsharebutton-postbottom', pbOptions);
    
    
  </script>

  

  

  

  

  

  

  <!-- 页面点击小红心 -->
	<script type="text/javascript" src="../js/src/love.js"></script><!-- hexo-inject:begin --><!-- Begin: Injected MathJax -->
<script type="text/x-mathjax-config">
  MathJax.Hub.Config({"tex2jax":{"inlineMath":[["$","$"],["\\(","\\)"]],"skipTags":["script","noscript","style","textarea","pre","code"],"processEscapes":true},"TeX":{"equationNumbers":{"autoNumber":"AMS"}}});
</script>

<script type="text/x-mathjax-config">
  MathJax.Hub.Queue(function() {
    var all = MathJax.Hub.getAllJax(), i;
    for(i=0; i < all.length; i += 1) {
      all[i].SourceElement().parentNode.className += ' has-jax';
    }
  });
</script>

<script type="text/javascript" src="https://cdnjs.cloudflare.com/ajax/libs/mathjax/2.7.1/MathJax.js">
</script>
<!-- End: Injected MathJax -->
<!-- hexo-inject:end -->
</body>
</html>
