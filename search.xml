<?xml version="1.0" encoding="utf-8"?>
<search>
  <entry>
    <title><![CDATA[简明的Python教程之NumPy]]></title>
    <url>%2F2018%2F10%2F10%2F%E7%AE%80%E6%98%8E%E7%9A%84Python%E6%95%99%E7%A8%8B%E4%B9%8BNumPy%2F</url>
    <content type="text"><![CDATA[摘要：Python作为一门简洁优美且功能强大的语言，越来越受编程人员的喜欢。在工业界和学术界也是非常受欢迎的编程语言。在python处理数据中，Numpy也是常有的工具，本文简要介绍，旨在大家熟悉相关应用。（本文原创，转载必须注明出处.） 导入相关的numpy包123456import numpyfrom numpy import arrayfrom numpy import mat,matrix # 导入矩阵包from numpy import shape # 查看矩阵或数组的方法from numpy import multiply # 元素相乘import random 计算方法向量求和12345def nu_add(): mm = array((1,1,1)) pp = array((2,2,2)) rr = mm + pp**3 # 数组的和运算 print(rr) 运行结果： [9 9 9] 矩阵相乘12345678def nu_matrix(): ss = mat([1,2,3]) # 矩阵 mm = matrix([1,2,3]) print('an element: '.title()+str(mm[0,0])) # 访问矩阵中的单个元素 print('Number of dimensions of mm '.title()+str(shape(mm))) print('mat is equal matrix: '.title()+str(ss==mm)) print('Matrix multiplication: '.title()+str(ss*mm.T)) # 矩阵相乘需要进行转置 print('Multiplication of elements： '.title()+str(multiply(mm,ss))) # mm每个元素和ss每个元素相乘 运行结果： An Element: 1 Number Of Dimensions Of Mm (1, 3) Mat Is Equal Matrix: [[ True True True]] Matrix Multiplication: [[14]] Multiplication Of Elements： [[1 4 9]] 列表转化成矩阵123456def nu_list_mat(): pylist = [1,2,3] rr = mat(pylist) # 列表转化成矩阵 print('list values: '.title()+str(pylist)) print('rr type: '.title()+str(type(rr))) print('mat values: '.title()+str(rr)) 运行结果： List Values: [1, 2, 3] Rr Type: &lt;class &#39;numpy.matrixlib.defmatrix.matrix&#39;&gt; Mat Values: [[1 2 3]] 矩阵求均值1234def nu_mean(): dd = mat([4,5,1]) rr = dd.mean() # 矩阵的均值 print('mean of dd: '.title()+ str(rr)) 运行结果： Mean Of Dd: 3.3333333333333335 矩阵维度12345def nu_mul_array(): jj = mat([[1,2,3],[8,8,8]]) print('Number of dimensions of jj '.title()+str(shape(jj))) one_row = jj[1,0:2] print(one_row) 运行结果： Number Of Dimensions Of Jj (2, 3) [[8 8]] 矩阵转置1234def nu_tran_mat(): # 矩阵转置 radMat = numpy.random.random((3,3)) print('Before matrix transposition:\n '+str(radMat)) print('After matrix transposition:\n '+str(radMat.T)) 运行结果： Before matrix transposition: [[0.44400432 0.39811184 0.15014053] [0.33399525 0.35953194 0.92571106] [0.3307816 0.38282677 0.01282852]] After matrix transposition: [[0.44400432 0.33399525 0.3307816 ] [0.39811184 0.35953194 0.38282677] [0.15014053 0.92571106 0.01282852]] 矩阵的逆1234def nu_inverse_mat(): # 矩阵的逆 radMat = numpy.random.random((3,3)) print('Before matrix inverse:\n '+str(radMat)) print('After matrix inverse:\n '+str(mat(radMat).I)) 运行结果： Before matrix inverse: [[0.67119611 0.28502048 0.00101008] [0.66644679 0.61934535 0.39481694] [0.10938817 0.22939074 0.45364209]] After matrix inverse: [[ 3.52467918 -2.38933642 2.07165582] [-4.79734922 5.63471564 -4.89336308] [ 1.57593243 -2.27312782 4.17923641]] 矩阵与逆矩阵相乘12345def nu_mat_mul_imat(): # 矩阵与其逆矩阵相乘 bmat = mat(numpy.random.random((3,3))) imat = bmat.I rus = bmat * imat print(rus) # 结果是3*3的单位矩阵，其位置原则应该都是0，实际中是非常小的数，这个计算机处理的问题 运行结果： [[ 1.00000000e+00 -2.23066267e-17 -3.47038713e-17] [-7.97119302e-17 1.00000000e+00 1.74271619e-17] [-3.16553513e-16 -8.86129567e-17 1.00000000e+00]] 参考文献 Python官网 中文维基百科 GitHub 图书：《机器学习实战》 图书：《自然语言处理理论与实战》 完整代码下载 源码请进【机器学习和自然语言QQ群：436303759】文件下载： 作者声明 本文版权归作者【白宁超】所有，转载请联系作者：1938036263@qq.com，但未经作者同意禁止转载，转载后需在文章页面明显位置给出原文连接，否则保留追究法律责任的权利。]]></content>
      <categories>
        <category>Python</category>
        <category>NumPy</category>
      </categories>
      <tags>
        <tag>Python</tag>
        <tag>NumPy</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[简明的Python教程之matplotlib可视化]]></title>
    <url>%2F2018%2F10%2F10%2F%E7%AE%80%E6%98%8E%E7%9A%84Python%E6%95%99%E7%A8%8B%E4%B9%8Bmatplotlib%E5%8F%AF%E8%A7%86%E5%8C%96%2F</url>
    <content type="text"><![CDATA[摘要：Python作为一门简洁优美且功能强大的语言，越来越受编程人员的喜欢。在工业界和学术界也是非常受欢迎的编程语言。在python处理数据中，需要数据分析，我们直面冷冰冰的数值或者信息很难得到直观的感受，如果借助图形化分析，常常可以一目了然，所谓一图胜千言就是这个意思。本文对可视化库matplotlib介绍，方便大家掌握。（本文原创，转载必须注明出处.） matplotlib绘制折线图绘制y=2x+1的折线图1234567891011121314151617181920212223242526import matplotlibimport matplotlib.pyplot as plt#加入中文显示import matplotlib.font_manager as fm# 解决中文乱码，本案例使用宋体字myfont=fm.FontProperties(fname=r"C:\\Windows\\Fonts\\simsun.ttc")def line_chart(xvalues,yvalues): # 绘制折线图,c颜色设置，alpha透明度 plt.plot(xvalues,yvalues,linewidth=5,alpha=0.5,c='red') # num_squares数据值，linewidth设置线条粗细 # 设置折线图标题和横纵坐标标题 plt.title("Python绘制折线图",fontsize=30,fontname='宋体',fontproperties=myfont) plt.xlabel('横坐标',fontsize=20,fontname='宋体',fontproperties=myfont) plt.ylabel('纵坐标',fontsize=20,fontname='宋体',fontproperties=myfont) # 设置刻度标记大小,axis='both'参数影响横纵坐标，labelsize刻度大小 plt.tick_params(axis='both',labelsize=10) # 显示图形 plt.show()if __name__ == "__main__": # 1 打印y=2X+1 的折线图 line_chart([0,2,3,4,5],[1,7,10,13,16]) 运行结果 matplotlib绘制散点图绘制y=2x+1的散点图1234567891011121314151617181920212223242526272829303132import matplotlibimport matplotlib.pyplot as plt#加入中文显示import matplotlib.font_manager as fm# 解决中文乱码，本案例使用宋体字myfont=fm.FontProperties(fname=r"C:\\Windows\\Fonts\\simsun.ttc")def scatter_chart(xvalues,yvalues): # 绘制散点图，s设置点的大小,c数据点的颜色，edgecolors数据点的轮廓 plt.scatter(xvalues,yvalues,c='green',edgecolors='none',s=40) # 设置散点图标题和横纵坐标标题 plt.title("Python绘制折线图",fontsize=30,fontname='宋体',fontproperties=myfont) plt.xlabel('横坐标',fontsize=20,fontname='宋体',fontproperties=myfont) plt.ylabel('纵坐标',fontsize=20,fontname='宋体',fontproperties=myfont) # 设置刻度标记大小,axis='both'参数影响横纵坐标，labelsize刻度大小 plt.tick_params(axis='both',which='major',labelsize=10) # 设置每个坐标轴取值范围 # plt.axis([80,100,6400,10000]) # 显示图形 plt.show() # 自动保存图表,bbox_inches剪除图片空白区 # plt.savefig('squares_plot.png',bbox_inches='tight')if __name__ == "__main__": # 1 绘制y=2X+1 的折线图 scatter_chart([0,2,3,4,5],[1,7,10,13,16]) 运行结果 matplotlib读取csv文件显示折线图加利福尼亚死亡谷日气温最高最低图123456789101112131415161718192021222324252627282930313233343536373839404142434445464748import csvfrom datetime import datetimefrom matplotlib import pyplot as pltimport matplotlib as mpl# 解决中文乱码问题mpl.rcParams['font.sans-serif']=['SimHei']mpl.rcParams['axes.unicode_minus']=False# Get dates, high, and low temperatures from file.filename = 'death_valley_2014.csv'with open(filename) as f: reader = csv.reader(f) header_row = next(reader) # print(header_row) # for index,column_header in enumerate(header_row): # print(index,column_header) dates, highs,lows = [],[], [] for row in reader: try: current_date = datetime.strptime(row[0], "%Y-%m-%d") high = int(row[1]) low = int(row[3]) except ValueError: # 处理 print(current_date, 'missing data') else: dates.append(current_date) highs.append(high) lows.append(low)# 汇制数据图形fig = plt.figure(dpi=120,figsize=(10,6))plt.plot(dates,highs,c='red',alpha=0.5)# alpha指定透明度plt.plot(dates,lows,c='blue',alpha=0.5)plt.fill_between(dates,highs,lows,facecolor='orange',alpha=0.1)#接收一个x值系列和y值系列，给图表区域着色#设置图形格式plt.title('2014年加利福尼亚死亡谷日气温最高最低图',fontsize=24)plt.xlabel('日（D）',fontsize=16)fig.autofmt_xdate() # 绘制斜体日期标签plt.ylabel('温度（F）',fontsize=16)plt.tick_params(axis='both',which='major',labelsize=16)# plt.axis([0,31,54,72]) # 自定义数轴起始刻度plt.savefig('highs_lows.png',bbox_inches='tight')plt.show() 运行结果 matplotlib生成随机漫步图随机数据生成123456789101112131415161718192021222324252627282930313233from random import choiceclass RandomWalk(): '''一个生成随机漫步数据的类''' def __init__(self,num_points=5000): '''初始化随机漫步属性''' self.num_points = num_points self.x_values = [0] self.y_values = [0] def fill_walk(self): '''计算随机漫步包含的所有点''' while len(self.x_values)&lt;self.num_points: # 决定前进方向及沿着该方向前进的距离 x_direction = choice([1,-1]) x_distance = choice([0,1,2,3,4]) x_step = x_direction*x_distance y_direction = choice([1,-1]) y_distance = choice([0,1,2,3,4]) y_step = y_direction*y_distance # 拒绝原地踏步 if x_step == 0 and y_step == 0: continue # 计算下一个点的x和y next_x = self.x_values[-1] + x_step next_y = self.y_values[-1] + y_step self.x_values.append(next_x) self.y_values.append(next_y) 生成随机漫步图123456789101112131415161718192021222324252627282930313233343536#-*- coding: utf-8 -*-#coding=utf-8import matplotlib as mplimport matplotlib.pyplot as pltimport pylabfrom random_walk import RandomWalk# 解决中文乱码问题mpl.rcParams['font.sans-serif']=['SimHei']mpl.rcParams['axes.unicode_minus']=False# 创建RandomWalk实例rw = RandomWalk()rw.fill_walk()plt.figure(figsize=(10,6))point_numbers = list(range(rw.num_points))# 随着点数的增加渐变深红色plt.scatter(rw.x_values,rw.y_values,c=point_numbers,cmap=plt.cm.Reds,edgecolors='none',s=1)# 设置起始点和终点颜色plt.scatter(0,0,c='green',edgecolors='none',s=100)plt.scatter(rw.x_values[-1],rw.y_values[-1],c='blue',edgecolors='none',s=100)# 设置标题和纵横坐标plt.title('随机漫步图',fontsize=24)plt.xlabel('左右步数',fontsize=14)plt.ylabel('上下步数',fontsize=14)# 隐藏坐标轴plt.axes().get_xaxis().set_visible(False)plt.axes().get_yaxis().set_visible(False)plt.show() 运行结果 matplotlib绘制世界各国人口统计图绘制世界各国人口统计图123456789101112131415161718192021222324252627282930313233343536373839404142434445464748495051525354555657585960#conding = utf-8import jsonfrom matplotlib import pyplot as pltimport matplotlib as mplfrom country_codes import get_country_codeimport pygalfrom pygal.style import RotateStylefrom pygal.style import LightColorizedStyle# 解决中文乱码问题mpl.rcParams['font.sans-serif']=['SimHei']mpl.rcParams['axes.unicode_minus']=False# 加载json数据filename='population_data.json'with open(filename) as f: pop_data = json.load(f) # print(pop_data[1])# 创建一个包含人口的字典cc_populations=&#123;&#125;# cc1_populations=&#123;&#125;# 打印每个国家2010年的人口数量for pop_dict in pop_data: if pop_dict['Year'] == '2010': country_name = pop_dict['Country Name'] population = int(float(pop_dict['Value'])) # 字符串数值转化为整数 # print(country_name + ":" + str(population)) code = get_country_code(country_name) if code: cc_populations[code] = population # elif pop_dict['Year'] == '2009': # country_name = pop_dict['Country Name'] # population = int(float(pop_dict['Value'])) # 字符串数值转化为整数 # # print(country_name + ":" + str(population)) # code = get_country_code(country_name) # if code: # cc1_populations[code] = populationcc_pops_1,cc_pops_2,cc_pops_3=&#123;&#125;,&#123;&#125;,&#123;&#125;for cc,pop in cc_populations.items(): if pop &lt;10000000: cc_pops_1[cc]=pop elif pop&lt;1000000000: cc_pops_2[cc]=pop else: cc_pops_3[cc]=pop# print(len(cc_pops_1),len(cc_pops_2),len(cc_pops_3))wm_style = RotateStyle('#336699',base_style=LightColorizedStyle)wm =pygal.maps.world.World(style=wm_style)wm.title = '2010年世界各国人口统计图'wm.add('0-10m', cc_pops_1)wm.add('10m-1bm',cc_pops_2)wm.add('&gt;1bm',cc_pops_3)# wm.add('2009', cc1_populations)wm.render_to_file('world_populations.svg') 运行结果 matplotlib绘制直方图绘制带有详细信息的直方图1234567891011121314151617import pygalfrom pygal.style import LightColorizedStyle as LCS, LightenStyle as LSmy_style = LS('#333366', base_style=LCS)chart = pygal.Bar(style=my_style, x_label_rotation=45, show_legend=False)chart.title = 'Python Projects'chart.x_labels = ['httpie', 'django', 'flask']plot_dicts = [ &#123;'value': 16101, 'label': 'Description of httpie.'&#125;, &#123;'value': 15028, 'label': 'Description of django.'&#125;, &#123;'value': 14798, 'label': 'Description of flask.'&#125;, ]chart.add('', plot_dicts)chart.render_to_file('bar_descriptions.svg') 运行结果 绘制两次随机骰子的直方图12345678910111213141516171819202122232425262728293031323334353637#coding=utf-8from die import Dieimport pygalimport matplotlib as mpl# 解决中文乱码问题mpl.rcParams['font.sans-serif']=['SimHei']mpl.rcParams['axes.unicode_minus']=Falsedie1 = Die()die2 = Die()results = []for roll_num in range(1000): result =die1.roll()+die2.roll() results.append(result)# print(results)# 分析结果frequencies = []max_result = die1.num_sides+die2.num_sidesfor value in range(2,max_result+1): frequency = results.count(value) frequencies.append(frequency)print(frequencies)# 直方图hist = pygal.Bar(figsize=(8,6))hist.title = '骰子投掷1000次各面结果统计图'hist.x_labels =[x for x in range(2,max_result+1)]hist.x_title ='结果'hist.y_title = '结果分布'hist.add('D6+D6',frequencies)hist.render_to_file('die_visual.svg')# hist.show() 运行结果 matplotlib：Github最受欢迎的星标项目可视化Github最受欢迎的星标项目可视化1234567891011121314151617181920212223242526272829303132333435363738394041424344454647484950515253545556# coding=utf-8import requestsimport pygalfrom pygal.style import LightColorizedStyle as LCS, LightenStyle as LS# Make an API call, and store the response.url = 'https://api.github.com/search/repositories?q=language:python&amp;sort=stars'r = requests.get(url)print("Status code:", r.status_code) # 查看请求是否成功，200表示成功response_dict = r.json()# print(response_dict.keys())print("Total repositories:", response_dict['total_count'])# Explore information about the repositories.repo_dicts = response_dict['items']print("Repositories returned:",len(repo_dicts))# 查看项目信息# repo_dict =repo_dicts[0]# print('\n\neach repository:')# for repo_dict in repo_dicts:# print("\nName:",repo_dict['name'])# print("Owner:",repo_dict['owner']['login'])# print("Stars:",repo_dict['stargazers_count'])# print("Repository:",repo_dict['html_url'])# print("Description:",repo_dict['description'])# 查看每个项目的键# print('\nKeys:',len(repo_dict))# for key in sorted(repo_dict.keys()):# print(key)names, plot_dicts = [], []for repo_dict in repo_dicts: names.append(repo_dict['name']) plot_dicts.append(repo_dict['stargazers_count'])# 可视化my_style = LS('#333366', base_style=LCS)my_config = pygal.Config() # Pygal类Config实例化my_config.x_label_rotation = 45 # x轴标签旋转45度my_config.show_legend = False # show_legend隐藏图例my_config.title_font_size = 24 # 设置图标标题主标签副标签的字体大小my_config.label_font_size = 14my_config.major_label_font_size = 18my_config.truncate_label = 15 # 较长的项目名称缩短15字符my_config.show_y_guides = False # 隐藏图表中的水平线my_config.width = 1000 # 自定义图表的宽度chart = pygal.Bar(my_config, style=my_style)chart.title = 'Most-Starred Python Projects on GitHub'chart.x_labels = nameschart.add('', plot_dicts)chart.render_to_file('python_repos.svg') 运行结果 参考文献 Python官网 中文维基百科 GitHub 图书：《机器学习实战》 图书：《自然语言处理理论与实战》 完整代码下载 源码请进【机器学习和自然语言QQ群：436303759】文件下载： 作者声明 本文版权归作者【白宁超】所有，转载请联系作者：1938036263@qq.com，但未经作者同意禁止转载，转载后需在文章页面明显位置给出原文连接，否则保留追究法律责任的权利。]]></content>
      <categories>
        <category>Python</category>
        <category>matplotlib</category>
      </categories>
      <tags>
        <tag>Python</tag>
        <tag>matplotlib</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[简明的Python教程之70个常备知识点]]></title>
    <url>%2F2018%2F10%2F10%2F%E7%AE%80%E6%98%8E%E7%9A%84Python%E6%95%99%E7%A8%8B%E4%B9%8B70%E4%B8%AA%E5%B8%B8%E5%A4%87%E7%9F%A5%E8%AF%86%E7%82%B9%2F</url>
    <content type="text"><![CDATA[摘要：Python作为一门简洁优美且功能强大的语言，越来越受编程人员的喜欢。在工业界和学术界也是非常受欢迎的编程语言。在阅读python相关书籍中，对其进行简单的笔记记录。旨在注意一些细节问题，在今后项目中灵活运用，并对部分小知识点进行代码标注。（本文原创，转载必须注明出处.） 1 python始终记录变量最新值。2 变量应简短且具有描述性，如student_name等。3 变量名推荐小写。4 单双引号括起来的，字符串可以包含引号和撇号。用法：”this’s a cup”5 title()将每个单词的首字母都改为大写。用法：str.title()6 upper()将字符串转化为大写。用法：str.upper()7 lower()将字符串转化为小写。用法：str.lower()8 空白泛指任何非打印字符。如空格、制表符和换行符。9 rstrip()剔除字符串末尾空白。用法：str.rstrip()10 lstrip()剔除字符串开头空白。用法：str.lstrip()11 strip()剔除字符串两端空白。用法：str.strip()12 Python使用两个称号表示乘方。用法：3 ** 213 编程理念。Python之禅：import this14 list中使用逗号来分割其中的元素。15 list索引-1返回最后一个元素列表，-2以此类推。用法：list[-3:]16 list[0] = ‘update’ 修改列表元素17 list.append(‘add’) 列表中添加元素18 list.insert(0.’insert’) 列表中指定位置插入元素19 del list[0] del元素删除list元素20 newlist = list.pop()方法pop()删除元素21 从列表中删除元素且不再使用用del方法，删除元素后还有可能用选择pop()22 list.remove(‘element’) 根据值移除第一个指定的元素，可接着使用。23 sort()列表按照字母永久性排序。如：list.sort()24 sort()列表按照字母相反的排序。如：list.sort(reverse=True)25 reverse() 反转列表元素排序。用法：list.reverse()26 for循环遍历时候选择有意义的名称。用法： for cat in cats:27 range() 生成一系列数字。用法： numbers= list(range(1,11,2))28 list的内建统计函数。用法：min(list)/max(list)/sum(list)29 python的切片功能。用法： list[0:3]/list[:]/list[-3:]/list[:9]30 list复制。用法：new_foods = old_food[:]31 元组包括一些列不可修改的元素且用圆括号标识。用法：tulple = (2,3)32 检查是否相等时不考虑大小写。用法：str.lower() == ‘somestr’33 使用and检查多个条件。用法：condition1&gt;=1 and condition2&gt;=2 and …34 使用or检查多个条件。用法：condition1&gt;=1 or condition2&gt;=2 or …35 使用多个列表。用法： 1234567list1 = ['1','2','3','4']list2 = ['1','4']for l2 in list2: if l2 in list1: go() else: pass 36 比较运算符两边各添加空格，便于可读性。用法：if age &gt; 40：37 dict修改值，用法：dict[‘key’] = value38 dict删除键值对，用法： del dict[‘key’]39 字典的遍历，用法：12345for key,value in dict.items():for key in dict:for key in dict.keys():for value in dict.values():for value in set(dict.values()): # 遍历字典的无重复值 40 字典列表，用法： 12345678dict1 = ['key1':'values1','key2':'values2']dict2 = ['key1':'values3','key2':'values4']dict3 = ['key1':'values5','key2':'values6'] dicts = [dict1,dict2,dict3] for dict in dicts: pass 41 字典中存储列表，用法：12345678910111213141516171819dict1 = &#123;'key1':'values1','key2':['values1','values2']&#125;for dict in dict1['key2']:``` 42 字典中存储字典，用法：```pythondicts = &#123;'keys1':&#123;'key1':'values1'，'key1':'values2''key1':'values3'&#125;,'keys2':&#123;'key2':'values2'，'key2':'values2''key2':'values3'&#125;&#125;``` 43 input接收用户输入，用法：message = input('user input some values!')44 %取模运算判断奇偶，用法：```pythonif (4 % 3) == 0: print('偶数')：else: print('奇数') 45 while循环的常规用法： 1234567891011current_number = 1while current_number &lt;= 10: print('current_number') current_number += 1``` 46 while循环使用标志的用法：```pythonflag = Truewhile flag: message = input(prompt) 47 列表之间移动元素，用法： 12while list[]: newlist.append(list[].pop()) 48 删除特定的元素，用法： 12while element in list: list.remove(element) 49 形参与实参的理解，用法： 123456789def method(username): # username形参method('zhangsan') # zhangsan实参``` 50 位置参数，用法：```pythondef describe(name,age):describe('zhangsan',22) # 参数位置对应传递 51 关键字实参是传递函数的名称-值对，用法： 123def describe(name,age):describe(name='zhangsan',age=22) # 关键字实参describe(age=22,name='zhangsan') # 关键字实参,位置不重要 52 形参设置默认值，用法：def describe(name=’lisi’,age):53 返回值，用法： 123456789101112131415161718192021222324252627def describe(name='lisi',age): des = name + str(age)return des # 可以返回字典、列表等形式``` 54 列表参数，用法：```pythonlists = ['huangsan','lisi','wangjun','denghui']def cats_name(lists): for list in lists: print("'my love is :\t'+list".title())``` 55 传递任意参数，用法：def cats_name(*cats): # 可以传递多个形参56 位置实参和任意数量实参：```pythondef cats_name(parament1,parament2,*cats): # 可以传递多个形参cats_name(para1,para2,para3,para4,...)``` 57 任意实参和关键字实参，用法：(cats.py)```pythondef cats_name(parament1,parament2,**cats): # 可以传递多个形参cats_name(para1,para2,para3,newname=para4,...) 58 导入整个模块，用法： 12345678910111213141516171819202122232425262728293031323334353637import catscats.cats_name(para1,para2,para3,newname=para4,...)``` 59 导入特定的函数,用法：from nltk import map_tag as mt60 导入模块所有函数,用法：from nltk import *61 形参默认时，两边不能为空，用法：def function_name(parament_0,parament_1='default')62 类的命名是驼峰型即首字母大写。63 __init__(self,papa1,para2):避免python默认方法跟普通方法名称冲突,self必不可少，必须位于其他形参的前面，指向实例本身。64 类的继承，用法：```python# 父类class Animal(): def __init__(self,name,age): self.name = name self.age = age def animal_call(self): print('this is '+self.name.title()+' call.') # 子类class Cat(Animal): def __init__(self,name,age,color): super().__init__(name,age) self.color =color def cat_color(self): my_color = 'the cat is '+self.color print(my_color) return my_color if __name__ == '__main__': cat = Cat('tom',22,'blue') cat.animal_call() strs=cat.cat_color() 65 几种类的导入方式，用法： 1234from cat import Cat # 导入单个类from cat import Animal,Cat # 导入多个类from cat # 导入整个模块from cat import * # 导入所有类 66 读取文本文件，并删除字符串始末空白，用法：my_str = line.strip()67 opem()自动创建文件路径，若路径不存在时候。68 异常代码块：try-except69 split()创建单词列表123str = 'this is a string'str.split()['this','is','a','string'] 70 存储数据json.dump()和json.load()123456789101112131415161718192021222324252627282930313233343536import json # 父类class Animal(): def __init__(self,name,age): self.name = name self.age = age def animal_call(self): print('this is '+self.name.title()+' call.') # 子类class Cat(Animal): def __init__(self,name,age,color): super().__init__(name,age) self.color =color def cat_color(self): my_color = 'the cat is '+self.color print(my_color) return my_color if __name__ == '__main__': cat = Cat('tom',22,'blue') cat.animal_call() strs=cat.cat_color() filename = r'../AllProject/V4.0EngInfoExtract/Document/EnPapers_single/test.json' with open(filename,'w') as f_obj: json.dump(strs,f_obj) with open(filename,'r') as f_obj: strs = json.load(f_obj) print(strs) 参考文献 Python官网 中文维基百科 GitHub 图书：《机器学习实战》 图书：《自然语言处理理论与实战》 完整代码下载 源码请进【机器学习和自然语言QQ群：436303759】文件下载： 作者声明 本文版权归作者【白宁超】所有，转载请联系作者：1938036263@qq.com，但未经作者同意禁止转载，转载后需在文章页面明显位置给出原文连接，否则保留追究法律责任的权利。]]></content>
      <categories>
        <category>Python</category>
      </categories>
      <tags>
        <tag>Python</tag>
        <tag>Django</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[简明的Python教程之网站篇]]></title>
    <url>%2F2018%2F10%2F10%2F%E7%AE%80%E6%98%8E%E7%9A%84Python%E6%95%99%E7%A8%8B%E4%B9%8B%E7%BD%91%E7%AB%99%E7%AF%87%2F</url>
    <content type="text"><![CDATA[摘要：Python作为一门简洁优美且功能强大的语言，越来越受编程人员的喜欢。在工业界和学术界也是非常受欢迎的编程语言。python语言可以跨平台跨应用开发。本系列文章首先介绍Python语言及其可以做什么事情。哪些人群适合学习python和python语法特点。其次介绍了Python进阶，以实际案例演示常用的语句和控制流、表达式、函数、数据结构、标准库等知识点。然后扩展介绍了python第三方库，使读者对python有个全面的理解和认识。最后一节，采用实际案例帮助读者综合运用python知识。 （本文原创，转载必须注明出处.） Django搞定用户管理系统Django是什么Django是一个开放源代码的Web应用框架，由Python写成。采用了MVC的软件设计模式，即模型M，视图V和控制器C。它最初是被开发来用于管理劳伦斯出版集团旗下的一些以新闻内容为主的网站的。并于2005年7月在BSD许可证下发布。这套框架是以比利时的吉普赛爵士吉他手Django Reinhardt来命名的。 Django的主要目标是使得开发复杂的、数据库驱动的网站变得简单。Django注重组件的重用性和“可插拔性”，敏捷开发和DRY法则（Don’t Repeat Yourself）。在Django中Python被普遍使用，甚至包括配置文件和数据模型。 Django开发模型Django是一个基于MVC构造的框架。但是在Django中，控制器接受用户输入的部分由框架自行处理，所以 Django 里更关注的是模型（Model）、模板(Template)和视图（Views），称为 MTV模式。它们各自的职责如图所示： 模型（Model），即数据存取层 处理与数据相关的所有事务： 如何存取、如何验证有效性、包含哪些行为以及数据之间的关系等。 视图（View），即表现层 处理与表现相关的决定： 如何在页面或其他类型文档中进行显示。 模板(Template)，即业务逻辑层 存取模型及调取恰当模板的相关逻辑。模型与模板的桥梁。 Django的架构让我们一览 Django 全貌： urls.py 网址入口，关联到对应的views.py中的一个函数（或者generic类），访问网址就对应一个函数。 views.py 处理用户发出的请求，从urls.py中对应过来, 通过渲染templates中的网页可以将显示内容，比如登陆后的用户名，用户请求的数据，输出到网页。 models.py 与数据库操作相关，存入或读取数据时用到这个，当然用不到数据库的时候 你可以不使用。 forms.py 表单，用户在浏览器上输入数据提交，对数据的验证工作以及输入框的生成等工作，当然你也可以不使用。 templates 文件夹 views.py 中的函数渲染templates中的Html模板，得到动态内容的网页，当然可以用缓存来提高速度。 admin.py 后台，可以用很少量的代码就拥有一个强大的后台。 settings.py Django 的设置，配置文件，比如 DEBUG 的开关，静态文件的位置等。 上面的py文件不理解也没有关系，后面会详细介绍。一图胜千言，架构全貌工作机制如图所示： Django商业网站Sohu 邮箱 、果壳网 、 豆瓣 、 爱调研 、 易度在线云办公 、 优容网 、 快玩游戏、九九房、贷帮网 、 趣奇网 、知乎、时尚时空 、游嘻板: YxPad webpy、DNSPod 国际版 、下厨房 、 贝太厨房 、 Wopus问答 、 咕咚网 、扇贝网 、站长工具、易度文档管理系统、个人租房、 在线文档查看-易度云查看 、 FIFA310 足球数据分析专家、 搜狐随身看等等。 Django安装配置前置条件 假设读者具备Python、web开发、html、css、js、SQL基础。 Anaconda(包含pip和python插件)、sublime环境已经安装。其中pip用来在线安装工具包。 系统环境：WIN10 64bit 开发环境：sublime+Anaconda 数据库：Mysql 5.6.17 语言：python3.5 框架：django1.11 通过“Win+R”键打开运行对话框，输入“pip”查看是否安装成功。如果pip输入报错，则需要自行下载安装即可。如果成功安装如图所示： 在线安装Django通过“Win+R”键打开运行对话框，输入“pip install django”代码，自动运行结束后。打开Sublime编辑器，点击“F6”切换的编辑环境，输入如下代码查看django是否安装成功。 123&gt;&gt;&gt; import django&gt;&gt;&gt; django.VERSION(1, 11, 0, 'final', 1) 创建用户管理项目创建项目和App 第一步 通过“Win+R”键打开运行对话框，并在电脑的E盘根目录下创建名为UserProject的项目,输入如下创建命名： 1django-admin startproject xmjc_analysis 命令执行完成，通过Sublime Text3打开菜单“File-&gt;Open Folder”选择刚刚创建的UserProject文件夹，如图所示： settings.py 项目的设置文件 urls.py 总的urls配置文件 wsgi.py 部署服务器文件 init.py python包的目录结构必须的，与调用有关 第二步 进入UserProject文件夹下创建App名为myuser，执行如下命令，命令成功后如图所示：1django-admin startapp myuser 一个项目可以包含多个App，执行完app创建命令后，打开项目查看如图所示： admin.py 后台，可以用很少量的代码就拥有一个强大的后台。 apps.py 本app项目名称等配置。 models.py 与数据库操作相关，存入或读取数据时用到这个，当然用不到数据库的时候 你可以不使用。 tests.py 单元测试文件 views.py 处理用户发出的请求，从urls.py中对应过来, 通过渲染templates中的网页可以将显示内容，比如登陆后的用户名，用户请求的数据，输出到网页。 第三步 将新定义名为“myuser”的app添加到UserProject项目中。修改UserProject/UserProject/settings.py代码如下：12345678910111213# Application definitionINSTALLED_APPS = [ 'django.contrib.admin', 'django.contrib.auth', 'django.contrib.contenttypes', 'django.contrib.sessions', 'django.contrib.messages', 'django.contrib.staticfiles', # 添加新建app 'myuser',] 到此，完成项目的创建和app的添加。是不是很简单，下面我们创建一个新的欢迎界面。 第一个欢迎页面1 在myuser文件夹下，打开UserProject/myuser/views.py文件,修改里面的代码如下： 1234567891011'''第一个页面author：白宁超site：http://www.cnblogs.com/baiboy/'''#coding:utf-8from django.shortcuts import renderfrom django.http import HttpResponsedef index(request): return HttpResponse(u"欢迎进入第一个Django页面!") 第一行是声明编码为utf-8, 因为我们在代码中用到了中文,如果不声明就报错.第二行引入HttpResponse，它是用来向网页返回内容的，就像Python中的 print 一样，只不过 HttpResponse 是把内容显示到网页上。我们定义了一个index()函数，第一个参数必须是 request，与网页发来的请求有关，request 变量里面包含get或post的内容。 2 我们打开UserProject/UserProject/urls.py 这个文件, 修改其中的代码 12345678910111213from django.conf.urls import urlfrom django.contrib import admin# 导入myuser下的视图文件from myuser import views as myuser_viewsurlpatterns = [ # 第一个欢迎界面的配置 url(r'^index/$', myuser_views.index,name='index'), url(r'^admin/', admin.site.urls),] 3 在UserProject目录下输入“python manage.py runserver”命令本地运行服务器，如图所示： 4 将上图的本地网址复制到浏览器访问，本地网址后面输入刚刚配置的方法名“index”即可访问我们刚刚设计的网页。如图所示： 带参数的欢迎页面 打开UserProject/myuser/views.py文件,修改里面的代码如下： 12345678910111213'''#coding:utf-8from django.shortcuts import renderfrom django.http import HttpResponse# 访问第一个页面def index(request): return HttpResponse(u"欢迎进入第一个Django页面!")# 访问第一个带参数的页面def indexPara(request): name = request.GET['name'] return HttpResponse(u"欢迎进入\t"+name+",第一个Django页面!") 我们打开UserProject/UserProject/urls.py 这个文件, 修改其中的代码 1234567891011121314from django.conf.urls import urlfrom django.contrib import admin# 导入myuser下的视图文件from myuser import views as myuser_viewsurlpatterns = [ # 带参数的欢迎界面的配置 url(r'^para/$', myuser_views.indexPara,name='para'), # 第一个欢迎界面的配置 url(r'^index/$', myuser_views.index,name='index'), url(r'^admin/', admin.site.urls),] 如果服务器关闭，需要如上方法重新打开。反之，直接输入网址查看，如图所示： 单数据库配置 在UserProject/UserProject/settings.py文件下,默认sqlites数据库，现在假设项目需求是mysql数据库。具体修改如下： 1234567891011121314151617181920# Database# https://docs.djangoproject.com/en/1.11/ref/settings/#databasesDATABASES = &#123; # 配置默认为mysql数据库 'default': &#123; 'ENGINE': 'django.db.backends.mysql', # 设置数据库引擎 'NAME': 'test', # 数据库名 'USER': 'test', # 数据库登陆名 'PASSWORD': 'test123', # 数据库登陆密码 'HOST':'localhost', # 数据库服务器IP，默认设置本地 'PORT':'3306', # 端口号 &#125;, # 默认配置为sqlite3数据库 # 'default': &#123; # 'ENGINE': 'django.db.backends.sqlite3', # 'NAME': os.path.join(BASE_DIR, 'db.sqlite3'), # &#125;&#125; UserProject/UserProject/ init.py文件添加如下代码：12import pymysqlpymysql.install_as_MySQLdb() 在UserProject/myuser/models.py下设计数据库表，采用ORM方式，完整代码如下： 1234567891011from django.db import models # Create your models here.class User(models.Model): username = models.CharField('用户名', max_length=30) userpass = models.CharField('密码',max_length=30) useremail = models.EmailField('邮箱',max_length=30) usertype = models.CharField('用户类型',max_length=30) def __str__(self): return self.username 在analysis/admin.py中定义显示数据 1234567from django.contrib import adminfrom .models import User class UserAdmin(admin.ModelAdmin): list_display = ('username','userpass','useremail') # 自定义显示字段 admin.site.register(User,UserAdmin) 打开对话框，在“UserProject”下将生成的py文件应用到mysql数据库。输入如下命令：12python manage.py makemigrationspython manage.py migrate 创建超级管理员：用户名，admin1；密码密码：admin123，如图所示1python manage.py createsuperuser 创建后台超级管理员 创建后台超级管理员 登录后台查看信息 可以看到后台信息，并对数据表进行增删改查操作，但是后台全部英文如图示，可以改为中文显示？ 后台管理设置为中文显示,UserProject/UserProject/settings.py下修改代码： LANGUAGE_CODE = 'zh-Hans' # 中文显示再去查看： Django数据库操作QuerySet API，shell玩转MySql在UserProject项目下输入【 python manage.py shell】，然后查询数据表如图所示： 创建一条用户信息，输入如下shell命令：1User.objects.create(username="李白", userpass="libai123",useremail="libai@163.com",usertype="超级管理员") 登录项目后台查看，如图所示。1![](https://i.imgur.com/tDHK2vF.png) 其他shell操作语句12345678910111213141516171819202122232425262728# 方法 1User.objects.create(username="李白", userpass="libai123",useremail="libai@163.com",usertype="超级管理员")# 方法 2twz =User(username="李白", userpass="libai123",useremail="libai@163.com",usertype="超级管理员")twz.save()# 获取对象：Person.objects.all()# 满足条件查询User.objects.filter(username="李白")# 迭代查询：es = Entry.objects.all()for e in es: print(e.headline)# 查询排序：User.objects.all().order_by('username')# 链式查询：User.objects.filter(name__contains="WeizhongTu").filter(email="tuweizhong@163.com")# 去重查询：qs = qs.distinct()# 删除操作：User.objects.all().delete()# 更新操作：Person.objects.filter(name__contains="abc").update(name='xxx')# 数据的导出：python manage.py dumpdata [appname] &gt; appname_data.jsonpython manage.py dumpdata blog &gt; blog_dump.json# 导出用户数据python manage.py dumpdata auth &gt; auth.json # 导出用户数据 批量向数据表导入数据 将name.txt导入数据库，数据内容如下： 张一|admin|zhang1@qq.com|超级管理员 张二|admin|zhang2@qq.com|超级管理员 张三|admin|zhang3@qq.com|超级管理员 张四|admin|zhang4@qq.com|超级管理员 张五|admin|zhang5@qq.com|超级管理员 张六|admin|zhang6@qq.com|超级管理员 张七|admin|zhang7@qq.com|超级管理员 张八|admin|zhang8@qq.com|超级管理员 张九|admin|zhang9@qq.com|超级管理员 文本数据批量导入mysql数据库中，核心源码如下：1234567def main(): from analysis.models import User f = open('./readme/files/name.txt',encoding='utf-8') for line in f: name,pwd,email,type = line.split('|') User.objects.create(username=name,userpass=pwd,useremail=email,usertype=type) f.close() 重新登录“用户信息管理后台”，查看结果如图所示： 参考文献 Python官网 中文维基百科 GitHub 图书：《机器学习实战》 图书：《自然语言处理理论与实战》 完整代码下载 源码请进【机器学习和自然语言QQ群：436303759】文件下载： 作者声明 本文版权归作者【白宁超】所有，转载请联系作者：1938036263@qq.com，但未经作者同意禁止转载，转载后需在文章页面明显位置给出原文连接，否则保留追究法律责任的权利。]]></content>
      <categories>
        <category>Python</category>
      </categories>
      <tags>
        <tag>Python</tag>
        <tag>Django</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[简明的Python教程之实例篇]]></title>
    <url>%2F2018%2F10%2F10%2F%E7%AE%80%E6%98%8E%E7%9A%84Python%E6%95%99%E7%A8%8B%E4%B9%8B%E5%AE%9E%E4%BE%8B%E7%AF%87%2F</url>
    <content type="text"><![CDATA[摘要：Python作为一门简洁优美且功能强大的语言，越来越受编程人员的喜欢。在工业界和学术界也是非常受欢迎的编程语言。python语言可以跨平台跨应用开发。本系列文章首先介绍Python语言及其可以做什么事情。哪些人群适合学习python和python语法特点。其次介绍了Python进阶，以实际案例演示常用的语句和控制流、表达式、函数、数据结构、标准库等知识点。然后扩展介绍了python第三方库，使读者对python有个全面的理解和认识。最后一节，采用实际案例帮助读者综合运用python知识。 （本文原创，转载必须注明出处.） 语句和控制流Hello World编程第一步，打印“Hello World”的输入结果： 1234def callHello(): print("hello world！")callHello() 运行结果： hello world！ if 语句::根据成绩评判等级123456789# if 语句:根据成绩评判等级def CallLevel(score): if score &gt;= 90 : print("优秀") elif score &gt;= 60: print("及格") else: print("不及格")CallLevel(score=60) 运行结果： 及格 for 语句:循环输出所有评分指标12345# for 语句:循环输出所有评分指标def GetLevel(score): for lev in score: print(lev,end=" ") # 设置不换行GetLevel(score=["优秀","及格","不及格"]) # 列表参数 运行结果： 优秀 及格 不及格 while 语句:循环输出所有评分12345678# while 语句:循环输出所有评分def GetLevel2(score): countlen=len(score) while countlen &gt; 0: print(score[countlen-1],end=" ") # 设置不换行 countlen -= 1GetLevel2(score=[90,30,100,98,60]) 运行结果： 60 98 100 30 90 range() 函数:循环输出所有评分指标的下标12345# range() 函数:循环输出所有评分指标的下标def GetValue(score): for lev in range(len(score)): print(lev,end=" ")GetValue(score=["优秀","及格","不及格"]) 运行结果： 0 1 2 break 语句：统计优秀学生的个数1234567891011# break 语句:不及格的跳过def GetHighLev(score): result=0 for lev in score: if lev &lt; 90: break else: result += 1 print("成绩优秀的学生有："+str(result)+"位。")GetHighLev(score=[90,30,100,98,60]) 运行结果： 成绩优秀的学生有：1位。 分析：实际优秀者个数是90,100,98共计3位，输出结果却是1位。造成这种结果的原因是，当循环输入列表90时候，满足条件自动加1.继续输入30，不满足条件，直接跳出整个程序，输出最后一条语句。 continue 语句：统计优秀成绩的个数1234567891011# continue 语句:统计优秀成绩的个数def GetHighLev2(score): result=0 for lev in score: if lev &lt; 90: continue else: result += 1 print("成绩优秀的学生有："+str(result)+"位。")GetHighLev2(score=[90,30,100,98,60]) 运行结果： 成绩优秀的学生有：3位。 pass 语句：什么也不做，占位符1234# pass 语句：什么也不做，占位符def callPass(): passprint(callPass()) 运行结果： None 函数定义函数：斐波那契数列12345678# 输出指定数的斐波那契数列def fib(n): a, b = 0, 1 while a &lt; n: print(a, end=' ') a, b = b, a+b print()fib(100) 运行结果： 0 1 1 2 3 5 8 13 21 34 55 89 结果分析： 关键字 def 引入了一个函数定义。在其后必须跟有函数名和包括形式参数的圆括号。函数体语句从下一行开始，必须是缩进的。一个函数定义会在当前符号表内引入函数名。函数名指代的值（即函数体）有一个被 Python 解释器认定为用户自定义函数的类型。 函数默认参数12345# 函数默认参数def sayhello(name="Tom"): print("Hello,"+name)sayhello() 运行结果： Hello,Tom 关键字参数123456# 关键字参数def person(name, age, **kw): #前两个是必须参数，最后一个可选可变参数 print('name:', name, 'age:', age, 'other:', kw)person("Tome",30) # 只调用必须参数person("Tom",30,city="ChengDu",sex="man") # 自定义关键字参数 运行结果： name: Tome age: 30 other: {} name: Tom age: 30 other: {&#39;sex&#39;: &#39;man&#39;, &#39;city&#39;: &#39;ChengDu&#39;} 可变参数1234# 可变参数def concat(*args, sep="/"): print(sep.join(args))concat('我','是','可变','参数') 运行结果： 我/是/可变/参数 Lambda 形式123456# Lambda 形式def Lambda(nums): nums.sort(key=lambda num: num[0]) print(nums)Lambda(nums = [(1, 'one'), (2, 'two'), (3, 'three'), (4, 'four')]) 运行结果： [(1, &#39;one&#39;), (2, &#39;two&#39;), (3, &#39;three&#39;), (4, &#39;four&#39;)] List 列表list常用方法1234567891011list.append(x) 添加元素到列表尾部。list.extend(L) 列表合并。list.insert(i, x) 在指定位置插入一个元素。list.remove(x) 删除列表中值为 x 的第一个元素。list.pop([i]) 从列表的指定位置删除元素，并将其返回。list.clear() 从列表中删除所有元素。相当于 del a[:]。list.index(x) 返回列表中第一个值为 x 的元素的索引。list.count(x) 返回 x 在列表中出现的次数。list.sort() 对列表中的元素就地进行排序。list.reverse() 就地倒排列表中的元素。list.copy() 返回列表的一个浅拷贝。等同于 a[:]。 列表的切分12345# 列表的切分def calllist(names): print(names[-1:]) # 输出列表最后一个值 print(names[:3]) # 输出列表前3个值calllist(names=['this','is','a','list']) 运行结果： [&#39;list&#39;] [&#39;this&#39;, &#39;is&#39;, &#39;a&#39;] List :列表作堆栈(先进先出)1234567891011121314# 把列表当作堆栈使用def SomeList(stack): print("原始列表（栈）：",end=' ') print(stack) stack.append('贺知章') stack.append('杜牧') print("追加后列表（栈）：",end=' ') print(stack) stack.pop() stack.pop() print("出栈后的数据：",end=' ') print(stack)SomeList(stack=['李白','杜甫', '白居易']) 运行结果：(先进先出) 原始列表（栈）： [&#39;李白&#39;, &#39;杜甫&#39;, &#39;白居易&#39;] 追加后列表（栈）： [&#39;李白&#39;, &#39;杜甫&#39;, &#39;白居易&#39;, &#39;贺知章&#39;, &#39;杜牧&#39;] 出栈后的数据： [&#39;李白&#39;, &#39;杜甫&#39;, &#39;白居易&#39;] List :列表作队列(先进后出)123456789101112131415# 把列表当作队列使用：使用队列时调用collections.deque，它为在首尾两端快速插入和删除而设计。from collections import dequedef SomeList2(queue): print("原始列表：",end=' ') print(queue) queue.append("李商隐") queue.append("杜牧") print("入队的列表：",end=' ') print(queue) queue.popleft() queue.popleft() print("出队后列表：",end=' ') print(queue)SomeList2(queue = deque(['李白','杜甫', '白居易'])) 运行结果：(先进后出) 原始列表： deque([&#39;李白&#39;, &#39;杜甫&#39;, &#39;白居易&#39;]) 入队的列表： deque([&#39;李白&#39;, &#39;杜甫&#39;, &#39;白居易&#39;, &#39;李商隐&#39;, &#39;杜牧&#39;]) 出队后列表： deque([&#39;白居易&#39;, &#39;李商隐&#39;, &#39;杜牧&#39;]) 列表推导式12345# 列表推导式def callList(nums): squares = [n**2 for n in nums] print(squares)callList(nums=[2,4,6,8]) 运行结果： [4, 16, 36, 64] 列表的矩阵转秩1234567891011# 矩阵转秩def countList(matrix): result = [[row[i] for row in matrix] for i in range(4)] print(result)matrix = [ [1, 2, 3, 4], [5, 6, 7, 8], [9, 10, 11, 12],]countList(matrix) 运行结果： [[1, 5, 9], [2, 6, 10], [3, 7, 11], [4, 8, 12]] 元组/集合/字典虽然元组和列表很类似，它们经常被用来在不同的情况和不同的用途。元组有很多用途。例如 (x, y) 坐标对，数据库中的员工记录等等。元组就像字符串， 不可变的。列表是可变的 ，它们的元素通常是相同类型的并通过迭代访问。 操作元组12345def calltuple(tuples): for t in tuples: print(t+"\t",end=" ") print()calltuple(tuples=('百度','阿里巴巴','腾讯')) # 元组参数 运行结果： 百度 阿里巴巴 腾讯 set集合集合是一个无序不重复元素的集。基本功能包括关系测试和消除重复元素。集合对象还支持 union（联合），intersection（交），difference（差）和 sysmmetric difference（对称差集）等数学运算。 12345def callset(basket): result= set(basket) print(result)callset(basket = &#123;'apple', 'orange', 'apple', 'pear', 'orange', 'banana'&#125;) 运行结果： {&#39;pear&#39;, &#39;orange&#39;, &#39;apple&#39;, &#39;banana&#39;} 字典理解字典的最佳方式是把它看做无序的键：值对（key:value 对）集合，键必须是互不相同的（在同一个字典之内）。一对大括号创建一个空的字典： {} 。初始化列表时，在大括号内放置一组逗号分隔的键：值对，这也是字典输出的方式。 1234567891011121314def calldict(dicts): print("原始字典",end=' ') print(dicts) # 原始字典 dicts['欧阳修'] = '宋朝' # 追加字典 print("追加后的字典",end=' ') print(dicts) # 追加后的字典 print("字典键的集合",end=' ') print(list(dicts.keys())) # 字典键的集合 print("字典键的排序",end=' ') print(sorted(dicts.keys())) # 字典键的排序 print("字典值的集合",end=' ') print(list(dicts.values())) # 字典值的集合calldict(dicts = &#123;'李白': '唐朝', '杜甫': '唐朝'&#125;) 运行结果： 原始字典 {&#39;杜甫&#39;: &#39;唐朝&#39;, &#39;李白&#39;: &#39;唐朝&#39;} 追加后的字典 {&#39;杜甫&#39;: &#39;唐朝&#39;, &#39;李白&#39;: &#39;唐朝&#39;, &#39;欧阳修&#39;: &#39;宋朝&#39;} 字典键的集合 [&#39;杜甫&#39;, &#39;李白&#39;, &#39;欧阳修&#39;] 字典键的排序 [&#39;李白&#39;, &#39;杜甫&#39;, &#39;欧阳修&#39;] 字典值的集合 [&#39;唐朝&#39;, &#39;唐朝&#39;, &#39;宋朝&#39;] 面向对象编程：类通过案例理解python中的类：父类是动物类，有初始化函数，且有动物讲话的方法，子类是一个狗类，继承父类所有属性，并扩展自己方法，调用子类讲话方法，并直接调用父类讲话方法。1234567891011121314151617181920212223242526"""# 欢迎进入我的主页：http://www.cnblogs.com/baiboy/."""class BaseAnimal: # 父类：动物 def __init__(self,name,age): # 初始化方法：括号里是形参 self.name=name self.age=age def speak(self): # 父类的行为方法 print("我的名字是[ %s ],今年[ %d ]岁" %(self.name,self.age))class SubDog(BaseAnimal): # 子类：小狗 def __init__(self,name,age,say): # 初始化方法：括号里是形参 BaseAnimal.__init__(self,name,age) self.say=say print("这是子类[ %s ]."%(self.name)) print('_'*20+'调用子函数方法'+'_'*20) def talk(self): # 子类的行为方法 # BaseAnimal.speak(self) # 调用父类的行为方法 print("我的名字是[ %s ],今年[ %d ]岁,我想说： %s" %(self.name,self.age,self.say))ani=SubDog('dog',12,'汪汪...')print(ani.talk())print('_'*20+'直接调用父函数方法'+'_'*20)BaseAnimal('tom',13).speak() 运行结果： 这是子类[ dog ]. ____________________调用子函数方法____________________ 我的名字是[ dog ],今年[ 12 ]岁,我想说： 汪汪... ____________________直接调用父函数方法____________________ 我的名字是[ tom ],今年[ 13 ]岁 解析： init 方法（双下划线）： init 方法在类的一个对象被建立时，马上运行。这个方法可以用来对你的对象初始化。注意，这个名称的开始和结尾都是双下划线。我们把init方法定义为取一个参数name（以及普通的参数self）。在 init 方法里，我们只是创建一个新的域，也称为name。注意:它们是两个不同的变量，尽管它们有相同的名字。点号使我们能够区分它们。最重要的是，在创建一个类的新实例的时候，把参数包括在圆括号内跟在类名后面，从而传递给 init 方法。这是这种方法的重要之处。现在，我们能够在我们的方法中使用self.name域。给C++/Java/C#程序员的注释 init 方法类似于C++、C#和Java中的constructor 。 标准库Python拥有一个强大的标准库。Python语言的核心只包含数字、字符串、列表、字典、文件等常见类型和函数，而由Python标准库提供了系统管理、网络通信、文本处理、数据库接口、图形系统、XML处理等额外的功能。Python标准库的主要功能有： 文本处理，包含文本格式化、正则表达式匹配、文本差异计算与合并、Unicode支持，二进制数据处理等功能 文件处理，包含文件操作、创建临时文件、文件压缩与归档、操作配置文件等功能 操作系统功能，包含线程与进程支持、IO复用、日期与时间处理、调用系统函数、日志（logging）等功能 网络通信，包含网络套接字，SSL加密通信、异步网络通信等功能 网络协议，支持HTTP，FTP，SMTP，POP，IMAP，NNTP，XMLRPC等多种网络协议，并提供了编写网络服务器的框架 W3C格式支持，包含HTML，SGML，XML的处理。 其它功能，包括国际化支持、数学运算、HASH、Tkinter等 Python社区提供了大量的第三方模块，使用方式与标准库类似。它们的功能覆盖科学计算、Web开发、数据库接口、图形系统多个领域。第三方模块可以使用Python或者C语言编写。SWIG,SIP常用于将C语言编写的程序库转化为Python模块。Boost C++ Libraries包含了一组库，Boost.Python，使得以Python或C++编写的程序能互相调用。Python常被用做其他语言与工具之间的“胶水”语言。 Python第三方库Web框架库 Django： 开源Web开发框架，它鼓励快速开发,并遵循MVC设计，开发周期短。 Flask： 轻量级的Web框架。 Pyramid： 轻量，同时有可以规模化的Web框架，Pylon projects 的一部分。 ActiveGrid： 企业级的Web2.0解决方案。 Karrigell： 简单的Web框架，自身包含了Web服务，py脚本引擎和纯python的数据库PyDBLite。 Tornado： 一个轻量级的Web框架，内置非阻塞式服务器，而且速度相当快 webpy： 一个小巧灵活的Web框架，虽然简单但是功能强大。 CherryPy： 基于Python的Web应用程序开发框架。 Pylons： 基于Python的一个极其高效和可靠的Web开发框架。 Zope： 开源的Web应用服务器。 TurboGears： 基于Python的MVC风格的Web应用程序框架。 Twisted： 流行的网络编程库，大型Web框架。 Quixote： Web开发框架。科学计算库 Matplotlib： 用Python实现的类matlab的第三方库，用以绘制一些高质量的数学二维图形。 Pandas： 用于数据分析、数据建模、数据可视化的第三方库。 SciPy： 基于Python的matlab实现，旨在实现matlab的所有功能。 NumPy： 基于Python的科学计算第三方库，提供了矩阵，线性代数，傅立叶变换等等的解决方案。GUI库 PyGtk： 基于Python的GUI程序开发GTK+库。 PyQt： 用于Python的QT开发库。 WxPython： Python下的GUI编程框架，与MFC的架构相似。其他库 BeautifulSoup： 基于Python的HTML/XML解析器，简单易用。 gevent： python的一个高性能并发框架,使用了epoll事件监听、协程等机制将异步调用封装为同步调用。 PIL： 基于Python的图像处理库，功能强大，对图形文件的格式支持广泛。目前已无维护，另一个第三方库Pillow实现了对PIL库的支持和维护。 PyGame： 基于Python的多媒体开发和游戏软件开发模块。 Py2exe： 将python脚本转换为windows上可以独立运行的可执行程序。 Requests： 适合于人类使用的HTTP库，封装了许多繁琐的HTTP功能，极大地简化了HTTP请求所需要的代码量。 scikit-learn： 机器学习第三方库，实现许多知名的机器学习算法。 TensorFlow： Google开发维护的开源机器学习库。 Keras： 基于TensorFlow，Theano与CNTK的高级神经网络API。 SQLAlchemy： 关系型数据库的对象关系映射(ORM)工具 参考文献 Python官网 中文维基百科 GitHub 图书：《机器学习实战》 图书：《自然语言处理理论与实战》 完整代码下载 源码请进【机器学习和自然语言QQ群：436303759】文件下载： 作者声明 本文版权归作者【白宁超】所有，转载请联系作者：1938036263@qq.com，但未经作者同意禁止转载，转载后需在文章页面明显位置给出原文连接，否则保留追究法律责任的权利。]]></content>
      <categories>
        <category>Python</category>
      </categories>
      <tags>
        <tag>Python</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[简明的Python教程之概述篇]]></title>
    <url>%2F2018%2F10%2F10%2F%E7%AE%80%E6%98%8E%E7%9A%84Python%E6%95%99%E7%A8%8B%E4%B9%8B%E6%A6%82%E8%BF%B0%E7%AF%87%2F</url>
    <content type="text"><![CDATA[摘要：Python作为一门简洁优美且功能强大的语言，越来越受编程人员的喜欢。在工业界和学术界也是非常受欢迎的编程语言。python语言可以跨平台跨应用开发。本系列文章首先介绍Python语言及其可以做什么事情。哪些人群适合学习python和python语法特点。其次介绍了Python进阶，以实际案例演示常用的语句和控制流、表达式、函数、数据结构、标准库等知识点。然后扩展介绍了python第三方库，使读者对python有个全面的理解和认识。最后一节，采用实际案例帮助读者综合运用python知识。 （本文原创，转载必须注明出处.） Python概述Python介绍Python是一种面向对象、直译式的计算机程序语言。它包含了一组功能完备的标准库，能够轻松完成很多常见的任务。它的语法简单，与其它大多数程序设计语言使用大括号不一样，它使用缩进来定义语句块。Python同样是一种动态语言，具备垃圾回收功能，能够自动管理内存使用。它经常被当作脚本语言用于处理系统管理任务和网络程序编写，然而它也非常适合完成各种高级任务。Python支持命令式程序设计、面向对象程序设计、函数式编程、面向侧面的程序设计、泛型编程多种编程范式。Python是完全面向对象的语言。函数、模块、数字、字符串都是对象。并且完全支持继承、重载、派生、多重继承，有益于增强源代码的复用性。Python支持重载运算符，因此Python也支持泛型设计。 Python发展历史Python的创始人是Guido van Rossum。1989年的圣诞节期间，Guido van Rossum为了在阿姆斯特丹打发时间，决心开发一个新的脚本解释程序，作为ABC语言的一种继承。之所以选中Python作为程序的名字，是因为他是BBC电视剧——蒙提·派森的飞行马戏团（Monty Python’s Flying Circus）的爱好者。ABC是由Guido参加设计的一种教学语言。就Guido本人看来，ABC这种语言非常优美和强大，是专门为非专业程序员设计的。但是ABC语言并没有成功，究其原因，Guido认为是非开放造成的。吉多决心在Python中避免这一错误，并获取了非常好的效果，完美结合了C和其他一些语言。就这样，Python在吉多手中诞生了。目前Guido仍然是Python的主要开发者，决定整个Python语言的发展方向。Python社区经常称呼他是仁慈的独裁者。 Python标准库的主要功能 文本处理，包含文本格式化、正则表达式匹配、文本差异计算与合并、Unicode支持，二进制数据处理等功能。 文件处理，包含文件操作、创建临时文件、文件压缩与归档、操作配置文件等功能。 操作系统功能，包含线程与进程支持、IO复用、日期与时间处理、调用系统函数、日志（logging）等功能。 网络通信，包含网络套接字，SSL加密通信、异步网络通信等功能。 网络协议，支持HTTP，FTP，SMTP，POP，IMAP，NNTP，XMLRPC等多种网络协议，并提供了编写网络服务器的框架。 W3C格式支持，包含HTML，SGML，XML的处理。 其它功能，包括国际化支持、数学运算、HASH、Tkinter等。 Python优缺点 优点 简单、易学、免费、开源、高层语言（无需考虑如何管理你的程序使用的内存等细节。 可移植性（这些平台包括Linux、Windows、FreeBSD、Macintosh、Solaris、OS/2、Amiga、AROS、AS/400、BeOS、OS/390、z/OS、Palm OS、QNX、VMS、Psion、Acom RISC OS、VxWorks、PlayStation、Sharp Zaurus、Windows CE、PocketPC、Symbian以及Google基于linux开发的android平台 解释性、面向对象、可扩展性（可以部分程序用C或C++编写，然后在Python程序中使用它们。 可嵌入性（可以把Python嵌入C/C++程序，从而向程序用户提供脚本功能。）丰富的库、规范的代码。 缺点 单行语句和命令行输出问题、独特的语法、运行速度慢（与C和C++相比。 Python开发环境通用IDE / 文本编辑器，很多并非集成开发环境软件的文本编辑器，也对Python有不同程度的支持。本文默认开发环境均集成在Anaconda中，第1章已经详细介绍过。此外，还有如下开发环境： Eclipse + pydev插件，目前对Python 3.X只支持到3.0 emacs +插件 NetBeans +插件 SlickEdit TextMate Python Tools for Visual Studio Vim +插件 Sublime Text +插件 EditPlus UltraEdit PSPad Editra由Python开发的程序编辑器。 Notepad++ Python能做什么？Python能做什么 系统编程：提供API，能方便进行系统维护和管理，很多系统管理员理想的编程工具 。 图形处理：有PIL、Tkinter等图形库支持，能方便进行图形处理。 数学处理：NumPy扩展提供大量与许多标准数学库的接口。 文本处理：python提供的re模块能支持正则表达式，还提供SGML，XML分析模块，许多程序员利用python进行XML程序的开发。 数据库编程：程序员可通过遵循Python DB-API（数据库应用程序编程接口）规范的模块与Microsoft SQL Server，Oracle，Sybase，DB2，MySQL、SQLite等数据库通信。python自带有一个Gadfly模块，提供了一个完整的SQL环境。 网络编程：提供丰富的模块支持sockets编程，能方便快速地开发分布式应用程序。 Web编程：应用的开发语言，支持最新的XML技术。 多媒体应用：能进行二维和三维图像处理。PyGame模块可用于编写游戏软件。 黑客编程：python有一个hack的库,内置你熟悉的或不熟悉的函数，但是缺少成就感。 Python开发的应用案例 Reddit - 社交分享网站 Dropbox - 文件分享服务 豆瓣网 - 图书、唱片、电影等文化产品的资料数据库网站 Django - 鼓励快速开发的Web应用框架 Pylons - Web应用框架 Zope - 应用服务器 Plone - 内容管理系统 TurboGears - 另一个Web应用快速开发框架 Twisted - Python的网络应用程序框架 Fabric - 用于管理成百上千台Linux主机的程序库 Python Wikipedia Robot Framework - MediaWiki的机器人程序 MoinMoinWiki - Python写成的Wiki程序 Trac - 使用Python编写的BUG管理系统 Mailman - 使用Python编写的邮件列表软件 Mezzanine - 基于Django编写的内容管理系统系统 flask - Python微Web框架 Webpy - Python微Web框架 Bottle - Python微Web框架 EVE - 网络游戏EVE大量使用Python进行开发 Blender - 使用Python作为建模工具与GUI语言的开源3D绘图软件 Inkscape - 一个开源的SVG矢量图形编辑器。 知乎 - 一个问答网站 果壳 - 一个泛科技主题网站 Python适合谁去学？ 知乎精选： 于这个问题，我先带着大家去知乎看看，大家感兴趣可以去知乎搜索下，基本上语调是一致的。笔者本人而言，本科主要net技术研究，在C#学习上花费很多精力和时间。后来读研初期又开始java方面学习。虽说技不压身，但是总是因为研究方向的客观变化去转战于不同语言之间，外加语言环境平台还是浪费了不少时间的，且均没有深入下去。反之，python的跨平台性就优势凸显了，你习惯Linux命令行，完全可以适应。接近伪代码的操作为你节省不少时间，特别在文本处理，自然语言分析方面，笔者之前用java编写，耗费一番功夫。总而言之，园子里面，多数同学为本科在读生，在拥有一门入门语言的情况下，研究下python我觉得是值得的，也是大的趋势。无论你做运维或者web开发，亦或算法研究，大数据分析。前天与一家大数据公司技术负责人聊天，他们产品全是python，从文本处理到数据清洗分析，直到模型构建结果评价。读者也可以看看：我爱自然语言处理社区，里面无论求职数据挖掘、自然语言处理、机器学习等均要求python经验。 Python语法和特点 编码 默认情况下，Python 3 源码文件以 UTF-8 编码，所有字符串都是 unicode 字符串。 当然你也可以为源码文件指定不同的编码： 1# -*- coding: cp-1252 -*- 标识符： 在python里，标识符有字母、数字、下划线组成。在python中，所有标识符可以包括英文、数字以及下划线（），但不能以数字开头。python中的标识符是区分大小写的。以下划线开头的标识符是有特殊意义的。以单下划线开头（foo）的代表不能直接访问的类属性，需通过类提供的接口进行访问，不能用”from xxx import *”而导入.以双下划线开头的（foo）代表类的私有成员；以双下划线开头和结尾的（foo）代表python里特殊方法专用的标识。 python保留字 保留字即关键字，我们不能把它们用作任何标识符名称。 123456&gt;&gt;&gt; import keyword&gt;&gt;&gt; keyword.kwlist['False', 'None', 'True', 'and', 'as', 'assert', 'break', 'class', 'continue', 'def', 'del', 'elif', 'else', 'except', 'finally', 'for', 'from', 'global', 'if', 'import', 'in', 'is', 'lambda', 'nonlocal', 'not', 'or', 'pass', 'raise', 'return', 'try', 'while', 'with', 'yield'] 注释 Python中单行注释以 # 开头，实例如下： 12#!/usr/bin/python3print ("Hello, Python!") # 第二个注释 行与缩进 python最具特色的就是使用缩进来表示代码块，不需要使用大括号({})。四个空格或者Tab进行缩进。1234if True: print ("True")else: print ("False") 多行语句：Python 通常是一行写完一条语句，但如果语句很长，我们可以使用反斜杠()来实现多行语句，例如： 123total = item_one + \ item_two + \ item_three 在 [], {}, 或 () 中的多行语句，不需要使用反斜杠()，例如：12total = ['item_one', 'item_two', 'item_three', 'item_four', 'item_five'] 引号 Python 接收单引号(‘ )，双引号(“ )，三引号(‘’’ “””) 来表示字符串，引号的开始与结束必须的相同类型的。 1234word = 'word'sentence = "这是一个句子。"paragraph = """这是一个段落。包含了多个语句""" 字符串 python中单引号和双引号使用完全相同。使用三引号(‘’’或”””)可以指定一个多行字符串。转义符 ‘\’自然字符串， 通过在字符串前加r或R。 如 r”this is a line with \n” 则\n会显示，并不是换行。python允许处理unicode字符串，加前缀u或U， 如 u”this is an unicode string”。字符串是不可变的。按字面意义级联字符串，如”this “ “is “ “string”会被自动转换为this is string。 空行 函数之间或类的方法之间用空行分隔，表示一段新的代码的开始。类和函数入口之间也用一行空行分隔，以突出函数入口的开始。 Print 输出 print 默认输出是换行的，如果要实现不换行需要在变量末尾加上 end=””：12345678910111213#!/usr/bin/python3x="a"y="b"# 换行输出print( x )print( y )print('---------')# 不换行输出print( x, end=" " )print( y, end=" " )print() 运行结果： a b --------- a b import 与 from…import 在 python 用 import 或者 from…import 来导入相应的模块。 (1) 将整个模块(somemodule)导入，格式为： import somemodule (2) 从某个模块中导入某个函数,格式为： from somemodule import somefunction (3) 从某个模块中导入多个函数,格式为： from somemodule import firstfunc, secondfunc, thirdfunc (4) 将某个模块中的全部函数导入，格式为： from somemodule import *12345678910111213导入 sys 模块import sysprint('================Python import mode==========================');print ('命令行参数为:')for i in sys.argv: print (i)print ('\n python 路径为',sys.path)导入 sys 模块的 argv,path 成员from sys import argv,path # 导入特定的成员 print('================python from import===================================')print('path:',path) # 因为已经导入path成员，所以此处引用时不需要加sys.path 数据类型 参考文献 Python官网 中文维基百科 GitHub 图书：《机器学习实战》 图书：《自然语言处理理论与实战》 完整代码下载 源码请进【机器学习和自然语言QQ群：436303759】文件下载： 作者声明 本文版权归作者【白宁超】所有，转载请联系作者：1938036263@qq.com，但未经作者同意禁止转载，转载后需在文章页面明显位置给出原文连接，否则保留追究法律责任的权利。]]></content>
      <categories>
        <category>Python</category>
      </categories>
      <tags>
        <tag>Python</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[谈谈自然语言处理技术的应用领域]]></title>
    <url>%2F2018%2F10%2F09%2F%E8%B0%88%E8%B0%88%E8%87%AA%E7%84%B6%E8%AF%AD%E8%A8%80%E5%A4%84%E7%90%86%E6%8A%80%E6%9C%AF%E7%9A%84%E5%BA%94%E7%94%A8%E9%A2%86%E5%9F%9F%2F</url>
    <content type="text"><![CDATA[摘要：通过《十分钟速览自然语言处理》一文，读者对自然语言基本概况进行了解。那么自然语言处理过程中总不是那么一帆风顺的，针对自然语言处理的任务和限制将在本文第一部分进行介绍。很多初学者发出疑问即自然语言处理能干什么？接下来我们回答这类问题，概要介绍自然语言处理所涉及的主要技术范畴，其中包括文本分类、问答系统、情感分析、中文分词等等。最后，我们介绍相关研究内容。（本文原创，转载必须注明出处.） 自然语言处理的任务和限制 任务和限制 NLP是一种很吸引人的人机交互方式。早期的语言处理系统如SHRDLU，当它们处于一个有限的“积木世界”，运用有限的词汇表会话时，工作得相当好。这使得研究员们对此系统相当乐观，然而，当把这个系统拓展到充满了现实世界的含糊与不确定性的环境中时，他们很快丧失了信心。由于理解自然语言，需要关于外在世界的广泛知识以及运用操作这些知识的能力，自然语言认知，同时也被视为一个人工智能完备的问题。在自然语言处理中，”理解”的定义也变成一个主要的问题。 一些NLP面临的问题实例： 句子“我们把香蕉给猴子，因为(它们)饿了”和“我们把香蕉给猴子，因为(它们)熟透了”有同样的结构。但是代词“它们”在第一句中指的是“猴子”，在第二句中指的是“香蕉”。如果不了解猴子和香蕉的属性，无法区分。(英文的it没有区分，但在中文里“它”和“它”是有区别的，只是代词在中文里常常被省略，因此需区别属性并且标示出来) 自然语言处理的主要技术范畴语音合成 语音合成（Speech synthesis）/文本朗读（Text to speech） 语音合成是将人类语音用人工的方式所产生。若是将电脑系统用在语音合成上，则称为语音合成器，而语音合成器可以用软/硬件所实现。文字转语音（text-to-speech，TTS）系统则是将一般语言的文字转换为语音，其他的系统可以描绘语言符号的表示方式，就像音标转换至语音一样。 一个语音合成器的质量通常是决定于人声的相似度以及语义是否能被了解。一个清晰的文字转语音程序应该提供人类在视觉受到伤害或是得到失读症时，能够听到并且在个人电脑上完成工作。从80年代早期开始，许多的电脑操作系统已经包含了语音合成器了。语音合成的应用包括：智能仪表、智能玩具、电子地图、电子导游、电子词典等。 语音识别 语音识别（Speech recognition） 语音识别（speech recognition）技术，也被称为语音转文本识别（英语：Speech To Text, STT），其目标是以电脑自动将人类的语音内容转换为相应的文字。与说话人识别及说话人确认不同，后者尝试识别或确认发出语音的说话人而非其中所包含的词汇内容。 语音识别技术的应用包括语音拨号、语音导航、室内设备控制、语音文档检索、简单的听写数据录入等。语音识别技术与其他自然语言处理技术如机器翻译及语音合成技术相结合，可以构建出更加复杂的应用，例如语音到语音的翻译。语音识别技术所涉及的领域包括：信号处理、模式识别、概率论和信息论、发声机理和听觉机理、人工智能等等。 中文自动分词 中文自动分词（Chinese word segmentation） 中文自动分词指的是使用计算机自动对中文文本进行词语的切分，即像英文那样使得中文句子中的词之间有空格以标识。中文自动分词被认为是中文自然语言处理中的一个最基本的环节。 现有方法包括： 基于词典的匹配：前向最大匹配、后向最大匹配。 基于字的标注：最大熵模型、条件随机场模型、感知器模型。 其它方法：与词性标注结合、与句法分析结合。 常用中文分词 中文文本词与词之间没有像英文那样有空格分隔，因此很多时候中文文本操作都涉及切词，这里整理了一些中文分词工具。 结巴分词（个人推荐，基于Python开发的） StanfordNLP汉语分词工具 哈工大语言云 庖丁解牛分词 盘古分词 ICTCLAS（中科院）汉语词法分析系统 IKAnalyzer（Luence项目下，基于java的） FudanNLP(复旦大学) 词性标注 词性标注（Part-of-speech tagging） 词性标注（Part-of-Speech tagging 或POS tagging)，又称词类标注或者简称标注，是指在词性标记集已确定，并且词典中每个词都有确定词性的基础上，对一个输入词串转换成相应词性标记串的过程叫做词性标注。 在汉语中，因为汉语词汇词性多变的情况比较少见，大多词语只有一个词性，或者出现频次最高的词性远远高于第二位的词性，相对比较简单。同时，它也受到一些条件约束。比如：兼类词在具体语境中的词性判定问题、未登录词即新词词性问题、兼类词问题等。词性标注方法包括：概率方法、隐马尔可夫模型的词性标注方法、机器学习规则的方法等 词性标注原理 原理描述：标注一篇文章中的句子，即语句标注，使用标注方法BIO标注或者BIEO标注（B代表开始，I中间相关字词，E代表结束，O代表其他词）。则观察序列X就是一个语料库（此处假设一篇文章，seg代表文章中的每一句，SEG是seg的集合），标识序列Y是BIO，即对应SEG序列的识别，从而可以根据条件概率P(标注|句子)，推测出正确的句子标注。 显然，这里针对的是序列状态，即CRF是用来标注或划分序列结构数据的概率化结构模型，CRF可以看作无向图模型或者马尔科夫随机场。 用过CRF的都知道，CRF是一个序列标注模型，指的是把一个词序列的每个词打上一个标记。一般通过，在词的左右开一个小窗口，根据窗口里面的词，和待标注词语来实现特征模板的提取。最后通过特征的组合决定需要打的tag是什么。 句法分析 句法分析（Parsing） 句法分析(Parsing)就是指对句子中的词语语法功能进行分析。比如“我来晚了”，这里“我”是主语，“来”是谓语，“晚了”是补语。 句法分析在中文信息处理中的主要应用包括：如机器翻译、命名实体识别等。 自然语言生成（Natural language generation） 自然语言生成是研究使计算机具有人一样的表达和写作的功能。即能够根据一些关键信息及其在机器内部的表达形式，经过一个规划过程，来自动生成一段高质量的自然语言文本。自然语言处理包括自然语言理解和自然语言生成。自然语言生成是人工智能和计算语言学的分支,相应的语言生成系统是基于语言信息处理的计算机模型,其工作过程与自然语言分析相反,是从抽象的概念层次开始,通过选择并执行一定的语义和语法规则来生成文本。 文本挖掘文本挖掘是信息挖掘的一个研究分支，用于基于文本信息的知识发现。文本挖掘的准备工作由文本收集、文本分析和特征修剪三个步骤组成。目前研究和应用最多的几种文本挖掘技术有：文档聚类、文档分类和摘要抽取。 文本分类 文本分类（Text categorization） 文本分类用电脑对文本集按照一定的分类器模型进行自动分类标记。文本分类的总体过程如下： 预处理：将原始语料格式化为同一格式，便于后续的统一处理； 索引：将文档分解为基本处理单元，同时降低后续处理的开销； 统计：词频统计，项（单词、概念）与分类的相关概率； 特征抽取：从文档中抽取出反映文档主题的特征； 分类器：分类器的训练； 评价：分类器的测试结果分析。 文本分类常用算法包括：决策树、朴素贝叶斯、神经网络、支持向量机、线性最小平方拟合、kNN、遗传算法、最大熵等。广泛应用于垃圾过滤，新闻分类，词性标注等。 文本挖掘 文本挖掘 文本挖掘一般指文本处理过程中产生高质量的信息。高质量的信息通常通过分类和预测来产生，如模式识别。文本挖掘通常涉及输入文本的处理过程，产生结构化数据，并最终评价和解释输出。 典型的文本挖掘方法包括文本分类、文本聚类、信息抽取、概念/实体挖掘、情感分析和观点分析等。 命名实体识别命名实体识别常见三种主流算法即基于CRF，字典法和混合的方法 CRF：在CRF for Chinese NER这个任务中，提取的特征大多是该词是否为中国人名姓氏用字，该词是否为中国人名名字用字之类的，True or false的特征。所以一个可靠的百家姓的表就十分重要啦~在国内学者做的诸多实验中，效果最好的人名可以F1测度达到90%，最差的机构名达到85%。 字典法：在NER中就是把每个字都当开头的字放到trie-tree中查一遍，查到了就是NE。中文的trie-tree需要进行哈希，因为中文字符太多了，不像英文就26个。 对六类不同的命名实体采取不一样的手段进行处理，例如对于人名，进行字级别的条件概率计算。 中文：哈工大（语言云）上海交大 英文：stanfordNER等。 信息抽取 信息抽取（Information extraction） 信息抽取（Information Extraction）主要是从大量文字数据中自动抽取特定消息作为数据库访问之用的技术。 简单可以理解为从给定文本中抽取重要的信息，比如，时间、地点、人物、事件、原因、结果、数字、日期、货币、专有名词等等。通俗说来，就是要了解谁在什么时候、什么原因、对谁、做了什么事、有什么结果。涉及到实体识别、时间抽取、因果关系抽取等关键技术。 问答系统 问答系统（Question answering） 问答系统（英语：Question answering），是，当下自然语言处理研究的热点，未来自然语言处理的明日之星。问答系统外部的行为上来看，其与目前主流资讯检索技术有两点不同：首先是查询方式为完整而口语化的问句，再来则是其回传的为高精准度网页结果或明确的答案字串。 以Ask Jeeves为例，使用者不需要思考该使用什么样的问法才能够得到理想的答案，只需要用口语化的方式直接提问如“请问谁是美国总统？”即可。而系统在了解使用者问句后，会非常清楚地回答“特朗普是美国总统”。从系统内部来看，问答系统使用了大量有别于传统资讯检索系统自然语言处理技术，如自然语言剖析（Natural Language Parsing）、问题分类（Question Classification）、专名辨识（Named Entity Recognition）等等。 机器翻译 机器翻译（Machine translation） 机器翻译（英语：Machine Translation，经常简写为MT）属于计算语言学的范畴，其研究借由计算机程序将文字或演说从一种自然语言翻译成另一种自然语言。 简单来说，机器翻译是通过将一个自然语言的字辞取代成另一个语言的字辞。借由使用语料库的技术，可达成更加复杂的自动翻译，包含可更佳的处理不同的文法结构、辞汇辨识、惯用语的对应等。一般而言，大众使用机器翻译的目的只是为了获知原文句子或段落的要旨，而不是精确的翻译。总的来说，机器翻译的效果并没有达到可以取代人工翻译的程度，所以无法成为正式的翻译。不过现在已有越来越多的公司尝试以机器翻译的技术来提供其公司网站多语系支援的服务。例如微软公司试将其 MSDN 以机器翻译来自动翻译成多国语言，如上文所说，知识库作为专业领域 ，其文法较为制式化，翻译结果亦更加符合自然语言。 情感分析 文本情感分析 文本情感分析（也称为意见挖掘）是指用自然语言处理、文本挖掘以及计算机语言学等方法来识别和提取原素材中的主观信息。 通常来说，情感分析的目的是为了找出说话者/作者在某些话题上或者针对一个文本两极的观点的态度。这个态度或许是他或她的个人判断或是评估，也许是他当时的情感状态（就是说，作者在做出这个言论时的情绪状态），或是作者有意向的情感交流（就是作者想要读者所体验的情绪）。 自动摘要 自动摘要（Automatic summarization） 所谓自动文摘就是利用计算机自动地从原始文献中提取文摘，文摘是全面准确地反映某一文献中心内容地简单连贯的短文。常用方法是自动摘要将文本作为句子的线性序列，将句子视为词的线性序列。 自动摘要可以按照技术类型和信息提取分为如下： 技术应用类型：自动提取给定文章的摘要信息、自动计算文章中词的权重、自动计算文章中句子的权重。 信息提取：单篇文章的摘要自动提取、大规模文档的摘要自动提取、基于分类的摘要自动提取。 文字蕴涵 文字蕴涵（Textual entailment） 文字蕴涵（Textual entailment，TE）在自然语言处理是一个文字片段之间的定向关系。拥有一个文字片段的含意时，可以从另一个文字如下关系。 范例 正向蕴涵 文本T:日本时间2011年3日11日，日本宫城县发生里氏震级9.0强震，造死伤失踪约3万多人。 假设H:日本时间2011年3日11日，日本宫城县发生里氏震级9.0强震。 矛盾蕴涵 文本T:张学友在1961年7月10日，生于香港，祖籍天津。 假设H:张学友生于1960年。 独立蕴涵 文本T:黎姿与”残障富豪”马廷强结婚。 假设H:马廷强为香港”东方报业集团”创办人之一马惜如之子。 自然语言处理的难点语言环境复杂自然语言处理语言环境较为复杂，以命名实体识别进行分析，对于同一个汉字某些情况下可以看作实体处理，某些情况就不能看作实体。例如： 人名，比如《天龙八部》中“婢子四姊妹一胎孪生，童姥姥给婢子取名为梅剑，这三位妹子是兰剑、竹剑、菊剑。”人物“竹剑”，某些情况下就是指的一种竹子做的剑。 地名，比如《射雕英雄传》中“陆庄主知道此人是湖南铁掌帮的帮主”中地点“湖南”，在某种情况下就指代地理方位“湖的那边”。 机构名，比如《鹿鼎记》中“这位是莲花堂香主蔡德忠蔡伯伯。”组织机构名(帮派名)“莲花堂”，在某种情况就指代种植莲花的一个地方，变成地点名了。 文本结构形式多样文本内部结构形式多样。还是以自然语言处理中的命名实体识别任务为例子，诸如： 人名，人名由姓和名构成。其中姓氏包括单姓和复姓(如：赵、钱、孙、李、慕容、东方、西门等)，名由若干个汉字组成。姓氏的用字范围相对有限，比较容易识别。然而名就比较灵活，既可以用名、字、号表示，也可以使用职务名和用典。比如：“李白、李十二、李翰林 、李供奉、李拾遗、李太白、青莲居士，谪仙人”都是同一个人。 地名，一般由若干个字组成地名，可以为作为后缀关键字或者别名(比如：“成都、蓉城、锦城、芙蓉城、锦官城、天府之国”)都是指代一个地方，其中“蓉城、锦城、芙蓉城、锦官城、天府之国”为别名。除了全称的名称之外，还有地理位置代表地名的。比如：“河南、河南省、豫”都是指的一个省份，其中“豫”是简称。 组织机构名，组织机构命名方式比较复杂，有些是修饰性的命名，有些表示历史典故，有些表示地理方位，有些表示地名，有些表示风俗习惯和关键字等等。例如：组织名“广州恒大淘宝足球俱乐部”中，“广州”表示地名的成分，“恒大”“淘宝”表示公司名称成分，“足球”是一项体育赛事成分，“俱乐部”是关键字的成分。比如：“四川大学附属中学”(四川省成都市第十二中学)中包括另一个机构名“四川大学”。机构名还可以以简称形式表示，比如：“四川大学附属中学”简称“川大附中”，“成都信息工程大学”简称“成信大”。 边界识别限制在自然语言处理任务中，边界识别最广泛应用于在命名识别识别当中，边界识别可以分解为两大任务。(1)如何去识别实体的边界？(2)如何去判定实体的类别(诸如：人名、地名、机构名)？中文命名实体识别要比英文命名实体识别更为复杂，一是受中文自身语言特性限制，不同于英语文本中词间有空格界定。二是英文中的实体一般首字母大写容易区分，诸如：‘Jobs was adopted at birth in San Francisco，and raised in a hotbed of counterculture’中，人名乔布斯Jobs的首字母大写，地名旧金山San Francisco首字母也是大写。而中文不具备这样的特征，例如：“周总理忙了一日，早已神困眼倦。”人名“周总理”就很难在一串汉字中识别出来。 词义消歧 词义消歧 词义消歧是一个自然语言处理和本体论的开放问题。歧义与消歧是自然语言理解中最核心的问题，在词义、句义、篇章含义层次都会出现语言根据上下文语义不同的现象，消歧即指根据上下文确定对象语义的过程。词义消歧即在词语层次上的语义消歧。语义消歧/词义消歧 是自然语言处理任务的一个核心与难点，影响了几乎所有任务的性能，比如搜索引擎、意见挖掘、文本理解与产生、推理等。 词性标注与词义消歧 词性标注与词义消歧是相互关联的2个问题，在人的系统他们同时能到满足。但是目前系统一般并不能让2者公用参数，同时输出。语义理解，包括分词、词性标注、词义消歧、句法解析、语义解析 并不是前馈的，是相互依赖的存在反馈的。词性标注与语义消歧都要依赖上下文来标注，但是词性标注比语义消歧要简单以及成功。原因主要是词性标注的标注集合是确定的，而语义消歧并没有，并且量级要大的多；词性标注的上下文依赖比语义消歧要短。 典型例子 许多字词不单只有一个意思，因而我们必须选出使句意最为通顺的解释。看下面歧义的句子：词意消歧就是分析出特定上下文的词被赋予的哪个意思。 川大学生上网成瘾如患绝症。歧义在于“川大学生”（1）四川大学的学生（2）四川的大学生 两代教授，人格不同。歧义：“两代”（1）两位代理教授（2）两个时代的教授 被控私分国有资产，专家总经理成了被告人。歧义：“专家总经理”（1）专家和总经理（2）有专家身份的总经理 新生市场苦熬淡季。歧义：“新生”（1）新学生的市场（2）新产生的市场 朝鲜十年走近国际社会一步。歧义：“十年走近国际社会一步”（1）每十年就向国际社会走近一步（2）最近十年间向国际社会走近了一步 新汽车牌照。歧义：“新”（1）新的汽车（2）新的牌照 咬死了猎人的狗。歧义：（1）猎人的狗被咬死了（2）把猎人咬死了的那条狗 菜不热了。歧义：“热”（1）指菜凉了（2）指菜不加热了 还欠款四万元。歧义：“还”（1）读huai（2）读hai 北京人多。歧义：（1）北京/人多（2）北京人/多 指代消解 定义 指代消解（Anaphora Resolution）是自然语言处理的重要内容，在信息抽取时，就用到了指代消解技术。 中文的三种典型指代 人称代词：李明怕高妈妈一人呆在家里寂寞，【他】便将家里的电视搬了过来。 指示代词：很多人都想创造一个美好的世界留给孩子，【这】可以理解，但不完全正确。 有定描述：贸易制裁似乎成了美国政府在对华关系中惯用的大棒。然而，这【大棒】果真如美国政府所希望的那样灵验吗? 典型指代消解 显性代词消解 所谓显性代词消解，就是指在篇章中确定显性代词指向哪个名词短语的问题，代词称为指示语或照应语（Anaphor），其所指向的名词短语一般被称为先行语（Antecedent），根据二者之间的先后位置，可分为回指（Anaphora）与预指（Cataphora），其中：如果先行语出现在指示语之前，则称为回指，反之则称为预指。 零代词消解 所谓零代词消解，是代词消解中针对零指代（Zero Anaphora）现象的一类特殊的消解。在篇章中，用户能够根据上下文关系推断出的部分经常会省略，而省略的部分（用零代词（Zero Pronoun）表示）在句子中承担着相应的句法成分，并且回指前文中的某个语言学单位。零指代现象在中文中更加常见，（中华语言博大精深。。）近几年随着各大评测任务的兴起开始受到学者们的广泛关注。 共指消解 所谓共指消解，是将篇章中指向同一现实世界客观实体（Entity）的词语划分到同一个等价集的过程，其中被划分的词语称为表述或指称语（Mention），形成的等价集称为共指链（Coreference Chain）。在共指消解中，指称语包含：普通名词、专有名词和代词，因此可以将显性代词消解看作是共指消解针对代词的子问题。共指消解与显性代词消解不同，它更关注在指称语集合上进行的等价划分，评测方法与显性代词消解也不近相同，通常使用MUC、B-CUBED、CEAF和BLANC评价方法。 指代消解的研究方法大致可以分为基于启发式规则的、基于统计的和基于深度学习的方法，目前看来，基于有监督统计机器学习的消解算法仍然是主流算法。 典型例子 指代消解是解决“谁对谁做了 什么”，处理如上所述自然语言的问题，下面看看例子: 美国政府表示仍然支持强势美元，但这到底只是嘴上说说还是要采取果断措施，经济学家对此的看法是否定的。 今天老师又在班会上表扬了自己，但是我觉得还需要继续努力。 三妹拉着葛姐的手说，她老家在偏远的山区，因为和家里赌气才跑到北京打工的，接着她又哭泣起自己的遭遇来。 当他把证书发给小钱时，他对他笑了。 小明和肖华去公园玩,他摔了一跤,他急忙把他扶起来. 星期天,小雨和小英到田老师家补习功课,她一早就打电话给她约好在红旗饭店吃早餐. 自然语言处理相关研究内容语料库知识语料库作为一个或者多个应用目标而专门收集的，有一定结构的、有代表的、可被计算机程序检索的、具有一定规模的语料的集合。 语料库划分： 时间划分 加工深度划分：标注语料库和非标注语料库 结构划分 语种划分 动态更新程度划分：参考语料库和监控语料库 语料库构建原则： 代表性 结构性 平衡性 规模性 元数据：元数据对 语料标注的优缺点 优点： 研究方便。可重用、功能多样性、分析清晰。 缺点： 语料不客观（手工标注准确率高而一致性差，自动或者半自动标注一致性高而准确率差）、标注不一致、准确率低 隐马尔可夫模型 应用 词类标注、语音识别、局部句法剖析、语块分析、命名实体识别、信息抽取等。应用于自然科学、工程技术、生物科技、公用事业、信道编码等多个领域。 马尔可夫链：在随机过程中，每个语言符号的出现概率不相互独立，每个随机试验的当前状态依赖于此前状态，这种链就是马尔可夫链。 多元马尔科夫链：考虑前一个语言符号对后一个语言符号出现概率的影响，这样得出的语言成分的链叫做一重马尔可夫链，也是二元语法。二重马尔可夫链，也是三元语法，三重马尔可夫链，也是四元语法 隐马尔可夫模型思想的三个问题 问题1（似然度问题）：给一个HMM λ=（A,B） 和一个观察序列O，确定观察序列的似然度问题 P(O|λ) 。（向前算法解决） 问题2（解码问题）：给定一个观察序列O和一个HMM λ=（A,B），找出最好的隐藏状态序列Q。（维特比算法解决） 问题3（学习问题）：给定一个观察序列O和一个HMM中的状态集合，自动学习HMM的参数A和B。（向前向后算法解决） Viterbi算法解码 算法思路 计算时间步1的维特比概率 计算时间步2的维特比概率，在第一步的基础计算 计算时间步3的维特比概率，在第二步的基础计算 维特比反向追踪路径 维特比算法与向前算法的区别 维特比算法要在前面路径的概率中选择最大值，而向前算法则计算其总和，除此之外，维特比算法和向前算法一样。 维特比算法有反向指针，寻找隐藏状态路径，而向前算法没有反向指针.HMM和维特比算法解决随机词类标注问题，利用Viterbi算法的中文句法标注 模型评价方法模型：方法=模型+策略+算法 模型问题涉及：训练误差、测试误差、过拟合等问题。通常将学习方法对未知数据的预测能力称为泛化能力。 模型评价参数： 准确率P=识别正确的数量/全部识别出的数量 错误率 =识别错误的数量/全部识别出的数量 精度=识别正确正的数量/识别正确的数量 召回率R=识别正确的数量/全部正确的总量（识别出+识别不出的） F度量=2PR/(P+R) 注意：如果数据正负均衡适合准确率，如果数据不均适合召回率，精度，F度量。 几种模型评估的方法：K-折交叉验证、随机二次抽样评估、ROC曲线评价两个模型好坏 生产模型与判别模型区别 生产式模型：直接对联合分布进行建模，如：隐马尔科夫模型、马尔科夫随机场等 判别式模型：对条件分布进行建模，如：条件随机场、支持向量机、逻辑回归等。 生成模型优点： 由联合分布 收敛速度比较快。 能够应付隐变量。 缺点：为了估算准确，样本量和计算量大，样本数目较多时候不建议使用。 判别模型优点： 计算和样本数量少。 准确率高。 缺点：收敛慢，不能针对隐变量。 知识图谱与本体 领域本体构建方法 确定领域本体的专业领域和范畴 考虑复用现有的本体 列出本体涉及领域中的重要术语 定义分类概念和概念分类层次 定义概念之间的关系 构建领域本体的知识工程方法： 主要特点：本体更强调共享、重用，可以为不同系统提供一种统一的语言，因此本体构建的工程性更为明显。 方法：目前为止，本体工程中比较有名的几种方法包括TOVE 法、Methontology方法、骨架法、IDEF-5法和七步法等。（大多是手工构建领域本体） 现状： 由于本体工程到目前为止仍处于相对不成熟的阶段，领域本体的建设还处于探索期，因此构建过程中还存在着很多问题。 方法成熟度： 以上常用方法的依次为:七步法、Methontology方法、IDEF-5法、TOVE法、骨架法。 特征工程 特征工程是什么 数据和特征决定了机器学习的上限，而模型和算法只是逼近这个上限而已。特征工程本质是一项工程活动，目的是最大限度地从原始数据中提取特征以供算法和模型使用。通过总结和归纳，人们认为特征工程包括以下方面： 特征处理是特征工程的核心部分，特征处理方法包括数据预处理，特征选择，降维等。 特征提取 特征提取是指将机器学习算法不能识别的原始数据转化为算法可以识别的特征的过程。 实例解析：文本是由一系列文字组成的，这些文字在经过分词后会形成一个词语集合，对于这些词语集合（原始数据），机器学习算法是不能直接使用的，我们需要将它们转化成机器学习算法可以识别的数值特征（固定长度的向量表示），然后再交给机器学习的算法进行操作。再比如说，图片是由一系列像素点构（原始数据）成的，这些像素点本身无法被机器学习算法直接使用，但是如果将这些像素点转化成矩阵的形式（数值特征），那么机器学习算法就可以使用了。特征提取实际上是把原始数据转化为机器学习算法可以识别的数值特征的过程，不存在降维的概念，特征提取不需要理会这些特征是否是有用的；而特征选择是在提取出来的特征中选择最优的一个特征子集。 文本分类特征提取步骤： 假设一个语料库里包含了很多文章，在对每篇文章作了分词之后，可以把每篇文章看作词语的集合。然后将每篇文章作为数据来训练分类模型，但是这些原始数据是一些词语并且每篇文章词语个数不一样，无法直接被机器学习算法所使用，机器学习算法需要的是定长的数值化的特征。因此，我们要做的就是把这些原始数据数值化，这就对应了特征提取。如何做呢？ 对训练数据集的每篇文章，我们进行词语的统计，以形成一个词典向量。词典向量里包含了训练数据里的所有词语（假设停用词已去除），且每个词语代表词典向量中的一个元素。 在经过第一步的处理后，每篇文章都可以用词典向量来表示。这样一来，每篇文章都可以被看作是元素相同且长度相同的向量，不同的文章具有不同的向量值。这也就是表示文本的词袋模型（bag of words）。 针对于特定的文章，如何给表示它的向量的每一个元素赋值呢？最简单直接的办法就是0-1法了。简单来说，对于每一篇文章，我们扫描它的词语集合，如果某一个词语出现在了词典中，那么该词语在词典向量中对应的元素置为1，否则为0。 在经过上面三步之后，特征提取就完成了。对于每一篇文章，其中必然包含了大量无关的特征，而如何去除这些无关的特征，就是特征选择要做的事情了。 数据预处理 未经处理的特征，这时的特征可能有以下问题：（标准化的前提是特征值服从正态分布，标准化后，其转换成标准正态分布） 特征的规格不一样。无量纲化可以解决。 信息冗余：对于某些定量特征，其包含的有效信息为区间划分，例如学习成绩，假若只关心“及格”或不“及格”，那么需要将定量的考分，转换成“1”和“0”表示及格和未及格。二值化可以解决这一问题。 定性特征不能直接使用：某些机器学习算法和模型只能接受定量特征的输入，那么需要将定性特征转换为定量特征。假设有N种定性值，则将这一个特征扩展为N种特征，当原始特征值为第i种定性值时，第i个扩展特征赋值为1，其他扩展特征赋值为0。 存在缺失值：缺失值需要补充。 信息利用率低：不同的机器学习算法和模型对数据中信息的利用是不同的。 使用sklearn中的preproccessing库来进行数据预处理，可以覆盖以上问题的解决方案。 特征选择 当数据预处理完成后，我们需要选择有意义的特征输入机器学习的算法和模型进行训练。特征选择是指去掉无关特征，保留相关特征的过程，也可以认为是从所有的特征中选择一个最好的特征子集。特征选择本质上可以认为是降维的过程。 1、Filter（过滤法）：按照发散性或者相关性对各个特征进行评分，设定阈值或者待选择阈值的个数，选择特征。如：方差选择法、相关系数法、卡方检验法、互信息法 方差选择法：使用方差选择法，先要计算各个特征的方差，然后根据阈值，选择方差大于阈值的特征。 相关系数法：使用相关系数法，先要计算各个特征对目标值的相关系数以及相关系数的P值。 卡方检验法：经典的卡方检验是检验定性自变量对定性因变量的相关性。假设自变量有N种取值，因变量有M种取值，考虑自变量等于i且因变量等于j的样本频数的观察值与期望的差距，构建统计量。 互信息法：经典的互信息也是评价定性自变量对定性因变量的相关性的。 2、Wrapper（包装法）：根据目标函数（通常是预测效果评分），每次选择若干特征，或者排除若干特征。如：递归特征消除法 递归特征消除法：递归消除特征法使用一个基模型来进行多轮训练，每轮训练后，消除若干权值系数的特征，再基于新的特征集进行下一轮训练。 3、Embedded（嵌入法）：先使用某些机器学习的算法和模型进行训练，得到各个特征的权值系数，根据系数从大到小选择特征。类似于Filter方法，但是是通过训练来确定特征的优劣。 基于惩罚项的特征选择法：使用带惩罚项的基模型，除了筛选出特征外，同时也进行了降维。使用feature_selection库的SelectFromModel类结合带L1惩罚项的逻辑回归模型。如：基于惩罚项的特征选择法、基于树模型的特征选择法 基于树模型的特征选择法：树模型中GBDT也可用来作为基模型进行特征选择，使用feature_selection库的SelectFromModel类结合GBDT模型。 4、深度学习方法：从深度学习模型中选择某一神经层的特征后就可以用来进行最终目标模型的训练了。 降维 当特征选择完成后，可以直接训练模型了，但是可能由于特征矩阵过大，导致计算量大，训练时间长的问题，因此降低特征矩阵维度也是必不可少的。常见的降维方法：L1惩罚项的模型、主成分分析法（PCA）、线性判别分析（LDA）。PCA和LDA有很多的相似点，其本质是要将原始的样本映射到维度更低的样本空间中。所以说PCA是一种无监督的降维方法，而LDA是一种有监督的降维方法。 主成分分析法（PCA）：使用decomposition库的PCA类选择特征。 线性判别分析法（LDA）：使用lda库的LDA类选择特征。 奇异值分解（SVD） 参考文献 自然语言处理概述 中文维基百科 GitHub 图书：《机器学习实战》 图书：《自然语言处理理论与实战》 完整代码下载 源码请进【机器学习和自然语言QQ群：436303759】文件下载： 作者声明 本文版权归作者【白宁超】所有，转载请联系作者：1938036263@qq.com，但未经作者同意禁止转载，转载后需在文章页面明显位置给出原文连接，否则保留追究法律责任的权利。]]></content>
      <categories>
        <category>自然语言处理</category>
      </categories>
      <tags>
        <tag>Python</tag>
        <tag>自然语言处理</tag>
        <tag>NLP</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[十分钟速览自然语言处理]]></title>
    <url>%2F2018%2F10%2F09%2F%E5%8D%81%E5%88%86%E9%92%9F%E9%80%9F%E8%A7%88%E8%87%AA%E7%84%B6%E8%AF%AD%E8%A8%80%E5%A4%84%E7%90%86%2F</url>
    <content type="text"><![CDATA[摘要：随着人工智能的快速发展，自然语言处理和机器学习技术应用愈加广泛。但是，初学者入门还是有一定难度，对该领域整体概况不能明晰。本章主要从发展历程、研究现状、应用前景等角度整体介绍自然语言处理及相关的机器学习技术，使读者对该技术领域有个系统而全面的认识。（本文原创，转载必须注明出处.） 课程导读 适合人群 具备一定编程基础的计算机专业、软件工程专业、通信专业、电子技术专业和自动化专业的学生和自然语言处理感兴趣的人群。 学习前技术储备 具备Python编程语言基础 具备面向对象的编程思想 具备一定的数学基础知识 快速了解自然语言处理什么是自然语言处理 自然语言 我们要对自然语言进行理解，其实就是我们日常使用的语言（书面文字和语音视频等）。简言之，汉语、日语、韩语、英语、法语等语言都属于此范畴。而自然语言处理是对自然语言处理的一种技术，就是通过我们的语音文字与计算机进行通信，我们称之为“人机交互”。 自然语言处理 自然语言处理（英语：Natural Language Processing，简称NLP）是人工智能和语言学领域的分支学科。此领域探讨如何处理及运用自然语言；自然语言认知则是指让电脑“懂”人类的语言。自然语言生成系统把计算机数据转化为自然语言。自然语言理解系统把自然语言转化为计算机程序更易于处理的形式。 我们要对自然语言进行理解，其实就是我们日常使用的语言（书面文字和语音视频等）。简言之，汉语、日语、韩语、英语、法语等语言都属于此范畴。而自然语言处理是对自然语言处理的一种技术，就是通过我们的语音文字与计算机进行通信，我们称之为“人机交互”。 自然语言处理发展背景和历程 自然语言处理发展背景 自然语言处理相关研究，最早是从机器翻译系统的研究开始的。20世纪60年代，国外对机器翻译曾有大规模的研究工作，投入了大量的人力物力财力。但是，受的客观历史因素的限制，当时人们低估了自然语言的复杂性，语言处理的理论和技术均不成热，所以进展并不大。其主要的做法是存储两种语言的单词、短语对应译法的大辞典，翻译时一一对应，技术上只是调整语言的同条顺序。但日常生活中语言的翻译远不是如此简单，很多时候还要参考某句话前后的意思。 我国机器翻译的起步较晚，是继美国、前苏联、英国之后世界上第四个开展机器翻译研究的国家。早在20世纪50年代机器翻译就被列入我国科学研究的发展规划。一些研究人员还进行了俄汉机器翻译实验，取得了一定的研究成果，但60年代的有关研究很快因“文革”而完全停顿。我国机器翻译研究的全面展开始于80年代中期以后，特别是90年代以来，一批机器翻译系统相继问世，其中影响力较大的有:中软总公司开发的汉英-汉日翻译系统(1993);中科院计算所研制的IMTEC英汉翻译系统(1992)等。 自然语言处理发展历史 1948年，香农（Shannon）把离散马尔可夫过程的概率模型应用于描述语言的自动机;同时又把“熵” (entropy)的概念引用到语言处理中。而克莱尼(Kleene)在同一时期研究了有限自动机和正则表达式。 1956年，乔姆斯基（Chomsky）又提出了上下文无关语法。这些工作导致了基于规则和基于概率两种不同的自然语言处理方法的诞生，使得该领域的研究分成了采用规则方法的符号派和采用概率方法的随机派两大阵营，进而引发了数十年有关这两种方法孰优孰劣的争执 。同年，人工智能诞生以后，自然语言处理迅速融入了人工智能的研究中。随机派学者在这一时期利用贝叶斯方法等统计学原理取得了一定的进步;而以乔姆斯基为代表的符号派也进行了形式语言理论生成句法和形式逻辑系统的研究。由于这一时期， 多数学者注重研究推理和逻辑问题，只有少数学者在研究统计方法和神经网络，所以 ，符号派的势头明显强于随机派的势头。 1967 年美国心理学家 奈瑟尔(Neisser)提出了认知心理学， 从而把自然语言处理与人类的认知联系起来。 70年代初，由于自然语言处理研究中的一些问题未能在短时间内得到解决，而新的问题又不断地涌现，许多人因此丧失了信心，自然语言处理的研究进入了低谷时期。尽管如此，一些发达国家的学者依旧地研究着。基于隐马尔可夫模型 (Hidden Markov Model，HMM)的统计方法和话语分析 (Discourse Analysis)在这一时期取得了重大进展 。 80年代， 在人们对于过去的工作反思之后 ， 有限状态模型和经验主义的研究方法开始复苏 。 90年代以后，随着计算机的速度和存储量大幅增加，自然语言处理的物质基础大幅改善，语音和语言处理的商品化开发成为可能;同时，网络技术的发展和Internet商业化使得基于自然语言的信息检索和信息抽取的需求变得更加突出。然语言处理的应用面不再局限于机器翻译、语音控制等早期研究领域了。 从90年代末到21世纪初 ，人们逐渐认识到，仅用基于规则的方法或仅用基于统计的方法都是无法成功进行自然语言处理的。基于统计、基于实例和基于规则的语料库技术在这一时期开始蓬勃发展， 各种处理技术开始融合，自然语言处理的研究又开始兴旺起来。 思考？ 基于规则的方法和基于统计的方法孰优孰劣？ 自然语言处理工作原理计算机对自然语言处理的过程：形式化描述-数学模型算法化-程序化-实用化。具体步骤如下： 形式化描述： 把需要研究是问题在语言上建立形式化模型，使其可以数学形式表示出来。 数学模型算法化： 把数学模型表示为算法的过程称之为“算法化“。 程序化： 根据算法，计算机进行实现，建立各种自然语言处理系统，这个过程是“程序化“。 实用化： 对系统进行评测和改进最终满足现实需求，这个过程是“实用化“。 自然语言处理涉及的学科领域 语言学 计算机科学（提供模型表示、算法设计、计算机实现） 数学（数学模型） 心理学（人类言语心理模型和理论） 哲学（提供人类思维和语言的更深层次理论） 统计学（提供样本数据的预测统计技术） 电子工程（信息论基础和语言信号处理技术） 生物学（人类言语行为机制理论）。 自然语言处理技术体系 自然语言处理就业与发展前景随着自然语言处理的蓬勃发展和深入研究，新的应用方向会不断呈现出来。自然语言处理发展前景广阔，主要研究领域有： 文本方面：基于自然语言理解的智能搜索引擎和智能检索、智能机器翻译、自动摘要与文本综合、文本分类与文件整理、智能自动作文系统、自动判卷系统、信息过滤与垃圾邮件处理、文学研究与古文研究、语法校对、文本数据挖掘与智能决策、基于自然语言的计算机程序设计等。 语音方面：机器同声传译、智能远程教学与答疑、语音控制、智能客户服务、机器聊天与智能参谋、智能交通信息服务、智能解说与体育新闻实时解说 、语音挖掘与多媒体挖掘、多媒体信息提取与文本转化、对残疾人智能帮助系统等。 发展前景 自然语言处理的十个发展趋势：https://blog.csdn.net/heyc861221/article/details/80130981 自然语言处理产业情况：https://www.itjuzi.com/ai#map 自然语言处理相关工作的前景：http://www.52nlp.cn/job-prospects-for-natural-language-processing 2017 年中国人工智能产业数据报告：http://www.caict.ac.cn/kxyj/qwfb/qwsj/201804/P020180213603539476032.pdf 思考：如何学习自然语言处理的问题？ - 综述了解，整体技术框架掌握 - 侧重方向，多看论文和会议文章 - 知其原理，重在实际应用 - 归纳总结，提高研究效率 - 资料检索，高效学习效率 自然语言处理相关学科NLP与数学 线性数学 自然语言处理是以计算机科学、统计学、数学和信息论等多个领域交叉的学科。线性代数又是数学的一个重要分支，对自然语言处理有着很直接的影响。诸如：算法建模、参数设置、验证策略、识别欠拟合和过拟合等等。读者往往知道线性代数很有用，常常全书通读。造成时间不足和效率较低。归因于对线性代数在机器学习中的重点和用途不明。本章主要以简明的方式介绍最常用的线性代数知识，并使读者知道线性代数常用于哪些方面。 概率论 由于基于规则方法向基于统计方法的转型，概率就显得尤为重要，诸如一些随机事件、独立假设、条件概率、完全概率等等。然后对贝叶斯模型进行案例式介绍，旨在读者深度理解。 NLP与统计学在数据科学中，统计地位尤为显著。其在数据分析的基础上，研究如何测定、收集、整理、归纳和分析反映数据规律，以便给出正确消息的科学。通过揭示数据背后的规律和隐藏信息，给相关角色提供参照价值，做出相应的决策。这在数据挖掘、自然语言处理、机器学习都广泛应用。 百度EChart：http://echarts.baidu.com/examples/ 地图案例应用场景 适合的场景 某年度国家各个省州的人口情况。 分级统计地图较多的是反映呈面状但属分散分布的现象，如反映人口密度、某农作物播种面积的比、人均收入等。 不适合的场景 2008 年美国总统大选结果。 民主党候选人奥巴马和共和党候选人麦凯恩胜出的州分别用蓝色和红色表示。这个例子的选举可视化很容易给用户造成简介中提到的错觉：数据分布和地理区域大小的不对称。共和党比民主党获得了更多的投票，因为红色的区域所占的面积更大。但是在美国总统大选中，最后的结果是看候选人获得的选举人票数，每个州拥有的选举人票数是不一样的，在一个州获胜的选举人将得到该州所有的选举人票数。纽约州虽然面积很小，却拥有33张选举人票，而蒙大拿州虽然面积很大，却只有3票。 统计可视化 统计学知识 信息图形化（饼图，线形图等） 集中趋势度量（平均值 中位数 众数 方差等） 概率 排列组合 分布（几何二项泊松正态卡方） 统计抽样 样本估计 假设检验 回归 NLP与机器学习 什么是机器学习 机器学习是人工智能的一个分支。人工智能的研究是从以“推理”为重点到以“知识”为重点，再到以“学习”为重点，一条自然、清晰的脉络。显然，机器学习是实现人工智能的一个途径，即以机器学习为手段解决人工智能中的问题。机器学习在近30多年已发展为一门多领域交叉学科，涉及概率论、统计学、逼近论、凸分析、计算复杂性理论等多门学科。机器学习理论主要是设计和分析一些让计算机可以自动“学习”的算法。机器学习算法是一类从数据中自动分析获得规律，并利用规律对未知数据进行预测的算法。因为学习算法中涉及了大量的统计学理论，机器学习与推断统计学联系尤为密切，也被称为统计学习理论。算法设计方面，机器学习理论关注可以实现的，行之有效的学习算法。很多推论问题属于无程序可循难度，所以部分的机器学习研究是开发容易处理的近似算法。机器学习已广泛应用于数据挖掘、计算机视觉、自然语言处理、生物特征识别、搜索引擎、医学诊断、检测信用卡欺诈、证券市场分析、DNA序列测序、语音和手写识别、战略游戏和机器人等领域。 机器学习就是指“计算机利用经验自动改善系统自身性能的行为”。简言之，机器学习是指通过计算机学习数据中的内在规律性信息，获得新的经验和知识，以提高计算机的智能性，使计算机能够像人那样去决策。本质上机器学习是一个从未知到已知的过程。假设计算机拥有这样一个程序，随着机器解决问题的增多，在该程序的作用下，机器性能或解决问题的能力增强，我们就说这台机器拥有学习能力。机器解决问题能力的增强主要表现在：初始状态下，对于问题Q，机器给出结果A，该机器在解决问题{Q1，Q2，… ，Qn}后，再次遇到问题Q时给出结果A1，而结果 A1比结果A更精确，我们就说机器解决问题的能力得到了增强。 机器学习发展历程 1943年， Warren McCulloch 和 Walter Pitts 提出了神经网络层次结构模型 ， 确立为神经网络的计算模型理论， 从而为机器学习的发展奠定了基础。 1950年， “人工智能之父”图灵发提出了著名的“图灵测试”，使人工智能成为了计算机科学领域一个重要的研究课题。 1957年， 康内尔大学教授 Frank Rosenblatt 提出Perceptron 概念，并且首次用算法精确定义了自组织自学习的神经网络数学模型， 设计出了第一个计算机神经网络，这个机器学习算法成为神经网络模型的开山鼻祖。 1959年， 美国 IBM 公司的 A． M． Samuel设计了一个具有学习能力的跳棋程序， 曾经战胜了美国一个保持 8 年不败的冠军。这个程序向人们初步展示了机器学习的能力。 1962年， Hubel 和 Wiesel 发现猫脑皮层中独特的神经网络结构可以有效降低学习的复杂性， 从而提出著名的 Hubel－Wiesel 生物视觉模型， 以后提出的神经网络模型均受此启迪。 1969 年， 人工智能研究的先驱者 Marvin Minsky和 Seymour Papert 出版了对机器学习研究具有深远影响的著作《Perceptron》， 虽然提出的 XOR 问题把感知机研究送上不归路、此后的十几年基于神经网络的人工智能研究进入低潮， 但是对于机器学习基本思想的论断:解决问题的算法能力和计算复杂性，影响深远、延续至今。 1980 年， 在美国卡内基·梅隆大学举行了第一届机器学习国际研讨会， 标志着机器学习研究在世界范围内兴起。1986 年， 《Machine Learning》创刊，标志着机器学习逐渐为世人瞩目并开始加速发展。 1982 年， Hopfield 发表了一篇关于神经网络模型的论文 ， 构造出能量函数并把这一概念引入Hopfield 网络，同时通过对动力系统性质的认识， 实现了 Hopfield 网络的最优化求解， 推动了神经网络的深入研究和发展应用。 1986 年，Rumelhart、Hinton 和 Williams 联合在《自然》杂志发表了著名的反向传播算法(BP) ， 首次阐述了 BP 算法在浅层前向型神经网络模型的应用， 不但明显降低了最优化问题求解的运算量，还通过增加一个隐层解决了感知器无法解决的 XOR Gate 难题，该算法成为神经网络的最基本算法。从此，神经网络的研究与应用开始复苏。 1989 年， 美国贝尔实验室学者 Yann LeCun 教授提出了目前最为流行的卷积神经网络( CNN) 计算模型，推导出基于 BP 算法的高效训练方法， 并成功地应用于英文手写体识别。CNN 是第一个被成功训练的人工神经网络，也是后来深度学习最成功、应用最广泛的模型之一。 90 年代后， 多种浅层机器学习模型相继问世，诸如逻辑回归、支持向量机等， 这些机器学习算法的共性是数学模型为凸代价函数的最优化问题，理论分析相对简单，训练方法也容易掌握，易于从训练样本中学习到内在模式，来完成对象识别、任务分类等初级智能工作。基于统计规律的浅层学习方法比起传统的基于规则的方法具备很多优越性， 取得了不少成功的商业应用的同时， 浅层学习的问题逐渐暴露出来，由于有限的样本和计算单元导致对数据间复杂函数的表示能力有限，学习能力不强，只能提取初级特征。 2006 年， 在学界及业界巨大需求刺激下， 特别是计算机硬件技术的迅速发展提供了强大的计算能力。机器学习领域的泰斗 Geoffrey Hinton 和 Ruslan Salakhutdinov 发表文章 ，提出了深度学习模型， 主要论点包括:多个隐层的人工神经网络具有良好的特征学习能力;通过逐层初始化来克服训练的难度，实现网络整体调优。这个模型的提出， 开启了深度神经网络机器学习的新时代。 2012 年， Hinton 研究团队采用深度学习模型赢得计算机视觉领域最具影响力的 ImageNet 比赛冠军，从而标志着深度学习进入第二个阶段。 至今， 随着Hinton、LeCun 和 Andrew Ng 对深度学习的研究，以及云计算、大数据、计算机硬件技术发展的支撑下，深度学习近年来在多个领域取得了令人赞叹的进展，推出一批成功的商业应用，诸如谷歌翻译，苹果语音工具 Siri， 微软的 Cortana 个人语音助手，蚂蚁金服的 Smile to Pay 扫脸技术， 特别是谷歌 AlphaGo 人机大战获胜的奇迹等， 使机器学习成为计算机科学的一个新的领域。深度学习是目前最接近人类大脑的分层智能学习方法，通过建立类似于人脑的分层模型结构，突破浅层学习的限制，能够表征复杂函数关系，对输入数据逐层提取从底层到高层的特征，并且逐层抽象，从而建立从底层简单特征到高层抽象语义的非线性映射关系 ，实现机器学习智能化的进一步提升， 成为机器学习的一个里程碑。 机器学习应用前景 2016年，引世人关注的人机大战以 AlphaGo 以 4:1 胜利而告终，这为世人所震撼惊叹的同时，更让人感受到机器学习的强大威力，更昭示出机器学习研究与应用的灿烂前景。以此为契机， 机器学习理论研究将会成为一个新的热点，在认知计算、类脑计算的支撑下将促进机器学习向更高阶段发展，在此基础上将会出现性能更好、结构优化、学习高效、功能强大的机器模型，非监督机器学习将会取得实质性的进展。机器学习的自主学习能力将进一步提高，逐渐跨越弱人工智能阶段，不断提高智能性。机器学习将向人类的学习、认知、理解、思考、推理和预测能力迈进，必将推动人工智能及整个科学技术的迈向更高台阶。随着机器学习与大数据、云计算、物联网的深度融合，将会掀起一场新的数字化技术革命，借助自然语言理解、情感及行为理解将会开启更加友好的人机交互新界面、自动驾驶汽车将成为现实，我们的工作、生活中将出现更多的智能机器人，在医疗、金融、教育等行业将能够给我们提供更多智能化、个性化服务定制服务，机器学习一定会造福于我们整个人类，使明天的生活更美好! 自然语言处理和机器学习的联系 语言是人类区别其他动物的本质特性。在所有生物中，只有人类才具有语言能力。人类的多种智能都与语言有着密切的关系。人类的逻辑思维以语言为形式，人类的绝大部分知识也是以语言文字的形式记载和流传下来的。因而，它也是人工智能（机器学习和深度学习为代表的人工智能）的一个重要，甚至核心部分。用自然语言与计算机进行通信，这是人们长期以来所追求的。因为它既有明显的实际意义和理论意义。实现人机间自然语言通信意味着要使计算机既能理解自然语言文本的意义，也能以自然语言文本来表达给定的意图、思想等。前者称为自然语言理解，后者称为自然语言生成。因此，自然语言处理大体包括了自然语言理解和自然语言生成两个部分。无论实现自然语言理解，还是自然语言生成，都远不如人们原来想象的那么简单，而是十分困难的。从现有的理论和技术现状看，通用的、高质量的自然语言处理系统，仍然是较长期的努力目标，但是针对一定应用，具有相当自然语言处理能力的实用系统已经出现，有些已商品化，甚至开始产业化。典型的例子有：多语种数据库和专家系统的自然语言接口、各种机器翻译系统、全文信息检索系统、自动文摘系统等。 现代NLP算法是基于机器学习，特别是统计机器学习。机器学习范式是不同于一般之前的尝试语言处理。语言处理任务的实现，通常涉及直接用手的大套规则编码。许多不同类的机器学习算法已应用于自然语言处理任务。这些算法的输入是一大组从输入数据生成的“特征”。一些最早使用的算法，如决策树，产生硬的if-then规则类似于手写的规则，是再普通的系统体系。然而，越来越多的研究集中于统计模型，这使得基于附加实数值的权重，每个输入要素柔软，概率的决策。此类模型具有能够表达许多不同的可能的答案，而不是只有一个相对的确定性，产生更可靠的结果时，这种模型被包括作为较大系统的一个组成部分的优点。自然语言处理研究逐渐从词汇语义成分的语义转移，进一步的，叙事的理解。然而人类水平的自然语言处理，是一个人工智能完全问题。它是相当于解决中央的人工智能问题使计算机和人一样聪明，或强大的AI。自然语言处理的未来一般也因此密切结合人工智能发展。 参考文献 自然语言处理概述 中文维基百科 GitHub 图书：《机器学习实战》 图书：《自然语言处理理论与实战》 完整代码下载 源码请进【机器学习和自然语言QQ群：436303759】文件下载： 作者声明 本文版权归作者【白宁超】所有，转载请联系作者：1938036263@qq.com，但未经作者同意禁止转载，转载后需在文章页面明显位置给出原文连接，否则保留追究法律责任的权利。]]></content>
      <categories>
        <category>自然语言处理</category>
      </categories>
      <tags>
        <tag>Python</tag>
        <tag>自然语言处理</tag>
        <tag>NLP</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[一步步教你轻松学主成分分析PCA降维算法]]></title>
    <url>%2F2018%2F09%2F29%2F%E4%B8%80%E6%AD%A5%E6%AD%A5%E6%95%99%E4%BD%A0%E8%BD%BB%E6%9D%BE%E5%AD%A6%E4%B8%BB%E6%88%90%E5%88%86%E5%88%86%E6%9E%90PCA%E9%99%8D%E7%BB%B4%E7%AE%97%E6%B3%95%2F</url>
    <content type="text"><![CDATA[摘要：主成分分析（英语：Principal components analysis，PCA）是一种分析、简化数据集的技术。主成分分析经常用于减少数据集的维数，同时保持数据集中的对方差贡献最大的特征。常常应用在文本处理、人脸识别、图片识别、自然语言处理等领域。可以做在数据预处理阶段非常重要的一环，本文首先对基本概念进行介绍，然后给出PCA算法思想、流程、优缺点等等。最后通过一个综合案例去实现应用。（本文原创，转载必须注明出处.） 数据降维预备知识 均值 方差 标准差 协方差 正交矩阵 什么是降维降维是对数据高维度特征的一种预处理方法。降维是将高维度的数据保留下最重要的一些特征，去除噪声和不重要的特征，从而实现提升数据处理速度的目的。在实际的生产和应用中，降维在一定的信息损失范围内，可以为我们节省大量的时间和成本。降维也成为了应用非常广泛的数据预处理方法。 我们正通过电视观看体育比赛，在电视的显示器上有一个足球。显示器大概包含了100万像素点，而球则可能是由较少的像素点组成，例如说一千个像素点。人们实时的将显示器上的百万像素转换成为一个三维图像，该图像就给出运动场上球的位置。在这个过程中，人们已经将百万像素点的数据，降至为三维。这个过程就称为降维(dimensionality reduction) 数据降维的目的： 使得数据集更容易使用 确保这些变量是相互独立的 降低很多算法的计算开销 去除噪音 使得结果易懂 适用范围: 在已标注与未标注的数据上都有降维技术。 本文主要关注未标注数据上的降维技术，将技术同样也可以应用于已标注的数据。 常见降维技术（PCA的应用目前最为广泛） 主成分分析就是找出一个最主要的特征，然后进行分析。例如： 考察一个人的智力情况，就直接看数学成绩就行(数学、语文、英语成绩) 因子分析(Factor Analysis),将多个实测变量转换为少数几个综合指标。它反映一种降维的思想，通过降维将相关性高的变量聚在一起,从而减少需要分析的变量的数量,而减少问题分析的复杂性.例如： 考察一个人的整体情况，就直接组合3样成绩(隐变量)，看平均成绩就行(存在：数学、语文、英语成绩),应用的领域包括社会科学、金融等。在因子分析中， 假设观察数据的成分中有一些观察不到的隐变量(latent variable)。 假设观察数据是这些隐变量和某些噪音的线性组合。 那么隐变量的数据可能比观察数据的数目少，也就说通过找到隐变量就可以实现数据的降维。 独立成分分析(Independ Component Analysis, ICA)，ICA 认为观测信号是若干个独立信号的线性组合，ICA 要做的是一个解混过程。 例如：我们去ktv唱歌，想辨别唱的是什么歌曲？ICA 是观察发现是原唱唱的一首歌【2个独立的声音（原唱／主唱）】。 ICA 是假设数据是从 N 个数据源混合组成的，这一点和因子分析有些类似，这些数据源之间在统计上是相互独立的，而在 PCA 中只假设数据是不 相关（线性关系）的。同因子分析一样，如果数据源的数目少于观察数据的数目，则可以实现降维过程。 PCA 概述主成分分析(Principal Component Analysis, PCA)：通俗理解：就是找出一个最主要的特征，然后进行分析。 主成分分析（英语：Principal components analysis，PCA）是一种分析、简化数据集的技术。主成分分析经常用于减少数据集的维数，同时保持数据集中的对方差贡献最大的特征。这是通过保留低阶主成分，忽略高阶主成分做到的。这样低阶成分往往能够保留住数据的最重要方面。但是，这也不是一定的，要视具体应用而定。由于主成分分析依赖所给数据，所以数据的准确性对分析结果影响很大。 主成分分析由卡尔·皮尔逊于1901年发明，用于分析数据及建立数理模型。其方法主要是通过对协方差矩阵进行特征分解，以得出数据的主成分（即特征向量）与它们的权值（即特征值）。PCA是最简单的以特征量分析多元统计分布的方法。其结果可以理解为对原数据中的方差做出解释：哪一个方向上的数据值对方差的影响最大？换而言之，PCA提供了一种降低数据维度的有效办法；如果分析者在原数据中除掉最小的特征值所对应的成分，那么所得的低维度数据必定是最优化的（也即，这样降低维度必定是失去讯息最少的方法）。主成分分析在分析复杂数据时尤为有用，比如人脸识别。 PCA是最简单的以特征量分析多元统计分布的方法。通常情况下，这种运算可以被看作是揭露数据的内部结构，从而更好的解释数据的变量的方法。如果一个多元数据集能够在一个高维数据空间坐标系中被显现出来，那么PCA就能够提供一幅比较低维度的图像，这幅图像即为在讯息最多的点上原对象的一个‘投影’。这样就可以利用少量的主成分使得数据的维度降低了。PCA跟因子分析密切相关，并且已经有很多混合这两种分析的统计包。而真实要素分析则是假定底层结构，求得微小差异矩阵的特征向量。 PCA 场景 例如： 考察一个人的智力情况，就直接看数学成绩就行(存在：数学、语文、英语成绩) PCA 思想 去除平均值 计算协方差矩阵 计算协方差矩阵的特征值和特征向量 将特征值排序 保留前N个最大的特征值对应的特征向量 将数据转换到上面得到的N个特征向量构建的新空间中（实现了特征压缩） PCA 原理 找出第一个主成分的方向，也就是数据方差最大的方向。 找出第二个主成分的方向，也就是数据方差次大的方向，并且该方向与第一个主成分方向正交(orthogonal 如果是二维空间就叫垂直)。 通过这种方式计算出所有的主成分方向。 通过数据集的协方差矩阵及其特征值分析，我们就可以得到这些主成分的值。 一旦得到了协方差矩阵的特征值和特征向量，我们就可以保留最大的 N 个特征。这些特征向量也给出了 N 个最重要特征的真实结构，我们就可以通过将数据乘上这 N 个特征向量 从而将它转换到新的空间上。 PCA 算法流程 下面我们看看具体的算法流程。 输入：n维样本集\( D=(x^{(1)},x^{(2)},…,x^{(m)}) \)，要降维到的维数n.输出：降维后的样本集\( D^′\)1) 对所有的样本进行中心化：\( x^{(i)}=x^{(i)}−\frac{1}{m}\sum_{j=1}^{m}x^{(j)} \)2) 计算样本的协方差矩阵\( XX^T\)3) 对矩阵\( XX^T\)进行特征值分解4）取出最大的n’个特征值对应的特征向量\( (w_1,w_2,…,w_n^′) \), 将所有的特征向量标准化后，组成特征向量矩阵W。5）对样本集中的每一个样本\( x^{(i)}\),转化为新的样本\( z^{(i)}=W^Tx^{(i)} \)6) 得到输出样本集\( D^′=(z^{(1)},z^{(2)},…,z^{(m)}) \) PCA 优缺点 优点：降低数据的复杂性，识别最重要的多个特征。缺点：不一定需要，且可能损失有用信息。适用数据类型：数值型数据。 实例理解真实的训练数据总是存在各种各样的问题： 比如拿到一个汽车的样本，里面既有以“千米/每小时”度量的最大速度特征，也有“英里/小时”的最大速度特征，显然这两个特征有一个多余。 拿到一个数学系的本科生期末考试成绩单，里面有三列，一列是对数学的兴趣程度，一列是复习时间，还有一列是考试成绩。我们知道要学好数学，需要有浓厚的兴趣，所以第二项与第一项强相关，第三项和第二项也是强相关。那是不是可以合并第一项和第二项呢？ 拿到一个样本，特征非常多，而样例特别少，这样用回归去直接拟合非常困难，容易过度拟合。比如北京的房价：假设房子的特征是（大小、位置、朝向、是否学区房、建造年代、是否二手、层数、所在层数），搞了这么多特征，结果只有不到十个房子的样例。要拟合房子特征-&gt;房价的这么多特征，就会造成过度拟合。 这个与第二个有点类似，假设在IR中我们建立的文档-词项矩阵中，有两个词项为“learn”和“study”，在传统的向量空间模型中，认为两者独立。然而从语义的角度来讲，两者是相似的，而且两者出现频率也类似，是不是可以合成为一个特征呢？ 在信号传输过程中，由于信道不是理想的，信道另一端收到的信号会有噪音扰动，那么怎么滤去这些噪音呢？ 这时可以采用主成分分析（PCA）的方法来解决部分上述问题。PCA的思想是将n维特征映射到k维上（k&lt;n），这k维是全新的正交特征。这k维特征称为主元，是重新构造出来的k维特征，而不是简单地从n维特征中去除其余n-k维特征。 PCA 算法实现准备数据收集数据：提供文本文件,文件名：testSet.txt.文本文件部分数据格式如下： 10.235186 11.321997 10.122339 11.810993 9.190236 8.904943 9.306371 9.847394 8.330131 8.340352 10.152785 10.123532 10.408540 10.821986 9.003615 10.039206 9.534872 10.096991 9.498181 10.825446 9.875271 9.233426 10.362276 9.376892 10.191204 11.250851 数据集处理代码实现如下 1234567'''加载数据集'''def loadDataSet(fileName, delim='\t'): fr = open(fileName) stringArr = [line.strip().split(delim) for line in fr.readlines()] datArr = [list(map(float, line)) for line in stringArr] #注意这里和python2的区别，需要在map函数外加一个list（），否则显示结果为 map at 0x3fed1d0 return mat(datArr) PCA 数据降维在等式 Av=λv 中，v 是特征向量， λ 是特征值。表示 如果特征向量 v 被某个矩阵 A 左乘，那么它就等于某个标量 λ 乘以 v.幸运的是： Numpy 中有寻找特征向量和特征值的模块 linalg，它有 eig() 方法，该方法用于求解特征向量和特征值。具体代码实现如下： 方差：（一维）度量两个随机变量关系的统计量,数据离散程度，方差越小越稳定 协方差： （二维）度量各个维度偏离其均值的程度 协方差矩阵：（多维）度量各个维度偏离其均值的程度 当 cov(X, Y)&gt;0时，表明X与Y正相关(X越大，Y也越大；X越小Y，也越小。) 当 cov(X, Y)&lt;0时，表明X与Y负相关； 当 cov(X, Y)=0时，表明X与Y不相关。 1234567891011121314151617181920212223242526272829303132333435363738394041'''pca算法 cov协方差=[(x1-x均值)*(y1-y均值)+(x2-x均值)*(y2-y均值)+...+(xn-x均值)*(yn-y均值)]/(n-1) Args: dataMat 原数据集矩阵 topNfeat 应用的N个特征 Returns: lowDDataMat 降维后数据集 reconMat 新的数据集空间'''def pca(dataMat, topNfeat=9999999): # 计算每一列的均值 meanVals = mean(dataMat, axis=0) # print('meanVals', meanVals) # 每个向量同时都减去均值 meanRemoved = dataMat - meanVals # print('meanRemoved=', meanRemoved) # rowvar=0，传入的数据一行代表一个样本，若非0，传入的数据一列代表一个样本 covMat = cov(meanRemoved, rowvar=0) # eigVals为特征值， eigVects为特征向量 eigVals, eigVects = linalg.eig(mat(covMat)) # print('eigVals=', eigVals) # print('eigVects=', eigVects) # 对特征值，进行从小到大的排序，返回从小到大的index序号 # 特征值的逆序就可以得到topNfeat个最大的特征向量 eigValInd = argsort(eigVals) # print('eigValInd1=', eigValInd) # -1表示倒序，返回topN的特征值[-1到-(topNfeat+1)不包括-(topNfeat+1)] eigValInd = eigValInd[:-(topNfeat+1):-1] # print('eigValInd2=', eigValInd) # 重组 eigVects 最大到最小 redEigVects = eigVects[:, eigValInd] # print('redEigVects=', redEigVects.T) # 将数据转换到新空间 # print( "---", shape(meanRemoved), shape(redEigVects)) lowDDataMat = meanRemoved * redEigVects reconMat = (lowDDataMat * redEigVects.T) + meanVals # print('lowDDataMat=', lowDDataMat) # print('reconMat=', reconMat) return lowDDataMat, reconMat 可视化结果分析接下来我们查看降维后的数据与原始数据可视化效果，我们将原始数据采用绿色△表示，降维后的数据采用红色○表示。可视化代码如下： 1234567'''降维后的数据和原始数据可视化'''def show_picture(dataMat, reconMat): fig = plt.figure() ax = fig.add_subplot(111) ax.scatter(dataMat[:, 0].flatten().A[0], dataMat[:, 1].flatten().A[0], marker='^', s=90,c='green') ax.scatter(reconMat[:, 0].flatten().A[0], reconMat[:, 1].flatten().A[0], marker='o', s=50, c='red') plt.show() 调用代码： 12345# 2 主成分分析降维特征向量设置lowDmat, reconMat = pca(dataMat, 1)print(shape(lowDmat))# 3 将降维后的数据和原始数据一起可视化show_picture(dataMat, reconMat) 运行结果显示： PCA对半导体制造数据降维项目概述半导体是在一些极为先进的工厂中制造出来的。设备的生命早期有限，并且花费极其巨大。虽然通过早期测试和频繁测试来发现有瑕疵的产品，但仍有一些存在瑕疵的产品通过测试。如果我们通过机器学习技术用于发现瑕疵产品，那么它就会为制造商节省大量的资金。具体来讲，它拥有590个特征。我们看看能否对这些特征进行降维处理。对于数据的缺失值的问题，将缺失值NaN(Not a Number缩写)，全部用平均值来替代(如果用0来处理的策略就太差了)。收集数据：提供文本文件,文件名：secom.data.文本文件部分数据格式如下： 3030.93 2564 2187.7333 1411.1265 1.3602 100 97.6133 0.1242 1.5005 0.0162 -0.0034 0.9455 202.4396 0 7.9558 414.871 10.0433 0.968 192.3963 12.519 1.4026 -5419 2916.5 -4043.75 751 0.8955 1.773 3.049 64.2333 2.0222 0.1632 3.5191 83.3971 9.5126 50.617 64.2588 49.383 66.3141 86.9555 117.5132 61.29 4.515 70 352.7173 10.1841 130.3691 723.3092 1.3072 141.2282 1 624.3145 218.3174 0 4.592 数据预处理将数据集中NaN替换成平均值，代码实现如下：1234567891011'''将NaN替换成平均值函数'''def replaceNanWithMean(): datMat = loadDataSet('./secom.data', ' ') numFeat = shape(datMat)[1] for i in range(numFeat): # 对value不为NaN的求均值 # .A 返回矩阵基于的数组 meanVal = mean(datMat[nonzero(~isnan(datMat[:, i].A))[0], i]) # 将value为NaN的值赋值为均值 datMat[nonzero(isnan(datMat[:, i].A))[0],i] = meanVal return datMat 分析数据我们拿到数据进行数据预处理之后，再跑下程序，看看中间结果如果，分析数据代码如下： 12345678910111213141516171819202122232425'''分析数据'''def analyse_data(dataMat): meanVals = mean(dataMat, axis=0) meanRemoved = dataMat-meanVals covMat = cov(meanRemoved, rowvar=0) eigvals, eigVects = linalg.eig(mat(covMat)) eigValInd = argsort(eigvals) topNfeat = 20 eigValInd = eigValInd[:-(topNfeat+1):-1] cov_all_score = float(sum(eigvals)) sum_cov_score = 0 for i in range(0, len(eigValInd)): line_cov_score = float(eigvals[eigValInd[i]]) sum_cov_score += line_cov_score ''' 我们发现其中有超过20%的特征值都是0。 这就意味着这些特征都是其他特征的副本，也就是说，它们可以通过其他特征来表示，而本身并没有提供额外的信息。 最前面15个值的数量级大于10^5，实际上那以后的值都变得非常小。 这就相当于告诉我们只有部分重要特征，重要特征的数目也很快就会下降。 最后，我们可能会注意到有一些小的负值，他们主要源自数值误差应该四舍五入成0. ''' print('主成分：%s, 方差占比：%s%%, 累积方差占比：%s%%' % (format(i+1, '2.0f'), format(line_cov_score/cov_all_score*100, '4.2f'), format(sum_cov_score/cov_all_score*100, '4.1f'))) 去均值化的特征值结果显示如下： [ 5.34151979e+07 2.17466719e+07 8.24837662e+06 2.07388086e+06 1.31540439e+06 4.67693557e+05 2.90863555e+05 2.83668601e+05 2.37155830e+05 2.08513836e+05 1.96098849e+05 1.86856549e+05 1.52422354e+05 1.13215032e+05 1.08493848e+05 1.02849533e+05 1.00166164e+05 8.33473762e+04 8.15850591e+04 7.76560524e+04 ... 0.00000000e+00 0.00000000e+00 0.00000000e+00 0.00000000e+00 0.00000000e+00 0.00000000e+00 0.00000000e+00 0.00000000e+00 0.00000000e+00 0.00000000e+00 0.00000000e+00 0.00000000e+00 0.00000000e+00 0.00000000e+00 0.00000000e+00 0.00000000e+00 0.00000000e+00 0.00000000e+00 0.00000000e+00 0.00000000e+00 0.00000000e+00 0.00000000e+00 0.00000000e+00 0.00000000e+00 0.00000000e+00 0.00000000e+00 0.00000000e+00 0.00000000e+00 0.00000000e+00 0.00000000e+00 0.00000000e+00 0.00000000e+00 0.00000000e+00 0.00000000e+00 0.00000000e+00 0.00000000e+00 ] 数据分析结果如下： 主成分： 1, 方差占比：59.25%, 累积方差占比：59.3% 主成分： 2, 方差占比：24.12%, 累积方差占比：83.4% 主成分： 3, 方差占比：9.15%, 累积方差占比：92.5% 主成分： 4, 方差占比：2.30%, 累积方差占比：94.8% 主成分： 5, 方差占比：1.46%, 累积方差占比：96.3% 主成分： 6, 方差占比：0.52%, 累积方差占比：96.8% 主成分： 7, 方差占比：0.32%, 累积方差占比：97.1% 主成分： 8, 方差占比：0.31%, 累积方差占比：97.4% 主成分： 9, 方差占比：0.26%, 累积方差占比：97.7% 主成分：10, 方差占比：0.23%, 累积方差占比：97.9% 主成分：11, 方差占比：0.22%, 累积方差占比：98.2% 主成分：12, 方差占比：0.21%, 累积方差占比：98.4% 主成分：13, 方差占比：0.17%, 累积方差占比：98.5% 主成分：14, 方差占比：0.13%, 累积方差占比：98.7% 主成分：15, 方差占比：0.12%, 累积方差占比：98.8% 主成分：16, 方差占比：0.11%, 累积方差占比：98.9% 主成分：17, 方差占比：0.11%, 累积方差占比：99.0% 主成分：18, 方差占比：0.09%, 累积方差占比：99.1% 主成分：19, 方差占比：0.09%, 累积方差占比：99.2% 主成分：20, 方差占比：0.09%, 累积方差占比：99.3% 我们发现其中有超过20%的特征值都是0。这就意味着这些特征都是其他特征的副本，也就是说，它们可以通过其他特征来表示，而本身并没有提供额外的信息。最前面值的数量级大于10^5，实际上那以后的值都变得非常小。这就相当于告诉我们只有部分重要特征，重要特征的数目也很快就会下降。最后，我们可能会注意到有一些小的负值，他们主要源自数值误差应该四舍五入成0. 根据实验结果我们绘制半导体数据中前七个主要成分所占的方差百分比如下 主成分 方差百分比（%） 累积方差百分比（%） 1 59.25 59.3 2 24.12 83.4 3 9.15 92.5 4 2.30 94.8 5 1.46 96.3 6 0.52 96.8 7 0.32 97.1 20 0.09 99.3 PCA降维结果可视化调用我们上文写的代码如下： 123lowDmat, reconMat = pca(dataMat, 20)print(shape(lowDmat))show_picture(dataMat, reconMat) 运行结果如下： 参考文献 主成分分析 中文维基百科 GitHub 图书：《机器学习实战》 图书：《自然语言处理理论与实战》 一篇深入剖析PCA的好文 主成分分析原理总结 完整代码下载 源码请进【机器学习和自然语言QQ群：436303759】文件下载： 作者声明 本文版权归作者【白宁超】所有，转载请联系作者：1938036263@qq.com，但未经作者同意禁止转载，转载后需在文章页面明显位置给出原文连接，否则保留追究法律责任的权利。]]></content>
      <categories>
        <category>数据准备</category>
        <category>PCA</category>
      </categories>
      <tags>
        <tag>Python</tag>
        <tag>PCA</tag>
        <tag>数据降维</tag>
        <tag>数据预处理</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[一步步教你轻松学关联规则Apriori算法]]></title>
    <url>%2F2018%2F09%2F27%2F%E4%B8%80%E6%AD%A5%E6%AD%A5%E6%95%99%E4%BD%A0%E8%BD%BB%E6%9D%BE%E5%AD%A6%E5%85%B3%E8%81%94%E8%A7%84%E5%88%99Apriori%E7%AE%97%E6%B3%95%2F</url>
    <content type="text"><![CDATA[摘要：先验算法（Apriori Algorithm）是关联规则学习的经典算法之一，常常应用在商业等诸多领域。本文首先介绍什么是Apriori算法，与其相关的基本术语，之后对算法原理进行多方面剖析，其中包括思路、原理、优缺点、流程步骤和应用场景。接着再通过一个实际案例进行语言描述性逐步剖析。至此，读者基本了解该算法思想和过程。紧接着我们进行实验，重点的频繁项集的生成和关联规则的生成。最后我们采用综合实例进行实际演示。（本文原创，转载必须注明出处.） 理论介绍算法概述 维基百科 在计算机科学以及数据挖掘领域中，先验算法（Apriori Algorithm）是关联规则学习的经典算法之一。先验算法的设计目的是为了处理包含交易信息内容的数据库（例如,顾客购买的商品清单，或者网页常访清单。）而其他的算法则是设计用来寻找无交易信息（如Winepi算法和Minepi算法）或无时间标记（如DNA测序）的数据之间的联系规则。 先验算法采用广度优先搜索算法进行搜索并采用树结构来对候选项目集进行高效计数。它通过长度为\( k-1 \)的候选项目集来产生长度为 k 的候选项目集，然后从中删除包含不常见子模式的候选项。根据向下封闭性引理,该候选项目集包含所有长度为 k 的频繁项目集。之后，就可以通过扫描交易数据库来决定候选项目集中的频繁项目集。 数据挖掘十大算法 Apriori 算法是一种最有影响力的挖掘布尔关联规则的频繁项集算法，它是由Rakesh Agrawal 和RamakrishnanSkrikant 提出的。它使用一种称作逐层搜索的迭代方法，k- 项集用于探索（k+1）- 项集。首先，找出频繁 1- 项集的集合。该集合记作L1。L1 用于找频繁2- 项集的集合 L2，而L2 用于找L3，如此下去，直到不能找到 k- 项集。每找一个 Lk 需要一次数据库扫描。为提高频繁项集逐层产生的效率，一种称作Apriori 性质用于压缩搜索空间。其约束条件：一是频繁项集的所有非空子集都必须也是频繁的，二是非频繁项集的所有父集都是非频繁的。 基本概念 关联分析 关联分析是一种在大规模数据集中寻找相互关系的任务。 这些关系可以有两种形式: 频繁项集（frequent item sets）: 经常出现在一块的物品的集合。 关联规则（associational rules）: 暗示两种物品之间可能存在很强的关系。 相关术语 关联分析（关联规则学习): 下面是用一个 杂货店简单交易清单的例子来说明这两个概念，如下表所示: 交易号码 商品 0 豆奶，莴苣 1 莴苣，尿布，葡萄酒，甜菜 2 豆奶，尿布，葡萄酒，橙汁 3 莴苣，豆奶，尿布，葡萄酒 4 莴苣，豆奶，尿布，橙汁 频繁项集: {葡萄酒, 尿布, 豆奶} 就是一个频繁项集的例子。 关联规则: 尿布 -&gt; 葡萄酒 就是一个关联规则。这意味着如果顾客买了尿布，那么他很可能会买葡萄酒。 支持度: 数据集中包含该项集的记录所占的比例。例如上图中，{豆奶} 的支持度为 4/5。{豆奶, 尿布} 的支持度为 3/5。 可信度: 针对一条诸如 {尿布} -&gt; {葡萄酒} 这样具体的关联规则来定义的。这条规则的 可信度 被定义为 支持度({尿布, 葡萄酒})/支持度({尿布})，支持度({尿布, 葡萄酒}) = 3/5，支持度({尿布}) = 4/5，所以 {尿布} -&gt; {葡萄酒} 的可信度 = 3/5 / 4/5 = 3/4 = 0.75。 支持度 和 可信度 是用来量化 关联分析 是否成功的一个方法。 假设想找到支持度大于 0.8 的所有项集，应该如何去做呢？ 一个办法是生成一个物品所有可能组合的清单，然后对每一种组合统计它出现的频繁程度，但是当物品成千上万时，上述做法就非常非常慢了。 我们需要详细分析下这种情况并讨论下 Apriori 原理，该原理会减少关联规则学习时所需的计算量。 k项集如果事件A中包含k个元素，那么称这个事件A为k项集，并且事件A满足最小支持度阈值的事件称为频繁k项集。 由频繁项集产生强关联规则 K维数据项集LK是频繁项集的必要条件是它所有K-1维子项集也为频繁项集，记为LK-1 如果K维数据项集LK的任意一个K-1维子集Lk-1，不是频繁项集，则K维数据项集LK本身也不是最大数据项集。 Lk是K维频繁项集，如果所有K-1维频繁项集合Lk-1中包含LK的K-1维子项集的个数小于K，则Lk不可能是K维最大频繁数据项集。 同时满足最小支持度阀值和最小置信度阀值的规则称为强规则。 算法原理Apriori 思想 算法思想 首先找出所有的频集，这些项集出现的频繁性至少和预定义的最小支持度一样。然后由频集产生强关联规则，这些规则必须满足最小支持度和最小可信度。然后使用第1步找到的频集产生期望的规则，产生只包含集合的项的所有规则，其中每一条规则的右部只有一项，这里采用的是中规则的定义。一旦这些规则被生成，那么只有那些大于用户给定的最小可信度的规则才被留下来。 Apriori算法过程 第一步通过迭代，检索出事务数据库中的所有频繁项集，即支持度不低于用户设定的阈值的项集；第二步利用频繁项集构造出满足用户最小信任度的规则。 具体做法就是：首先找出频繁1-项集，记为L1；然后利用L1来产生候选项集C2，对C2中的项进行判定挖掘出L2，即频繁2-项集；不断如此循环下去直到无法发现更多的频繁k-项集为止。每挖掘一层Lk就需要扫描整个数据库一遍。算法利用了一个性质：任一频繁项集的所有非空子集也必须是频繁的。 Apriori 原理假设我们一共有 4 个商品: 商品0, 商品1, 商品2, 商品3。 所有可能的情况如下: 如果我们计算所有组合的支持度，也需要计算 15 次。即 \( 2^N - 1 = 2^4 - 1 = 15 \)。随着物品的增加，计算的次数呈指数的形式增长 。为了降低计算次数和时间，研究人员发现了一种所谓的 Apriori 原理，即某个项集是频繁的，那么它的所有子集也是频繁的。 例如，如果 {0, 1} 是频繁的，那么 {0}, {1} 也是频繁的。 该原理直观上没有什么帮助，但是如果反过来看就有用了，也就是说如果一个项集是 非频繁项集，那么它的所有超集也是非频繁项集，如下图所示: 在图中我们可以看到，已知灰色部分 {2,3} 是 非频繁项集，那么利用上面的知识，我们就可以知道 {0,2,3} {1,2,3} {0,1,2,3} 都是 非频繁的。 也就是说，计算出 {2,3} 的支持度，知道它是 非频繁 的之后，就不需要再计算 {0,2,3} {1,2,3} {0,1,2,3} 的支持度，因为我们知道这些集合不会满足我们的要求。 使用该原理就可以避免项集数目的指数增长，从而在合理的时间内计算出频繁项集。 Apriori 算法优缺点 优点：易编码实现 缺点：在大数据集上可能较慢 适用数据类型：数值型 或者 标称型数据。 Apriori 算法流程步骤： 收集数据：使用任意方法。 准备数据：任何数据类型都可以，因为我们只保存集合。 分析数据：使用任意方法。 训练数据：使用Apiori算法来找到频繁项集。 测试算法：不需要测试过程。 使用算法：用于发现频繁项集以及物品之间的关联规则。 应用场景Apriori 算法广泛应用于各种领域，通过对数据的关联性进行了分析和挖掘，挖掘出的这些信息在决策制定过程中具有重要的参考价值。 Apriori算法广泛应用于消费市场价格分析中 它能够很快的求出各种产品之间的价格关系和它们之间的影响。通过数据挖掘，市场商人可以瞄准目标客户，采用个人股票行市、最新信息、特殊的市场推广活动或其他一些特殊的信息手段，从而极大地减少广告预算和增加收入。百货商场、超市和一些老字型大小的零售店也在进行数据挖掘，以便猜测这些年来顾客的消费习惯。 Apriori算法应用于网络安全领域，比如网络入侵检测技术中。 早期中大型的电脑系统中都收集审计信息来建立跟踪档，这些审计跟踪的目的多是为了性能测试或计费，因此对攻击检测提供的有用信息比较少。它通过模式的学习和训练可以发现网络用户的异常行为模式。采用作用度的Apriori算法削弱了Apriori算法的挖掘结果规则，是网络入侵检测系统可以快速的发现用户的行为模式，能够快速的锁定攻击者，提高了基于关联规则的入侵检测系统的检测性。 Apriori算法应用于高校管理中。随着高校贫困生人数的不断增加，学校管理部门资助工作难度也越加增大。针对这一现象，提出一种基于数据挖掘算法的解决方法。将关联规则的Apriori算法应用到贫困助学体系中，并且针对经典Apriori挖掘算法存在的不足进行改进，先将事务数据库映射为一个布尔矩阵，用一种逐层递增的思想来动态的分配内存进行存储，再利用向量求”与”运算，寻找频繁项集。实验结果表明，改进后的Apriori算法在运行效率上有了很大的提升，挖掘出的规则也可以有效地辅助学校管理部门有针对性的开展贫困助学工作。 Apriori算法被广泛应用于移动通信领域。 移动增值业务逐渐成为移动通信市场上最有活力、最具潜力、最受瞩目的业务。随着产业的复苏，越来越多的增值业务表现出强劲的发展势头，呈现出应用多元化、营销品牌化、管理集中化、合作纵深化的特点。针对这种趋势，在关联规则数据挖掘中广泛应用的Apriori算法被很多公司应用。依托某电信运营商正在建设的增值业务Web数据仓库平台，对来自移动增值业务方面的调查数据进行了相关的挖掘处理，从而获得了关于用户行为特征和需求的间接反映市场动态的有用信息，这些信息在指导运营商的业务运营和辅助业务提供商的决策制定等方面具有十分重要的参考价值。 Apriori 实例理解实例理解1一个大型超级市场根据最小存货单位（SKU）来追踪每件物品的销售数据。从而也可以得知哪里物品通常被同时购买。通过采用先验算法来从这些销售数据中创建频繁购买商品组合的清单是一个效率适中的方法。假设交易数据库包含以下子集{1,2,3,4}，{1,2}，{2,3,4}，{2,3}，{1,2,4}，{3,4}，{2,4}。每个标号表示一种商品，如“黄油”或“面包”。先验算法首先要分别计算单个商品的购买频率。下表解释了先验算法得出的单个商品购买频率。 商品编号 购买次数 1 3 2 6 3 4 4 5 然后我们可以定义一个最少购买次数来定义所谓的“频繁”。在这个例子中，我们定义最少的购买次数为3。因此，所有的购买都为频繁购买。接下来，就要生成频繁购买商品的组合及购买频率。先验算法通过修改树结构中的所有可能子集来进行这一步骤。然后我们仅重新选择频繁购买的商品组合： 商品编号 购买次数 {1,2} 3 {2,3} 3 {2,4} 4 {3,4} 3 并且生成一个包含3件商品的频繁组合列表（通过将频繁购买商品组合与频繁购买的单件商品联系起来得出）。在上述例子中，不存在包含3件商品组合的频繁组合。最常见的3件商品组合为{1,2,4}和{2,3,4}，但是他们的购买次数为2，低于我们设定的最低购买次数。 实例理解2假设有一个数据库D，其中有4个事务记录，分别表示为： TID Items T1 l1,l3,l4 T2 l2,l3,l5 T3 l1,l2,l3,l5 T4 l2,l5 这里预定最小支持度minSupport=2,下面用图例说明算法运行的过程：1、扫描D，对每个候选项进行支持度计数得到表C1: 项集 支持度计数 {l1} 2 {l2} 3 {l3} 3 {l4} l {l5} 3 2、比较候选项支持度计数与最小支持度minSupport（假设为2），产生1维最大项目集L1： 项集 支持度计数 {l1} 2 {l2} 3 {l3} 3 {l5} 3 3、由L1产生候选项集C2： 项集 {l1,l2} {l1,l3} {l1,l5} {l2,l3} {l2,l5} {l3,l5} 4、扫描D，对每个候选项集进行支持度计数: 项集 支持度计数 {l1,l2} 1 {l1,l3} 2 {l1,l5} 1 {l2,l3} 2 {l2,l5} 3 {l3,l5} 2 5、比较候选项支持度计数与最小支持度minSupport，产生2维最大项目集L2： 项集 支持度计数 {l1,l3} 2 {l2,l3} 2 {l2,l5} 3 {l3,l5} 2 6、由L2产生候选项集C3： 项集 {l2,l3,l5} 7、比较候选项支持度计数与最小支持度minSupport，产生3维最大项目集L3： 项集 支持度计数 {l2,l3,l5} 2 算法终止。 从整体同样的能说明此过程 首先我们收集所有数据集（可以理解为商品清单），经过数据预处理后如Database TDB所示。我们扫描数据集，经过第一步对每个候选项进行支持度计数得到表C1，比较候选项支持度计数与最小支持度minSupport（假设最小支持度为2），产生1维最大项目集L1。再对L1进行组合产生候选项集C2。第二步我们对C2进行支持度计数，比较候选项支持度计数与最小支持度minSupport，产生2维最大项目集L2。由L2产生候选项集C3，对C3进行支持度计数，使用Apriori性质剪枝：频繁项集的所有子集必须是频繁的，对候选项C3，我们可以删除其子集为非频繁的选项，{A,B,C}的2项子集是{A,B},{A,C},{B,C}，其中{A,B}不是L2的元素，所以删除这个选项；{A,C,E}的2项子集是{A,C},{A,E},{C,E}，其中{A,E} 不是L2的元素，所以删除这个选项；{B,C,E}的2项子集是{B,C},{B,E},{C,E}，它的所有2－项子集都是L2的元素，因此保留这个选项。这样，剪枝后得到{B,C,E}，比较候选项支持度计数与最小支持度minSupport，产生3维最大项目集L3：继续进行没有满足条件，算法终止。 Apriori 算法实现关联分析的目标包括两项:发现频繁项集和发现关联规则。Apriori算法是发现频繁项集的一种方法。 Apriori 算法的两个输入参数分别是最小支持度和数据集。该算法首先会生成所有单个物品的项集列表。接着扫描交易记录来查看哪些项集满足最小支持度要求，那些不满足最小支持度要求的集合会被去掉。然后对剩下来的集合进行组合以生成包含两个元素的项集。接下来再重新扫描交易记录，去掉不满足最小支持度的项集。该过程重复进行直到所有项集被去掉。 生成候选项集 下面会创建一个用于构建初始集合的函数，也会创建一个通过扫描数据集以寻找交易记录子集的函数， 数据扫描的伪代码如下: - 对数据集中的每条交易记录 tran - 对每个候选项集 can - 检查一下 can 是否是 tran 的子集: 如果是则增加 can 的计数值 - 对每个候选项集 - 如果其支持度不低于最小值，则保留该项集 - 返回所有频繁项集列表 以下是一些辅助函数。 第一步加载数据集，123# 加载数据集def loadDataSet(): return [[1, 3, 4], [2, 3, 5], [1, 2, 3, 5], [2, 5]] 运行结果如下： [[1, 3, 4], [2, 3, 5], [1, 2, 3, 5], [2, 5]] 第二步创建集合 C1。对 dataSet 进行去重，排序，放入 list 中，然后转换所有的元素为 frozenset 1234567891011'''创建集合C1即对dataSet去重排序'''def createC1(dataSet): C1 = [] for transaction in dataSet: for item in transaction: if not [item] in C1: C1.append([item]) C1.sort() # frozenset表示冻结的set 集合，元素无改变把它当字典的 key 来使用 return C1 # return map(frozenset, C1) 运行结果如下，注意map(frozenset, C1)在后面会用到，注意便于计数处理： [[1], [2], [3], [4], [5]] 第三步计算候选数据集CK在数据集D中的支持度。1234567891011121314151617181920212223242526''' 计算候选数据集CK在数据集D中的支持度，返回大于最小支持度的数据'''def scanD(D,Ck,minSupport): # ssCnt 临时存放所有候选项集和频率. ssCnt = &#123;&#125; for tid in D: # print('1:',tid) for can in map(frozenset,Ck): #每个候选项集can # print('2:',can.issubset(tid),can,tid) if can.issubset(tid): if not can in ssCnt: ssCnt[can] = 1 else: ssCnt[can] +=1 numItems = float(len(D)) # 所有项集数目 # 满足最小支持度的频繁项集 retList = [] # 满足最小支持度的频繁项集和频率 supportData = &#123;&#125; for key in ssCnt: support = ssCnt[key]/numItems #除以总的记录条数，即为其支持度 if support &gt;= minSupport: retList.insert(0,key) #超过最小支持度的项集，将其记录下来。 supportData[key] = support return retList, supportData 运行结果如下： 满足最小支持度的频繁项集是： [frozenset({1}), frozenset({3}), frozenset({2}), frozenset({5})] 频繁项集的支持度 {frozenset({4}): 0.25, frozenset({5}): 0.75, frozenset({2}): 0.75, frozenset({3}): 0.75, frozenset({1}): 0.5} 第四步 根据上步Lk计算可能的候选项集 Ck123456789101112131415''' Apriori算法：输入频繁项集列表Lk，输出所有可能的候选项集 Ck'''def aprioriGen(Lk, k): retList = [] # 满足条件的频繁项集 lenLk = len(Lk) for i in range(lenLk): for j in range(i+1, lenLk): L1 = list(Lk[i])[: k-2] L2 = list(Lk[j])[: k-2] # print '-----i=', i, k-2, Lk, Lk[i], list(Lk[i])[: k-2] # print '-----j=', j, k-2, Lk, Lk[j], list(Lk[j])[: k-2] L1.sort() L2.sort() if L1 == L2: retList.append(Lk[i] | Lk[j]) return retList L1，k=2的运行结果： [frozenset({1, 3}), frozenset({1, 2}), frozenset({1, 5}), frozenset({2, 3}), frozenset({3, 5}), frozenset({2, 5})] 第五步： 找出满足最小支持度的频繁项集。123456789101112131415161718192021222324252627282930'''找出数据集中支持度不小于最小支持度的候选项集以及它们的支持度即频繁项集。算法思想：首先构建集合C1，然后扫描数据集来判断这些只有一个元素的项集是否满足最小支持度。满足最小支持度要求的项集构成集合L1。然后L1 中的元素相互组合成C2，C2再进一步过滤变成L2，以此类推，直到C_n的长度为0时结束，即可找出所有频繁项集的支持度。返回：L 频繁项集的全集 supportData 所有元素和支持度的全集'''def apriori(dataSet, minSupport=0.5): # C1即对dataSet去重排序，然后转换所有的元素为frozenset C1 = createC1(dataSet) # 对每一行进行 set 转换，然后存放到集合中 D = list(map(set, dataSet)) # 计算候选数据集C1在数据集D中的支持度，并返回支持度大于minSupport 的数据 L1, supportData = scanD(D, C1, minSupport) # L 加了一层 list, L一共 2 层 list L = [L1];k = 2 # 判断L第k-2项的数据长度是否&gt;0即频繁项集第一项。第一次执行时 L 为 [[frozenset([1]), frozenset([3]), frozenset([2]), frozenset([5])]]。L[k-2]=L[0]=[frozenset([1]), frozenset([3]), frozenset([2]), frozenset([5])]，最后面 k += 1 while (len(L[k-2]) &gt; 0): Ck = aprioriGen(L[k-2], k) # 例如: 以 &#123;0&#125;,&#123;1&#125;,&#123;2&#125; 为输入且 k = 2 则输出 &#123;0,1&#125;, &#123;0,2&#125;, &#123;1,2&#125;. 以 &#123;0,1&#125;,&#123;0,2&#125;,&#123;1,2&#125; 为输入且 k = 3 则输出 &#123;0,1,2&#125; # 返回候选数据集CK在数据集D中的支持度大于最小支持度的数据 Lk, supK = scanD(D, Ck, minSupport) # 保存所有候选项集的支持度，如果字典没有就追加元素，如果有就更新元素 supportData.update(supK) if len(Lk) == 0: break # Lk 表示满足频繁子项的集合，L 元素在增加，例如: # l=[[set(1), set(2), set(3)]] # l=[[set(1), set(2), set(3)], [set(1, 2), set(2, 3)]] L.append(Lk) k += 1 return L, supportData 我们写个测试以上代码1234567891011121314151617'''测试频繁项集生产'''def testApriori(): # 加载测试数据集 dataSet = loadDataSet() print ('dataSet: ', dataSet) # Apriori 算法生成频繁项集以及它们的支持度 L1, supportData1 = apriori(dataSet, minSupport=0.7) print ('L(0.7): ', L1) print ('supportData(0.7): ', supportData1) print ('-&gt;-&gt;-&gt;-&gt;-&gt;-&gt;-&gt;-&gt;-&gt;-&gt;-&gt;-&gt;-&gt;-&gt;-&gt;-&gt;-&gt;-&gt;-&gt;-&gt;-&gt;-&gt;-&gt;-&gt;-&gt;-&gt;-&gt;-&gt;') # Apriori 算法生成频繁项集以及它们的支持度 L2, supportData2 = apriori(dataSet, minSupport=0.5) print ('L(0.5): ', L2) print ('supportData(0.5): ', supportData2) 运行结果如下： dataSet: [[1, 3, 4], [2, 3, 5], [1, 2, 3, 5], [2, 5]] L(0.7): [[frozenset({3}), frozenset({2}), frozenset({5})], [frozenset({2, 5})]] supportData(0.7): {frozenset({5}): 0.75, frozenset({3}): 0.75, frozenset({3, 5}): 0.5, frozenset({4}): 0.25, frozenset({2, 3}): 0.5, frozenset({2, 5}): 0.75, frozenset({1}): 0.5, frozenset({2}): 0.75} -&gt;-&gt;-&gt;-&gt;-&gt;-&gt;-&gt;-&gt;-&gt;-&gt;-&gt;-&gt;-&gt;-&gt;-&gt;-&gt;-&gt;-&gt;-&gt;-&gt;-&gt;-&gt;-&gt;-&gt;-&gt;-&gt;-&gt;-&gt; L(0.5): [[frozenset({1}), frozenset({3}), frozenset({2}), frozenset({5})], [frozenset({3, 5}), frozenset({1, 3}), frozenset({2, 5}), frozenset({2, 3})], [frozenset({2, 3, 5})]] supportData(0.5): {frozenset({5}): 0.75, frozenset({3}): 0.75, frozenset({2, 3, 5}): 0.5, frozenset({1, 2}): 0.25, frozenset({1, 5}): 0.25, frozenset({3, 5}): 0.5, frozenset({4}): 0.25, frozenset({2, 3}): 0.5, frozenset({2, 5}): 0.75, frozenset({1}): 0.5, frozenset({1, 3}): 0.5, frozenset({2}): 0.75} 到这一步，我们就找出我们所需要的 频繁项集 和他们的 支持度 了，接下来再找出关联规则即可！ 第六步从频繁项集中挖掘关联规则集合中的元素是不重复的，但我们想知道基于这些元素能否获得其它内容。 某个元素或某个元素集合可能会推导出另一个元素。 从先前 杂货店 的例子可以得到，如果有一个频繁项集 {豆奶,莴苣}，那么就可能有一条关联规则 “豆奶 -&gt; 莴苣”。 这意味着如果有人买了豆奶，那么在统计上他会购买莴苣的概率比较大。 但是，这一条件反过来并不总是成立。 也就是说 “豆奶 -&gt; 莴苣” 统计上显著，那么 “莴苣 -&gt; 豆奶” 也不一定成立。 前面我们给出了 频繁项集 的量化定义，即它满足最小支持度要求。对于 关联规则，我们也有类似的量化方法，这种量化指标称之为 可信度。一条规则 A -&gt; B 的可信度定义为 support(A | B) / support(A)。（注意: 在 python 中 | 表示集合的并操作，而数学书集合并的符号是 U）。A | B 是指所有出现在集合 A 或者集合 B 中的元素。由于我们先前已经计算出所有 频繁项集 的支持度了，现在我们要做的只不过是提取这些数据做一次除法运算即可。 一个频繁项集可以产生多少条关联规则呢？ 如下图所示，给出的是项集 {0,1,2,3} 产生的所有关联规则: 与我们前面的 频繁项集 生成一样，我们可以为每个频繁项集产生许多关联规则。如果能减少规则的数目来确保问题的可解析，那么计算起来就会好很多。通过观察，我们可以知道，如果某条规则并不满足 最小可信度 要求，那么该规则的所有子集也不会满足 最小可信度 的要求。如上图所示，假设 123 -&gt; 3 并不满足最小可信度要求，那么就知道任何左部为 {0,1,2} 子集的规则也不会满足 最小可信度 的要求。 即 12 -&gt; 03 , 02 -&gt; 13 , 01 -&gt; 23 , 2 -&gt; 013, 1 -&gt; 023, 0 -&gt; 123 都不满足 最小可信度 要求。可以利用关联规则的上述性质属性来减少需要测试的规则数目，跟先前 Apriori 算法的套路一样。以下是一些辅助函数: 计算可信度123456789101112131415161718192021'''计算可信度（confidence）Args: freqSet 频繁项集中的元素，例如: frozenset([1, 3]) H 频繁项集中的元素的集合，例如: [frozenset([1]), frozenset([3])] supportData 所有元素的支持度的字典 brl 关联规则列表的空数组 minConf 最小可信度Returns: prunedH 记录 可信度大于阈值的集合'''def calcConf(freqSet, H, supportData, brl, minConf=0.7): # 记录可信度大于最小可信度（minConf）的集合 prunedH = [] for conseq in H: # 假设 freqSet = frozenset([1, 3]), H = [frozenset([1]), frozenset([3])]，那么现在需要求出 frozenset([1]) -&gt; frozenset([3]) 的可信度和 frozenset([3]) -&gt; frozenset([1]) 的可信度 conf = supportData[freqSet]/supportData[freqSet-conseq] # 支持度定义: a -&gt; b = support(a | b) / support(a). 假设 freqSet = frozenset([1, 3]), conseq = [frozenset([1])]，那么 frozenset([1]) 至 frozenset([3]) 的可信度为 = support(a | b) / support(a) = supportData[freqSet]/supportData[freqSet-conseq] = supportData[frozenset([1, 3])] / supportData[frozenset([1])] if conf &gt;= minConf: # 只要买了 freqSet-conseq 集合，一定会买 conseq 集合（freqSet-conseq 集合和 conseq集合 是全集） print (freqSet-conseq, '--&gt;', conseq, 'conf:', conf) brl.append((freqSet-conseq, conseq, conf)) prunedH.append(conseq) return prunedH 递归计算频繁项集的规则1234567891011121314151617181920212223242526272829"""递归计算频繁项集的规则 Args: freqSet 频繁项集中的元素，例如: frozenset([2, 3, 5]) H 频繁项集中的元素的集合，例如: [frozenset([2]), frozenset([3]), frozenset([5])] supportData 所有元素的支持度的字典 brl 关联规则列表的数组 minConf 最小可信度"""def rulesFromConseq(freqSet, H, supportData, brl, minConf=0.7): # H[0] 是 freqSet 的元素组合的第一个元素，并且 H 中所有元素的长度都一样，长度由 aprioriGen(H, m+1) 这里的 m + 1 来控制 # 该函数递归时，H[0] 的长度从 1 开始增长 1 2 3 ... # 假设 freqSet = frozenset([2, 3, 5]), H = [frozenset([2]), frozenset([3]), frozenset([5])] # 那么 m = len(H[0]) 的递归的值依次为 1 2 # 在 m = 2 时, 跳出该递归。假设再递归一次，那么 H[0] = frozenset([2, 3, 5])，freqSet = frozenset([2, 3, 5]) ，没必要再计算 freqSet 与 H[0] 的关联规则了。 m = len(H[0]) if (len(freqSet) &gt; (m + 1)): # 生成 m+1 个长度的所有可能的 H 中的组合，假设 H = [frozenset([2]), frozenset([3]), frozenset([5])] # 第一次递归调用时生成 [frozenset([2, 3]), frozenset([2, 5]), frozenset([3, 5])] # 第二次 。。。没有第二次，递归条件判断时已经退出了 Hmp1 = aprioriGen(H, m+1) # 返回可信度大于最小可信度的集合 Hmp1 = calcConf(freqSet, Hmp1, supportData, brl, minConf) # print ('Hmp1=', Hmp1) # print ('len(Hmp1)=', len(Hmp1), 'len(freqSet)=', len(freqSet)) # 计算可信度后，还有数据大于最小可信度的话，那么继续递归调用，否则跳出递归 if (len(Hmp1) &gt; 1): # print '----------------------', Hmp1 # print len(freqSet), len(Hmp1[0]) + 1 rulesFromConseq(freqSet, Hmp1, supportData, brl, minConf) 生成关联规则12345678910111213141516171819202122'''生成关联规则 Args: L 频繁项集列表 supportData 频繁项集支持度的字典 minConf 最小置信度 Returns: bigRuleList 可信度规则列表（关于 (A-&gt;B+置信度) 3个字段的组合）'''def generateRules(L, supportData, minConf=0.7): bigRuleList = [] for i in range(1, len(L)): # 获取频繁项集中每个组合的所有元素 for freqSet in L[i]: # 组合总的元素并遍历子元素，转化为 frozenset集合存放到 list 列表中 H1 = [frozenset([item]) for item in freqSet] # print(H1) # 2 个的组合else, 2 个以上的组合 if if (i &gt; 1): rulesFromConseq(freqSet, H1, supportData, bigRuleList, minConf) else: calcConf(freqSet, H1, supportData, bigRuleList, minConf) return bigRuleList 到这里为止，通过调用 generateRules 函数即可得出我们所需的 关联规则。测试下结果： 12345678910111213def testGenerateRules(): # 加载测试数据集 dataSet = loadDataSet() print ('dataSet: ', dataSet) # Apriori 算法生成频繁项集以及它们的支持度 L1, supportData1 = apriori(dataSet, minSupport=0.5) print ('L(0.7): ', L1) print ('supportData(0.7): ', supportData1) # 生成关联规则 rules = generateRules(L1, supportData1, minConf=0.5) print ('rules: ', rules) 运行结果如下： dataSet: [[1, 3, 4], [2, 3, 5], [1, 2, 3, 5], [2, 5]] L(0.7): [[frozenset({1}), frozenset({3}), frozenset({2}), frozenset({5})], [frozenset({3, 5}), frozenset({1, 3}), frozenset({2, 5}), frozenset({2, 3})], [frozenset({2, 3, 5})]] supportData(0.7): {frozenset({5}): 0.75, frozenset({3}): 0.75, frozenset({2, 3, 5}): 0.5, frozenset({1, 2}): 0.25, frozenset({1, 5}): 0.25, frozenset({3, 5}): 0.5, frozenset({4}): 0.25, frozenset({2, 3}): 0.5, frozenset({2, 5}): 0.75, frozenset({1}): 0.5, frozenset({1, 3}): 0.5, frozenset({2}): 0.75} frozenset({5}) --&gt; frozenset({3}) conf: 0.6666666666666666 frozenset({3}) --&gt; frozenset({5}) conf: 0.6666666666666666 frozenset({3}) --&gt; frozenset({1}) conf: 0.6666666666666666 frozenset({1}) --&gt; frozenset({3}) conf: 1.0 frozenset({5}) --&gt; frozenset({2}) conf: 1.0 frozenset({2}) --&gt; frozenset({5}) conf: 1.0 frozenset({3}) --&gt; frozenset({2}) conf: 0.6666666666666666 frozenset({2}) --&gt; frozenset({3}) conf: 0.6666666666666666 frozenset({5}) --&gt; frozenset({2, 3}) conf: 0.6666666666666666 frozenset({3}) --&gt; frozenset({2, 5}) conf: 0.6666666666666666 frozenset({2}) --&gt; frozenset({3, 5}) conf: 0.6666666666666666 rules: [(frozenset({5}), frozenset({3}), 0.6666666666666666), (frozenset({3}), frozenset({5}), 0.6666666666666666), (frozenset({3}), frozenset({1}), 0.6666666666666666), (frozenset({1}), frozenset({3}), 1.0), (frozenset({5}), frozenset({2}), 1.0), (frozenset({2}), frozenset({5}), 1.0), (frozenset({3}), frozenset({2}), 0.6666666666666666), (frozenset({2}), frozenset({3}), 0.6666666666666666), (frozenset({5}), frozenset({2, 3}), 0.6666666666666666), (frozenset({3}), frozenset({2, 5}), 0.6666666666666666), (frozenset({2}), frozenset({3, 5}), 0.6666666666666666)] 实际应用：发现毒蘑菇的相似特性实际需求菌类蘑菇食用对人体有益，现在市场上很受欢迎。假设你在一个山林里，遇到很多蘑菇，有些可以食用有些有毒。此刻，你或许会询问山中常驻居民，居民非常友好的告诉你伞菇上有彩色花斑的，样式好看的等等有毒。他会通过判断蘑菇的大小，高度，颜色，形状等23个特征决定蘑菇有毒，我把将居民的经验收集在mushromm.dat里面，以下是部分数据： 1 3 9 13 23 25 34 36 38 40 52 54 59 63 67 76 85 86 90 93 98 107 113 2 3 9 14 23 26 34 36 39 40 52 55 59 63 67 76 85 86 90 93 99 108 114 2 4 9 15 23 27 34 36 39 41 52 55 59 63 67 76 85 86 90 93 99 108 115 其中第一列1代表可以食用2代表有毒。其他各列代表不同特征。实际中，我们不可能对比23个特征，我们只需要找出毒蘑菇特有的几个特征即可，比如颜色彩色，形状方形等。我们自然语言描述很容易，就是看到蘑菇，对比下毒蘑菇的几个特征，不具备就可以采摘食用了。 到目前为止，我们清楚的采用毒蘑菇共同特征判断，那么如何知道毒蘑菇共同特征呢？我们就可以使用本节学习的先验算法Apriori进行关联规则找出毒蘑菇的共同特性。 算法实现 得到数据集 dataSet = [line.split() for line in open(&quot;./mushroom.dat&quot;).readlines()] 利用我们的先验算法计算L频繁项集和所有元素支持度的全集 L, supportData = apriori(dataSet, minSupport=0.4) 找出关于2的频繁子项，就知道如果是毒蘑菇，那么出现频繁的也可能是毒蘑菇 for item in L[2]: if item.intersection(&#39;2&#39;): print (item) 毒蘑菇的相似特性运行结果frozenset({&#39;59&#39;, &#39;39&#39;, &#39;2&#39;}) frozenset({&#39;59&#39;, &#39;85&#39;, &#39;2&#39;}) frozenset({&#39;34&#39;, &#39;39&#39;, &#39;2&#39;}) frozenset({&#39;90&#39;, &#39;86&#39;, &#39;2&#39;}) frozenset({&#39;34&#39;, &#39;90&#39;, &#39;2&#39;}) frozenset({&#39;39&#39;, &#39;86&#39;, &#39;2&#39;}) frozenset({&#39;85&#39;, &#39;28&#39;, &#39;2&#39;}) frozenset({&#39;59&#39;, &#39;86&#39;, &#39;2&#39;}) frozenset({&#39;34&#39;, &#39;85&#39;, &#39;2&#39;}) frozenset({&#39;90&#39;, &#39;39&#39;, &#39;2&#39;}) frozenset({&#39;39&#39;, &#39;85&#39;, &#39;2&#39;}) frozenset({&#39;34&#39;, &#39;59&#39;, &#39;2&#39;}) frozenset({&#39;34&#39;, &#39;86&#39;, &#39;2&#39;}) frozenset({&#39;90&#39;, &#39;59&#39;, &#39;2&#39;}) frozenset({&#39;85&#39;, &#39;86&#39;, &#39;2&#39;}) frozenset({&#39;90&#39;, &#39;85&#39;, &#39;2&#39;}) frozenset({&#39;63&#39;, &#39;85&#39;, &#39;2&#39;}) 如上结果显示，遇到如上特征就很可能是毒蘑菇不能食用的啦。我们上面实验设置的2-频繁项集，根据实际需要可以调整k-频繁项集。 参考文献 数据挖掘十大算法：https://wizardforcel.gitbooks.io/dm-algo-top10/content/apriori.html 中文维基百科：https://zh.wikipedia.org/wiki/%E5%85%88%E9%AA%8C%E7%AE%97%E6%B3%95 GitHub：https://github.com/BaiNingchao/MachineLearning-1 图书：《机器学习实战》 图书：《自然语言处理理论与实战》 完整代码下载 源码请进【机器学习和自然语言QQ群：436303759】文件下载： 作者声明 本文版权归作者【白宁超】所有，转载请联系作者：1938036263@qq.com，但未经作者同意禁止转载，转载后需在文章页面明显位置给出原文连接，否则保留追究法律责任的权利。]]></content>
      <categories>
        <category>机器学习</category>
        <category>Apriori</category>
      </categories>
      <tags>
        <tag>机器学习算法</tag>
        <tag>Python</tag>
        <tag>文本聚类</tag>
        <tag>Apriori</tag>
        <tag>关联规则</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[Sublime+Anaconda开发环境部署教程]]></title>
    <url>%2F2018%2F09%2F20%2FSublime-Anaconda%E5%BC%80%E5%8F%91%E7%8E%AF%E5%A2%83%E9%83%A8%E7%BD%B2%E6%95%99%E7%A8%8B%2F</url>
    <content type="text"><![CDATA[摘要：随着人工智能的快速发展，深度学习、机器学习、自然语言处理和数据挖掘等技术的应用愈加广泛。然而身为初学者，要想快速入门这些前沿技术总是存在着各种各样的困难。古语说“工欲善其事，必先利其器”，本课程的“器”就是开发环境部署，本文主要介绍Sublime的安装部署与使用。最后，我们将用一个简单的实战案例让读者亲身领略编程之美。（本文原创编著，转载注明出处.） Sublime Text和Anaconda介绍 Sublime Text简介 Sublime Text是一套跨平台的文本编辑器，支持基于Python的插件。Sublime Text 是专有软件，可通过包Package扩充本身的功能。大多数的包使用自由软件授权发布，并由社区建设维护。Sublime Text是由程序员Jon Skinner于2008年1月份所开发出来，它最初被设计为一个具有丰富扩展功能的Vim。其具有漂亮的用户界面和强大的功能，例如代码缩略图，Python的插件，代码段等。还可自定义键绑定，菜单和工具栏。Sublime Text 的主要功能包括：拼写检查，书签，完整的 Python API ， Goto 功能，即时项目切换，多选择，多窗口等等。Sublime Text 是一个跨平台的编辑器，同时支持Windows、Linux、Mac OS X等操作系统。 Sublime Text 支持众多编程语言，并支持语法上色。内置支持的编程语言包含：ActionScript、AppleScript、ASP、batch files、C、C++、C#、Clojure、CSS、D、Diff、Erlang、Go、Graphviz (DOT)、Groovy、Haskell、HTML、Java、JSP、JavaScript、JSON、LaTeX、Lisp、Lua、Makefiles、Markdown、MATLAB、Objective-C、OCaml、Perl、PHP、Python、R、Rails、Regular Expressions、reStructuredText、Ruby、Scala、shell scripts (Bash)、SQL、Tcl、Textile、XML、XSL 和 YAML。用户可通过下载外挂支持更多的编程语言。 Sublime Text优点 主流前端开发编辑器 体积较小，运行速度快 文本功能强大 支持编译功能且可在控制台看到输出 内嵌python解释器支持插件开发以达到可扩展目的 Package Control：ST支持的大量插件可通过其进行管理 Anaconda简介 Anaconda是一个用于科学计算的Python发行版，支持 Linux, Mac, Windows系统，提供了包管理与环境管理的功能，可以很方便地解决多版本python并存、切换以及各种第三方包安装问题。Anaconda利用工具/命令conda来进行package和environment的管理，并且已经包含了Python和相关的配套工具。这里先解释下conda、anaconda这些概念的差别。conda可以理解为一个工具，也是一个可执行命令，其核心功能是包管理与环境管理。包管理与pip的使用类似，环境管理则允许用户方便地安装不同版本的python并可以快速切换。Anaconda则是一个打包的集合，里面预装好了conda、某个版本的python、众多packages、科学计算工具等等，所以也称为Python的一种发行版。其实还有Miniconda，顾名思义，它只包含最基本的内容——python与conda，以及相关的必须依赖项，对于空间要求严格的用户，Miniconda是一个不错的选择。 开发环境安装与配置 工具包的准备 本文主要介绍Windows下的安装配置，关于Linux和MacOS下的安装，后文给出了扩展文章，需要的读者可自行在线下载。Sublime Text3安装包下载地址（http://www.sublimetext.com/3）。点击该网址进入Sublime主页，根据本机操作系统选择相关工具包下载。本文示范下载Windows64 bit。具体详见下图： Anaconda安装包下载地址（https://www.anaconda.com/download/）进入下载页面显示Python3.0以上版本和Python2.0以上版本。关于Python3和Python2的区别请访问（http://www.runoob.com/python/python-2x-3x.html）查看，在此不做赘述。一般推荐下载Python3.0以上版本。具体详见图所示： Anaconda安装 (1) 安装Anaconda集成环境，将下载后的Anaconda包双击打开如图所示： (2) 然后一直“Next”下去，直到完成配置。（环境变量自动配置），配置完成后，查看是否成功。打开主菜单-&gt;所有应用查看安装，如图所示： (3) 打开cmd进入dos命令下，输入conda list 查看集成的python包。如图所示： (4) 如果想添加新的python包，打开Anaconda官网：https://anaconda.org/search进行查找，比如想找到机器学习工具包scikit-learn如图所示： 至此我们就完成了Anaconda安装配置工作，以及对包文件的自定义下载安装。需要注明的是Anaconda自身集成了Python、pip、nltk、numpy、matplotlib等一系列常用包。现在，我们已经可以对python进行操作了。考虑到熟悉python开发的人员，常用Pycharm开发工具，熟悉java的开发人员常用Eclipse开发工具，熟悉C#的开发人员常用VS开发工具。然后我们将Anaconda集成到PyDev、Pycharm、Eclipse、VS等编译环境即可，诸如此类就不一一列举了。考虑到新学一种语言要重新学习一种编程环境，这样极其不方便。那么能不能找到一款编程工具可以通用以上语言？或许这样还不够，如果它还能跨Linux、Windows、MacOS那就更好了。本书强烈推荐的Sublime跨平台跨语言编辑器事实上就是这样一款强大的工具。我们接下来唯一要做的，就是将Anaconda集成到sublime中就可以了。扩展：linux和MacOS安装教程请访问（https://docs.continuum.io/anaconda/install/）。 Sublime Text3 安装 (1) 将下载好的Sublime Text3工具包双击到如下界面：如图所示： (2) 一直执行“Next”一路安装即可，中间保存路径可以自定义。最终安装成功将如图所示： (3) 安装插件Package Control。打开（ https://packagecontrol.io/installation）复制Sublime Text3中的代码如图所示： (4) 点击“Ctrl+`”，将3中文本代码内容复制粘贴到文本框中，按Enter即可。如图所示： (5) 成功安装后，在Sublime Text3中同时按住“Ctrl+Shift+P”键盘。最终安装成功：如图示： (6) 点击“Packeage Control:Install Package”进入查找python环境配置插件“SublimeREPL”，下载安装完成后，点击“Preferences-&gt;Browse Package…”查看安装的包如图所示： (7) 自定义快捷键盘配置：打开Preferences下Key Bindings输入如下代码，F5运行程序，F6切换IDEL工具，Ctrl+D自定义删除行，其他快捷键是通用的，网上有很多快捷键的资料，这里不赘述。 [ { "keys": ["f5"], "caption": "SublimeREPL: Python - RUN current file", "command": "run_existing_window_command", "args": { "id": "repl_python_run", "file": "config/Python/Main.sublime-menu" } }, { "keys": ["f6"], "caption": "SublimeREPL: Python", "command": "run_existing_window_command", "args": { "id": "repl_python", "file": "config/Python/Main.sublime-menu" } },{ "keys": ["ctrl+d"], "command":"run_macro_file", "args": {"file":"res://Packages/Default/Delete Line.sublime-macro"} } ] 至此完成了Sublime Text3安装配置工作，详细插件安装参考网址（http://www.open-open.com/news/view/26d731），快捷键使用请查看（https://segmentfault.com/a/1190000004463984）。还有问题的读者可以自行上网检索，由于资料较多且比较容易实现，不再详写。 实战：第一个小程序的诞生实例介绍 编写一个可以智能数据计算的小程序，用户输入公式如“10/(2+3)”，自动提示计算结果。 源码实现本实例设计思路如下： 如下①中采用def定义函数名，python不采用花括号，而是用冒号代替代码块，形参中param是一个自动识别类型的参数。 如下②中基本的计算公式，记住结尾没有分号 如下③是对结果的输入。 如下④类似于C、C#、Java中的主函数，后面章节会项目介绍。 如下⑤是对函数名的调用，并且直接传递列表参数，暂时不理解也没有关系，详见第二章。 源码如下（源码下载见https://github.com/BaiNingchao/NLP&amp;ML/01chapter/1.1py）：123456def countNum(param): ① result = param[0]/(param[1]+param[2]) ② print("this count: "+str(result)) ③ if __name__=="__main__": ④ countNum([10,2,3]) ⑤ 运行结果如图所示： 参考文献 Anaconda使用总结 官网anaconda配置教程 简单⾼效地进⾏科学计算 : Python和Anaconda 图书：《自然语言处理理论与实战》 完整代码下载 源码请进【机器学习和自然语言QQ群：436303759】文件下载： 作者声明 本文版权归作者【白宁超】所有，转载请联系作者：1938036263@qq.com，但未经作者同意禁止转载，转载后需在文章页面明显位置给出原文连接，否则保留追究法律责任的权利。]]></content>
      <categories>
        <category>工具</category>
      </categories>
      <tags>
        <tag>Python</tag>
        <tag>自然语言处理</tag>
        <tag>Logistic regression</tag>
        <tag>Sublime</tag>
        <tag>Anaconda</tag>
        <tag>开发环境</tag>
        <tag>机器学习</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[数据处理：量身打造自定义文件格式转换]]></title>
    <url>%2F2018%2F09%2F19%2F%E6%95%B0%E6%8D%AE%E5%A4%84%E7%90%86%EF%BC%9A%E9%87%8F%E8%BA%AB%E6%89%93%E9%80%A0%E8%87%AA%E5%AE%9A%E4%B9%89%E6%96%87%E4%BB%B6%E6%A0%BC%E5%BC%8F%E8%BD%AC%E6%8D%A2%2F</url>
    <content type="text"><![CDATA[摘要：随着大数据的快速发展，自然语言处理、数据挖掘、机器学习技术应用愈加广泛。针对大数据的预处理工作是一项庞杂、棘手的工作。首先数据采集和存储，尤其高质量数据采集往往不是那么简单。采集后的信息文件格式不一，诸如pdf，doc，docx，Excel，ppt等多种形式。然而最常见便是txt、pdf和word类型的文档。本文主要对pdf和word文档进行文本格式转换成txt。格式一致化以后再进行后续预处理工作。笔者采用一些工具转换效果都不理想，于是才出现本系统的研究与实现。（本文原创，转载必须注明出处.） 本文概述背景介绍 为什么要文件格式转换？ 无论读者现在是做数据挖掘、数据分析、自然语言处理、智能对话系统、商品推荐系统等等，都不可避免的涉及语料的问题即大数据。数据来源无非分为结构化数据、半结构化数据和非结构化数据。其中结构化数据以规范的文档、数据库文件等等为代表；半结构化数据以网页、json文件等为代表；非结构化数据以自由文本为主，诸如随想录、中医病症记录等等。遗憾的是现实生活中半结构化和非结构化数据居多，而且往往还需要自己去收集。读者试想以下情况： 你的技术主管交给你一堆数据文件，让你做数据分析工作。你打开一看文件格式繁杂，诸如pdf、doc、docx、txt、excel等。更悲催的是有些pdf文件还是加密的，或者是图片格式的等复杂情况。此刻你采用什么方法做数据分析与预处理工作呢？ 上面情况算你幸运，隔几天技术主管直接给你一堆网站，让你自己去采集信息。你或许会惊喜的说的，那不简单，使用爬虫技术不就可以啦？恭喜你思路完全正确，可是爬取过程中遇到一些网页是pdf格式的情况，你不能直接抓取页面了。你此刻如何去采集信息呢？ 现有工具的转换效果如何 针对以上典型的情况，自定义插件PDFMiner、win2com等将派上用场（本文主要讲述文件格式转化，网络爬虫解析读者自行研究）。首先我们看看常规方式的处理，比如我下载个格式转化软件或者在线格式转化软件，具体如下所示：在线格式转换工具1页面效果如下： pdf格式转化为txt后的效果如下： 上面转换效果读者是否满意？是否因为某一个在线转换工具不完备，那我们再尝试一个,在线格式转换工具2页面效果如下： pdf格式转化为txt后的效果如下： 继续我们的格式转换工作，我们这次采用offic软件内带的pdf另存为效果如下： 总结 通过上面现有常规的方法，我们总结出以下问题： 1、 格式转换后，识别乱码较多。 2、 不支持或者限制支持批量处理。 3、 格式转换后的txt文件存在编码问题。 4、 生成目标文件的标题跟原标题不一致。 5、 操作不够灵活便捷。 基于自定义格式转换介绍 预期效果 1、 将带有嵌套的目录放在一个根目录文件下，只需要传入文件名即可自动转化。 2、 自动过滤掉不符合指定格式的文件。 3、 对处理的pdf文件不能识别的（加密文件等）给出日志记录其路径。 4、 生成目标文件的标题跟原文件目录标题保持一致。 5、 生成的文件按照统一的utf-8编码格式保存。 6、 支持默认保存路径与自定义保存路径。 预期效果展示 待处理语料数据如下： 处理后默认自动保存的结果（支持自定义指定保存目录）： 基于自定义插件的文本转化效果： 基于pdfminer插件的运行效果 基础配置工作基础准备工作 运行环境 1、windows7以上64bit操作系统 2、sublime运行环境 3、python3.0+ 需要插件 1、 pdfminer插件： 链接: https://pan.baidu.com/s/1p7X430bvBpjJ-qGNO-Fmcg 密码: v5th 或者：pip install pdfminer3k 2、 win2com 插件：链接: https://pan.baidu.com/s/1-2BsiTs8XjMIe5Gnh_GFjw 密码: 7j3t pip install pypiwin32 类库重构 算法基础类库重构 重构又称高度代码封装，旨在代码重用和面向对象编程。本文将相关基本方法封装在一个类库中供外部类调用，提高代码复用性和可读性。具体重构文件结构如下：123456789101112131415161718192021222324252627282930313233重构文件名：BaseClass.py'''功能描述：遍历目录，对子文件单独处理参数描述： 1 rootdir：待处理的目录路径 2 deffun： 方法参数，默认为空 3 savepath: 保存路径'''class TraversalFun(): TraversalDir：遍历目录文件方法 creat_savepath：支持默认和自定义保存目录方法 AllFiles：递归遍历所有文件，并提供具体文件操作功能 TranType：通过指定关键字操作，检查文件类型并转化目标类型 filelogs：记录文件处理日志方法 cleardir：清空目录文件方法 writeFile：文件的写操作方法 readFile：文件的读操作方法 mkdir：创建目录方法 ''' 功能描述：提供全局变量类 作 者：白宁超 时 间：2017年10月24日15:07:38 ''' class Global(object):提高各个公共全局变量 ''' 功能描述：测试类 作 者：白宁超 时 间：2017年10月24日15:07:38 ''' def TestMethod(filepath,newpath):方法测试类 核心方法详解 1 TraversalFun类方法：123456789101112131415161718192021222324252627282930313233343536373839404142434445464748495051525354555657585960616263646566676869707172737475767778798081828384858687888990919293949596979899100101102103104105106107108109110111112113114115116117118119120121122123124125126127128129130131def __init__(self,rootdir,deffun=None,savedir=""): self.rootdir = rootdir # 目录路径 self.deffun = deffun # 参数方法 self.savedir = savedir # 保存路径''' 遍历目录文件'''def TraversalDir(self,defpar='newpath'): try: # 支持默认和自定义保存目录 newdir = TraversalFun.creat_savepath(self,defpar) # 递归遍历word文件并将其转化txt文件 TraversalFun.AllFiles(self,self.rootdir,newdir) except Exception as e: raise e'''支持默认和自定义保存目录'''# @staticmethoddef creat_savepath(self,defpar): # 文件路径切分为上级路径和文件名('F:\\kjxm\\kjt', '1.txt') prapath,filename = os.path.split(self.rootdir) newdir = "" if self.savedir=="": newdir = os.path.abspath(os.path.join(prapath,filename+"_"+defpar)) else: newdir = self.savedir print("保存目录路径：\n"+newdir) if not os.path.exists(newdir): os.mkdir(newdir) return newdir'''递归遍历所有文件，并提供具体文件操作功能。'''def AllFiles(self,rootdir,newdir=''): # 返回指定目录包含的文件或文件夹的名字的列表 for lists in os.listdir(rootdir): # 待处理文件夹名字集合 path = os.path.join(rootdir, lists) # 核心算法，对文件具体操作 if os.path.isfile(path): self.deffun(path,newdir) # 具体方法实现功能 # TraversalFun.filelogs(rootdir) # 日志文件 # 递归遍历文件目录 if os.path.isdir(path): newpath = os.path.join(newdir, lists) if not os.path.exists(newpath): os.mkdir(newpath) TraversalFun.AllFiles(self,path,newpath)''' 通过指定关键字操作，检查文件类型并转化目标类型'''def TranType(filename,typename): # print("本方法支持文件类型处理格式：pdf2txt，代表pdf转化为txt；word2txt，代表word转化txt；word2pdf，代表word转化pdf。") # 新的文件名称 new_name = "" if typename == "pdf2txt" : #如果不是pdf文件，或者是pdf临时文件退出 if not fnmatch.fnmatch(filename, '*.pdf') or not fnmatch.fnmatch(filename, '*.PDF') or fnmatch.fnmatch(filename, '~$*'): return # 如果是pdf文件，修改文件名 if fnmatch.fnmatch(filename, '*.pdf') or fnmatch.fnmatch(filename, '*.PDF'): new_name = filename[:-4]+'.txt' # 截取".pdf"之前的文件名 if typename == "word2txt" : #如果是word文件： if fnmatch.fnmatch(filename, '*.doc') : new_name = filename[:-4]+'.txt' print(new_name) if fnmatch.fnmatch(filename, '*.docx'): new_name = filename[:-5]+'.txt' # 如果不是word文件，或者是word临时文件退出 else: return if typename == "word2pdf" : #如果是word文件： if fnmatch.fnmatch(filename, '*.doc'): new_name = filename[:-4]+'.pdf' if fnmatch.fnmatch(filename, '*.docx'): new_name = filename[:-5]+'.pdf' #如果不是word文件：继续 else: return return new_name'''记录文件处理日志'''def filelogs(rootdir): prapath,filename = os.path.split(rootdir) # 创建日志目录 dirpath = prapath+r"/"+filename+"_logs" TraversalFun.mkdir(dirpath) # 错误文件路径 errorpath = dirpath+r"/errorlogs.txt" # 限制文件路径 limitpath = dirpath+r"/limitlogs.txt" # 错误文件日志写入 TraversalFun.writeFile(errorpath,'\n'.join(Global.error_file_list)) # # 限制文件日志写入 TraversalFun.writeFile(limitpath,'\n'.join(Global.limit_file_list))'''清空目录文件'''def cleardir(dirpath): if not os.path.exists(dirpath): TraversalFun.mkdir(dirpath) else: shutil.rmtree(dirpath) TraversalFun.mkdir(dirpath)''' 文件的写操作'''def writeFile(filepath,strs): #encoding="utf-8" with open(filepath,'wb') as f: f.write(strs.encode())''' 文件的读操作'''def readFile(filepath): isfile = os.path.exists(filepath) readstr = "" if isfile: with open(filepath,"r",encoding="utf-8") as f: readstr = f.read() else: return return readstr''' 创建目录 '''def mkdir(dirpath): # 判断路径是否存在 isExists=os.path.exists(dirpath) # 判断结果 if not isExists: os.makedirs(dirpath) print(dirpath+' 创建成功') else: pass 2 TestMethod测试类12345def TestMethod(filepath,newpath): if os.path.isfile(filepath) : print("this is file name:"+filepath) else: pass 3 利用测试类方法运行方法参数效果图 方法的调用：传达参数分别是跟目录和测试类中的方法参数12345678910t1=time.time()# 根目录文件路径rootDir = r"../../Corpus/DataSet"tra=TraversalFun(rootDir,TestMethod) # 默认方法参数打印所有文件路径tra.TraversalDir() # 遍历文件并进行相关操作t2=time.time()totalTime=Decimal(str(t2-t1)).quantize(Decimal('0.0000'))print("耗时："+str(totalTime)+" s"+"\n")input() 运行结果如图所示： 基于pdfminer插件的pdf批量格式转换代码实现 pdfminer原理介绍 由于解析PDF是一件非常耗时和内存的工作，因此PDFMiner使用了一种称作lazy parsing的策略，只在需要的时候才去解析，以减少时间和内存的使用。要解析PDF至少需要两个类：PDFParser 和 PDFDocument，PDFParser 从文件中提取数据，PDFDocument保存数据。另外还需要PDFPageInterpreter去处理页面内容，PDFDevice将其转换为我们所需要的。PDFResourceManager用于保存共享内容例如字体或图片。 LTPage :表示整个页。可能会含有LTTextBox，LTFigure，LTImage，LTRect，LTCurve和LTLine子对象。 LTTextBox:表示一组文本块可能包含在一个矩形区域。注意此box是由几何分析中创建，并且不一定表示该文本的一个逻辑边界。它包含TTextLine对象的列表。使用 get_text（）方法返回的文本内容。 LTTextLine :包含表示单个文本行LTChar对象的列表。字符对齐要么 水平或垂直，取决于文本的写入模式。 get_text（）方法返回的文本内容。 LTAnno:在文本中实际的字母表示为Unicode字符串（？）。需要注意的是，虽然一个LTChar对象具有实际边界，LTAnno对象没有，因为这些是“虚拟”的字符，根据两个字符间的关系（例如，一个空格）由布局分析后插入。 LTImage:表示一个图像对象。嵌入式图像可以是JPEG或其它格式，但是目前PDFMiner没有放置太多精力在图形对象。 LTLine:代表一条直线。可用于分离文本或附图。 LTRect:表示矩形。可用于框架的另一图片或数字。 LTCurve:表示一个通用的 Bezier曲线 pdfminer学习文献 英文官方：https://euske.github.io/pdfminer/index.html中文：https://blog.csdn.net/robolinux/article/details/43318229 pdfminer代码实现 12345678910111213141516171819202122232425262728293031323334353637383940414243444546474849505152535455565758596061626364656667686970717273747576777879808182838485868788# pdfminer库的地址 https://pypi.python.org/pypi/pdfminer3k# 下载后，用cmd执行命令 setup.py installfrom pdfminer.pdfparser import PDFParser,PDFDocumentfrom pdfminer.pdfinterp import PDFResourceManager, PDFPageInterpreterfrom pdfminer.converter import PDFPageAggregatorfrom pdfminer.layout import LTTextBoxHorizontal,LAParamsfrom pdfminer.pdfinterp import PDFTextExtractionNotAllowedfrom decimal import Decimalimport time,fnmatch,os,re,sysfrom BaseClass import * #全局变量# from BaseClass import TraversalFun # 文件遍历处理基类函数# 清除警告import logginglogging.Logger.propagate = Falselogging.getLogger().setLevel(logging.ERROR)'''pdf文件格式转换为txt'''def PdfToText(filepath,newdir=''): # 文件路径切分为上级路径和文件名 prapath,filename = os.path.split(filepath) new_txt_name=TraversalFun.TranType(filename,"pdf2txt") # 更改文件名 if new_txt_name ==None: return newpath = os.path.join(newdir,new_txt_name) # 文件保存路径 print ("-&gt;格式转换后保留路径：\n"+newpath) try: praser = PDFParser(open(filepath, 'rb')) # 创建一个pdf文档分析器 doc = PDFDocument() # 创建一个PDF文档 praser.set_document(doc) # 连接分析器 与文档对象 doc.set_parser(praser) doc.initialize() # 提供初始化密码，如果没有密码 就创建一个空的字符串 # 检测文档是否提供txt转换，不提供就忽略 if not doc.is_extractable: Global.error_file_list.append(filepath) return rsrcmgr = PDFResourceManager() # 创建PDf 资源管理器管理共享资源 laparams = LAParams() # 创建一个PDF设备对象 device = PDFPageAggregator(rsrcmgr, laparams=laparams) interpreter = PDFPageInterpreter(rsrcmgr, device) # 创建一个PDF解释器对象 pdfStr = "" # 存储解析后的提取内容 # 循环遍历列表，每次处理一个page的内容 for page in doc.get_pages(): # doc.get_pages()获取page列表 interpreter.process_page(page) layout = device.get_result() # 接受该页面的LTPage对象 # 这里layout是一个LTPage对象 里面存放着 这个page解析出的各种对象 一般包括LTTextBox, LTFigure, LTImage, LTTextBoxHorizontal 等等 想要获取文本就获得对象的text属性， for x in layout: if (isinstance(x, LTTextBoxHorizontal)): pdfStr = pdfStr + x.get_text() TraversalFun.writeFile(newpath,pdfStr) # 写文件 # 限制文件列表 filesize = os.path.getsize(newpath) if filesize &lt; Global.limit_file_size : Global.limit_file_list.append(newpath+"\t"+ str(Decimal(filesize/1024).quantize(Decimal('0.00'))) +"KB") os.remove(newpath) else : Global.all_FileNum+=1 except Exception as e: Global.error_file_list.append(filepath) returnif __name__ == '__main__': t1=time.time() rootDir = r"../../Corpus/DataSet" # 默认处理路径 TraversalFun.cleardir(r'../../Corpus/DataSet_newpath') # 每次加载清空目录 print ('【批量生成的文件:】') tra=TraversalFun(rootDir,PdfToText) # 默认方法参数打印所有文件路径 tra.TraversalDir() # 写入日志文件 TraversalFun.filelogs(rootDir) print ('共处理文档数目：'+str(Global.all_FileNum+len(Global.error_file_list)+len(Global.limit_file_list))+' 个,其中:\n \ 1) 筛选文件(可用)'+str(Global.all_FileNum)+'个.\n \ 2) 错误文件(不能识别)'+ str(len(Global.error_file_list)) +'个.\n \ 3) 限制文件(&lt;5K)'+ str(len(Global.limit_file_list))+'个.' ) t2=time.time() totalTime=Decimal(str(t2-t1)).quantize(Decimal('0.0000')) print("耗时："+str(totalTime)+" s"+"\n") input() 解析pdf文件用到的类： PDFParser：从一个文件中获取数据 PDFDocument：保存获取的数据，和PDFParser是相互关联的 PDFPageInterpreter处理页面内容 PDFDevice将其翻译成你需要的格式 PDFResourceManager用于存储共享资源，如字体或图像。 pdfminer页面结果： pdfminer转化结果 实验结论 错误分析，打开日志文件查看 错误原因分析：因为我们在全局变量中限制了最小文件读取1KB，该文件0KB不符合要求故而过滤出来。打开查看发现该pdf是一张图片转换出来的，没有成功识别。但是，通过技术研究是可以实现的，本文没有深入进行。还有以下结论： 1 可以支持批量文本和单文本转化。 2 编码格式一致，默认utf-8。 3 生成文件名誉原始处理文件名保存一致。 4 生成的文本信息相对比较规范。 支持多方式转化，其他案例读者自行研究。 扩展学习 在解析有些PDF的时候会报这样的异常：pdfminer.pdfdocument.PDFEncryptionError: Unknown algorithm: param={‘CF’: {‘StdCF’: {‘Length’: 16, ‘CFM’: /AESV2, ‘AuthEvent’: /DocOpen}}, ‘O’: ‘\xe4\xe74\xb86/\xa8)\xa6x\xe6\xa3/U\xdf\x0fWR\x9cPh\xac\xae\x88B\x06_\xb0\x93@\x9f\x8d’, ‘Filter’: /Standard, ‘P’: -1340, ‘Length’: 128, ‘R’: 4, ‘U’: ‘|UTX#f\xc9V\x18\x87z\x10\xcb\xf5{\xa7\x00\x00\x00\x00\x00\x00\x00\x00\x00\x00\x00\x00\x00\x00\x00\x00’, ‘V’: 4, ‘StmF’: /StdCF, ‘StrF’: /StdCF}如上是加密的PDF，所以无法解析 ，但是如果直接打开PDF却是可以的并没有要求输密码什么的，原因是这个PDF虽然是加过密的，但密码是空，所以就出现了这样的问题。解决这个的问题的办法是通过qpdf命令来解密文件（要确保已经安装了qpdf），要想在python中调用该命令只需使用call即可： 1 from subprocess import call 2 call(‘qpdf —password=%s —decrypt %s %s’ %(‘’, file_path, new_file_path), shell=True)其中参数file_path是要解密的PDF的路径，new_file_path是解密后的PDF文件路径，然后使用解密后的文件去做解析就OK了 基于win32com插件的代码实现 导入相关包 from win32com import client as wc from win32com.client import Dispatch, constants, gencache import os,fnmatch,time,sys from decimal import Decimal from BaseClass import * # 自定义类库 word的doc或docx文件转化pdf文本 1 代码实现 ‘’’ 功能名称：word的doc或docx文件转化pdf文本 功能描述：输入一个doc或docx文件路径，自动转化为pdf文件，并存储在当前路径下。 用户可以指定存储文件路径。 参数描述： 1 filepath：单个文件路径 2 newdir： 指定保存路径 测试路径： F:\corper\kjt\1.docx ‘’’ def doc2pdf(filepath,newDir=’’): # 文件路径切分为上级路径和文件名 prapath,filename = os.path.split(filepath) # 单文件处理使用 if newDir==&#39;&#39;: newDir = prapath else: newDir =newDir new_txt_name=TraversalFun.TranType(filename,&quot;word2pdf&quot;) if new_txt_name ==None: return else: print(new_txt_name) newpath = os.path.join(newDir,new_txt_name) word = wc.DispatchEx(&quot;Word.Application&quot;) worddoc = word.Documents.Open(filepath,ReadOnly = 1) worddoc.SaveAs(newpath, FileFormat = 17) worddoc.Close() Global.all_FileNum+=1 2 单个word转换pdf主程序运行代码： # 单个word转换pdf filepath=os.path.abspath(r&quot;../../Corpus/DataSet/2012/科技项目数据挖掘决策架构.docx&quot;) doc2pdf(filepath) 控制台打印效果： 科技项目数据挖掘决策架构.pdf 共处理文档数目：1 个 耗时：3.6121 s 结果： 打开显示： 3 批量word转换pdf主程序运行代码： rootDir =os.path.abspath(r”../../Corpus/DataSet”) # 1 批量的word转换pdf tra=TraversalFun(rootDir,doc2pdf) # 默认方法参数打印所有文件路径 tra.TraversalDir(&#39;word2pdf&#39;) 控制台打印效果： 保存目录路径： F:\AllNote\AllProject\TechDataMining\Corpus\DataSet_word2pdf 科技项目数据挖掘决策架构.pdf 科技项目数据挖掘决策架构.pdf 共处理文档数目：2 个 耗时：7.1494 s结果： word的doc或docx文件转化txt文本 1 代码实现123456789101112131415161718192021222324'''功能名称：单个word的doc或docx文件转化txt文本'''def WordTranslate(filepath,newDir=''): # 文件路径切分为上级路径和文件名 prapath,filename = os.path.split(os.path.abspath(filepath)) if newDir=='': newDir = prapath else: newDir =newDir new_txt_name=TraversalFun.TranType(filename,'word2txt') if new_txt_name == None: return else: word_to_txt = os.path.join(newDir,new_txt_name) print ("格式转换后保留路径：\n"+word_to_txt) #加载处理应用 wordapp = wc.Dispatch('Word.Application') doc = wordapp.Documents.Open(filepath) #为了让python可以在后续操作中r方式读取txt和不产生乱码，参数为4 doc.SaveAs(word_to_txt,4) doc.Close() # print(word_to_txt) Global.all_FileNum += 1 2 单个word转换txt # 单个word转换txt filepath=os.path.abspath(r&quot;../../Corpus/DataSet/2012/科技项目数据挖掘决策架构.docx&quot;) WordTranslate(filepath) 3 批量的word转换txt # 批量的word转换txt tra=TraversalFun(rootDir,WordTranslate) # 默认方法参数打印所有文件路径 tra.TraversalDir(&#39;word2txt&#39;) 4 批量的word转换txt结果 pdf文件转化txt文本 1 代码实现123456789101112131415161718192021222324252627282930'''功能名称：pdf文件转化txt文本功能描述：输入一个pdf文件路径，自动转化为txt文件，并存储在当前路径下。 用户可以指定存储文件路径。参数描述： 1 filepath：单个文件路径 2 newdir： 指定保存路径测试路径： F:\corper\kjt\申报书.pdf'''def PdfTranslate(filepath,newDir=''): # 文件路径切分为上级路径和文件名 prapath,filename = os.path.split(filepath) if newDir=="": newDir = prapath else: newDir = newDir new_txt_name=TraversalFun.TranType(filename,"pdf2txt") if new_txt_name ==None: return else: word_to_txt = os.path.join(newDir,new_txt_name) # print(word_to_txt) #加载处理应用 wordapp = wc.Dispatch('Word.Application') doc = wordapp.Documents.Open(filepath) #为了让python可以在后续操作中r方式读取txt和不产生乱码，参数为4 doc.SaveAs(word_to_txt,4) doc.Close() Global.all_FileNum += 1 2 单个pdf文件转化txt文本 # 单个pdf转换txt filepath=os.path.abspath(r&quot;../../Corpus/DataSet/2012/改进朴素贝叶斯文本分类方法研究.pdf&quot;) PdfTranslate(filepath) 3 批量pdf文件转化txt文本 # 3 批量的pdf转换txt tra=TraversalFun(rootDir,PdfTranslate) # 默认方法参数打印所有文件路径 tra.TraversalDir(&quot;pdf2txt&quot;) 4 批量pdf文件转化txt文本结果 完整代码下载 源码请进机器学习和自然语言QQ群：436303759文件下载： 参考文献 http://www.unixuser.org/~euske/python/pdfminer/programming.html https://www.cnblogs.com/jamespei/p/5339769.html https://blog.csdn.net/u011389474/article/details/60139786 https://blog.csdn.net/u010983763/article/details/78654651 https://blog.csdn.net/zyc121561/article/details/77879831 https://blog.csdn.net/zyc121561/article/details/77877912?locationNum=7&amp;fps=1 作者声明 本文版权归作者【白宁超】所有，转载请联系作者：1938036263@qq.com，但未经作者同意禁止转载，转载后需在文章页面明显位置给出原文连接，否则保留追究法律责任的权利。]]></content>
      <categories>
        <category>自然语言处理</category>
      </categories>
      <tags>
        <tag>Python</tag>
        <tag>数据预处理</tag>
        <tag>自然语言处理</tag>
        <tag>NLP</tag>
        <tag>pdf2txt</tag>
        <tag>格式转化</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[一步步教你轻松学决策树模型算法]]></title>
    <url>%2F2018%2F09%2F19%2F%E4%B8%80%E6%AD%A5%E6%AD%A5%E6%95%99%E4%BD%A0%E8%BD%BB%E6%9D%BE%E5%AD%A6%E5%86%B3%E7%AD%96%E6%A0%91%E7%AE%97%E6%B3%95%2F</url>
    <content type="text"><![CDATA[摘要：决策树算法是一种基本的分类与回归方法，是最经常使用的算法之一。决策树模型呈树形结构，在分类问题中，表示基于特征对实例进行分类的过程。它可以认为是基于规则的集合。本文首先介绍决策树定义、工作原理、算法流程、优缺点等，然后结合案例进行分析。（本文原创，转载必须注明出处.） 理论介绍什么是决策树 维基百科：决策树（Decision Tree）是一个预测模型；他代表的是对象属性与对象值之间的一种映射关系。树中每个节点表示某个对象，而每个分叉路径则代表某个可能的属性值，而每个叶节点则对应从根节点到该叶节点所经历的路径所表示的对象的值。数据挖掘中决策树是一种经常要用到的技术，可以用于分析数据，同样也可以用来作预测。从数据产生决策树的机器学习技术叫做决策树学习,通俗说就是决策树。 分类决策树模型是一种描述对实例进行分类的树形结构。决策树由结点（node）和有向边（directed edge）组成。结点有两种类型：内部结点（internal node）和叶结点（leaf node）。内部结点表示一个特征或属性(features)，叶结点表示一个类(labels)。 用决策树对需要测试的实例进行分类：从根节点开始，对实例的某一特征进行测试，根据测试结果，将实例分配到其子结点；这时，每一个子结点对应着该特征的一个取值。如此递归地对实例进行测试并分配，直至达到叶结点。最后将实例分配到叶结点的类中。 什么是信息熵和信息增益 熵（entropy）： 熵指的是体系的混乱的程度，在不同的学科中也有引申出的更为具体的定义，是各领域十分重要的参量。 信息论（information theory）中的熵（香农熵）： 是一种信息的度量方式，表示信息的混乱程度，也就是说：信息越有序，信息熵越低。例如：火柴有序放在火柴盒里，熵值很低，相反，熵值很高。 信息增益（information gain）： 在划分数据集前后信息发生的变化称为信息增益，信息增益越大，确定性越强。 决策树工作原理12345678910111213'''决策树工作原理：基于迭代的思想。'''def createBranch(): 检测数据集中的所有数据的分类标签是否相同: If so return 类标签 Else: 寻找划分数据集的最好特征（划分之后信息熵最小，也就是信息增益最大的特征） 划分数据集 创建分支节点 for 每个划分的子集 调用函数 createBranch （创建分支的函数）并增加返回结果到分支节点中 return 分支节点 决策树算法流程收集数据：可以使用任何方法。 准备数据：树构造算法 (这里使用的是ID3算法，只适用于标称型数据，这就是为什么数值型数据必须离散化。 还有其他的树构造算法，比如CART) 分析数据：可以使用任何方法，构造树完成之后，我们应该检查图形是否符合预期。 训练算法：构造树的数据结构。 测试算法：使用训练好的树计算错误率。 使用算法：此步骤可以适用于任何监督学习任务，而使用决策树可以更好地理解数据的内在含义。 决策树优缺点相对于其他数据挖掘算法，决策树在以下几个方面拥有优势： 1 决策树易于理解和实现.人们在通过解释后都有能力去理解决策树所表达的意义。 2 对于决策树，数据的准备往往是简单或者是不必要的.其他的技术往往要求先把数据一般化，比如去掉多余的或者空白的属性。 3 能够同时处理数据型和常规型属性。其他的技术往往要求数据属性的单一。 4 是一个白盒模型如果给定一个观察的模型，那么根据所产生的决策树很容易推出相应的逻辑表达式。 5 易于通过静态测试来对模型进行评测。表示有可能测量该模型的可信度。 6 在相对短的时间内能够对大型数据源做出可行且效果良好的结果。 7 计算复杂度不高，输出结果易于理解，数据有缺失也能跑，可以处理不相关特征。 缺点： 1 容易过拟合。 2 对于那些各类别样本数量不一致的数据，在决策树当中信息增益的结果偏向于那些具有更多数值的特征。 适用数据类型：数值型和标称型。 1 数值型：数值型目标变量则可以从无限的数值集合中取值，如0.100，42.001等 (数值型目标变量主要用于回归分析) 2 标称型：标称型目标变量的结果只在有限目标集中取值，如真与假(标称型目标变量主要用于分类) 案例描述：加深决策树理解案例描述小王是一家著名高尔夫俱乐部的经理。但是他被雇员数量问题搞得心情十分不好。某些天好像所有人都来玩高尔夫，以至于所有员工都忙的团团转还是应付不过来，而有些天不知道什么原因却一个人也不来，俱乐部为雇员数量浪费了不少资金。小王的目的是通过下周天气预报寻找什么时候人们会打高尔夫，以适时调整雇员数量。因此首先他必须了解人们决定是否打球的原因。 数据采集在2周时间内我们得到以下记录： 天气状况有晴，云和雨；气温用华氏温度表示；相对湿度用百分比；还有有无风。当然还有顾客是不是在这些日子光顾俱乐部。最终他得到了14行5列的数据表格。 构建决策树决策树模型就被建起来用于解决问题。 结果分析决策树是一个有向无环图。根结点代表所有数据。分类树算法可以通过变量outlook，找出最好地解释非独立变量play（打高尔夫的人）的方法。变量outlook的范畴被划分为以下三个组：晴天，多云天和雨天。 我们得出第一个结论：如果天气是多云，人们总是选择玩高尔夫，而只有少数很着迷的甚至在雨天也会玩。 接下来我们把晴天组的分为两部分，我们发现顾客不喜欢湿度高于70%的天气。最终我们还发现，如果雨天还有风的话，就不会有人打了。 这就通过分类树给出了一个解决方案。小王（老板）在晴天，潮湿的天气或者刮风的雨天解雇了大部分员工，因为这种天气不会有人打高尔夫。而其他的天气会有很多人打高尔夫，因此可以雇用一些临时员工来工作。 决策树算法实现与分析案例: 判定鱼类和非鱼类 案例需求描述 我们采集海洋生物数据信息，选择其中5条如下表所示，从诸多特征中选择2个最主要特征，以及判定是否属于鱼类（此处我们选择二分类法即只考虑鱼类和非鱼类）。根据这些信息如何创建一个决策树进行分类并可视化展示？ 收集数据 部分数据采集信息 序号 不浮出水面是否可以生存 是否有脚蹼 属于鱼类 1 是 是 是 2 是 是 是 3 是 否 否 4 否 是 否 5 否 是 否 我们将自然语言数据转化为计算机输入数据，代码实现如下：123456789'''创建数据集，返回数据集和标签'''def createDataSet(): dataSet = [[1, 1, 'yes'], [1, 1, 'yes'], [1, 0, 'no'], [0, 1, 'no'], [0, 1, 'no']] labels = ['no surfacing', 'flippers'] return dataSet, labels 运行查看数据集的特征向量和分类标签： # 1 打印数据集和标签 dataset,label=createDataSet() print(dataset) print(label) 运行结果： [[1, 1, &#39;yes&#39;], [1, 1, &#39;yes&#39;], [1, 0, &#39;no&#39;], [0, 1, &#39;no&#39;], [0, 1, &#39;no&#39;]] [&#39;no surfacing&#39;, &#39;flippers&#39;] 准备数据 由于我们输入的数据已经是数据预处理后的数据，这一步不需要进行。 分析数据我们得到数据之后，到底是按照第一个特征即(不浮出水面是否可以生存)还是第二个特征即（是否有脚蹼）进行数据划分呢？这里面就需要找到一种量化的方法判断特征的选择。在介绍具体数据划分方法之前，我们首先明白划分数据集的最大原则是：将无序的数据变得更加有序 1948 年，香农引入信息熵，将其定义为离散随机事件的出现概率。一个系统越有序，信息熵就越低；反之，一个系统越混乱，信息熵就越高。所以说，信息熵可以被认为是系统有序化程度的一个度量。 这里就要用的信息熵的概念，熵越高表示混合数据越多，度量数据集无序程度。我们看下信息熵的数学描述（具体请自行查找熵相关知识）： 计算数据集的香农熵(信息期望值) 根据公式比较容易理解的实现方法1如下：123456789101112131415161718'''计算数据集的香农熵(信息期望值):熵越高表示混合数据越多，度量数据集无序程度'''def calcShannonEnt(dataSet): numEntries = len(dataSet) # 计算数据集中实例总数 labelCounts = &#123;&#125; # 创建字典，计算分类标签label出现的次数 for featVec in dataSet: currentLabel = featVec[-1] # 记录当前实例的标签 if currentLabel not in labelCounts.keys():# 为所有可能的分类创建字典 labelCounts[currentLabel] = 0 labelCounts[currentLabel] += 1 # print(featVec, labelCounts) # 打印特征向量和字典的键值对 # 对于label标签的占比，求出label标签的香农熵 shannonEnt = 0.0 for key in labelCounts: prob = float(labelCounts[key])/numEntries # 计算类别出现的概率。 shannonEnt -= prob * log(prob, 2) # 计算香农熵，以 2 为底求对数 print(Decimal(shannonEnt).quantize(Decimal('0.00000'))) return shannonEnt 更高级的实现方法2如下：12345678'''计算数据集的香农熵(信息期望值):熵越高表示混合数据越多，度量数据集无序程度'''def calcShannonEnt(dataSet): # 需要对 list 中的大量计数时,可以直接使用Counter,不用新建字典来计数 label_count = Counter(data[-1] for data in dataSet) # 统计标签出现的次数 probs = [p[1] / len(dataSet) for p in label_count.items()] # 计算概率 shannonEnt = sum([-p * log(p, 2) for p in probs]) # 计算香农熵 print(Decimal(shannonEnt).quantize(Decimal('0.00000'))) return shannonEnt 调用运行如下： # 2 计算数据集的熵 calcShannonEnt(dataset) 按照给定的特征划分数据集 我们根据信息熵度量出来的特征，进行数据集划分方法1如下：123456789101112131415161718'''划分数据集:按照特征划分'''def splitDataSet(dataSet, index, value): retDataSet = [] for featVec in dataSet: if featVec[index] == value:# 判断index列的值是否为value reducedFeatVec = featVec[:index] # [:index]表示取前index个特征 reducedFeatVec.extend(featVec[index+1:]) # 取接下来的数据 retDataSet.append(reducedFeatVec) print(retDataSet) return retDataSet``` 我们根据信息熵度量出来的特征，进行数据集划分方法2如下：```python '''划分数据集:按照特征划分'''def splitDataSet(dataSet, index, value): retDataSet = [data for data in dataSet for i, v in enumerate(data) if i == index and v == value] print(retDataSet) return retDataSet 指定特征的数据集划分方法调用 #3 划分数据集 splitDataSet(dataset,0,1) 运行结果如下： [[1, 1, &#39;yes&#39;], [1, 1, &#39;yes&#39;], [1, 0, &#39;no&#39;]] 选择最好的数据集划分方式 选择最好的数据集划分方式：特征选择，划分数据集、计算最好的划分数据集特征，方法1如下：1234567891011121314151617181920212223'''注意：一是数据集列表元素具备相同数据长度，二是最后一列是标签列'''def chooseBestFeatureToSplit(dataSet): numFeatures = len(dataSet[0]) - 1 # 特征总个数, 最后一列是标签 baseEntropy = calcShannonEnt(dataSet) # 计算数据集的信息熵 bestInfoGain, bestFeature = 0.0, -1 # 最优的信息增益值, 和最优的Featurn编号 for i in range(numFeatures): featList = [example[i] for example in dataSet] # 获取各实例第i+1个特征 uniqueVals = set(featList) # 获取去重后的集合 newEntropy = 0.0 # 创建一个新的信息熵 for value in uniqueVals: subDataSet = splitDataSet(dataSet, i, value) prob = len(subDataSet)/float(len(dataSet)) newEntropy += prob * calcShannonEnt(subDataSet) # 比较所有特征中的信息增益，返回最好特征划分的索引值。 infoGain = baseEntropy - newEntropy print('infoGain=', infoGain, 'bestFeature=', i, baseEntropy, newEntropy) if (infoGain &gt; bestInfoGain): bestInfoGain = infoGain bestFeature = i # print(bestFeature) return bestFeature 选择最好的数据集划分方式：特征选择，划分数据集、计算最好的划分数据集特征，方法2如下：123456789101112131415161718192021'''注意：一是数据集列表元素具备相同数据长度，二是最后一列是标签列'''def chooseBestFeatureToSplit(dataSet): base_entropy = calcShannonEnt(dataSet) # 计算初始香农熵 best_info_gain = 0 best_feature = -1 # 遍历每一个特征 for i in range(len(dataSet[0]) - 1): # 对当前特征进行统计 feature_count = Counter([data[i] for data in dataSet]) # 计算分割后的香农熵 new_entropy = sum(feature[1] / float(len(dataSet)) * calcShannonEnt(splitDataSet(dataSet, i, feature[0])) for feature in feature_count.items()) # 更新值 info_gain = base_entropy - new_entropy # print('No. &#123;0&#125; feature info gain is &#123;1:.3f&#125;'.format(i, info_gain)) if info_gain &gt; best_info_gain: best_info_gain = info_gain best_feature = i # print(best_feature) return best_feature 选择最好的数据集划分方法调用 # 4 选择最好的数据集划分方式 chooseBestFeatureToSplit(dataset)) 运行结果如下： infoGain= 0.4199730940219749 bestFeature= 0 0.9709505944546686 0.5509775004326937 infoGain= 0.17095059445466854 bestFeature= 1 0.9709505944546686 0.8 选择：0 训练算法：构造树的数据结构创建树的函数代码如下：1234567891011121314151617181920212223242526272829303132'''创建决策树'''def createTree(dataSet, labels): classList = [example[-1] for example in dataSet] # 如果数据集的最后一列的第一个值出现的次数=整个集合的数量，也就说只有一个类别，就只直接返回结果就行 # 第一个停止条件：所有的类标签完全相同，则直接返回该类标签。 # count() 函数是统计括号中的值在list中出现的次数 if classList.count(classList[0]) == len(classList): return classList[0] # 如果数据集只有1列，那么最初出现label次数最多的一类，作为结果 # 第二个停止条件：使用完了所有特征，仍然不能将数据集划分成仅包含唯一类别的分组。 if len(dataSet[0]) == 1: return majorityCnt(classList) # 选择最优的列，得到最优列对应的label含义 bestFeat = chooseBestFeatureToSplit(dataSet) # 获取label的名称 bestFeatLabel = labels[bestFeat] # 初始化myTree myTree = &#123;bestFeatLabel: &#123;&#125;&#125; # 所以这行代码导致函数外的同名变量被删除了元素，造成例句无法执行，提示'no surfacing' is not in list # del(labels[bestFeat]) # 取出最优列，然后它的branch做分类 featValues = [example[bestFeat] for example in dataSet] uniqueVals = set(featValues) for value in uniqueVals: # 求出剩余的标签label subLabels = labels[:] # 遍历当前选择特征包含的所有属性值，在每个数据集划分上递归调用函数createTree() myTree[bestFeatLabel][value] = createTree(splitDataSet(dataSet, bestFeat, value), subLabels) # print('myTree', value, myTree) print(myTree) return myTree 其中多数表决方法决定叶子节点的分类实现如下：123456789101112131415161718'''多数表决方法决定叶子节点的分类：选择出现次数最多的一个结果'''def majorityCnt(classList): # -----------多数表决实现的方式一-------------- # classCount = &#123;&#125; # 标签字典，用于统计类别频率 # for vote in classList: # classList标签的列表集合 # if vote not in classCount.keys(): # classCount[vote] = 0 # classCount[vote] += 1 # # 取出结果（yes/no），即出现次数最多的结果 # sortedClassCount = sorted(classCount.items(), key=operator.itemgetter(1), reverse=True) # print('sortedClassCount:', sortedClassCount) # return sortedClassCount[0][0] # -----------多数表决实现的方式二----------------- major_label = Counter(classList).most_common(1)[0] print('sortedClassCount:', major_label[0]) return major_label[0] 调用方法： # 6创建决策树 createTree(dataset, label) 运行结果： {&#39;no surfacing&#39;: {0: &#39;no&#39;, 1: {&#39;flippers&#39;: {0: &#39;no&#39;, 1: &#39;yes&#39;}}}} 结果分析：此时，每次生成决策树数据都需要大量的计算，并且耗时，最好是每次直接调用生成结果。这里就需要使用Python模块pickle序列化对象，其存储决策树读取决策树代码实现如下：1234567891011121314151617'''使用pickle模块存储决策树'''def storeTree(inputTree, filename): import pickle # -------------- 第一种方法 -------------- fw = open(filename, 'wb') pickle.dump(inputTree, fw) fw.close() # -------------- 第二种方法 -------------- with open(filename, 'wb') as fw: pickle.dump(inputTree, fw)def grabTree(filename): import pickle fr = open(filename,'rb') return pickle.load(fr) 测试算法：使用决策树执行分类用决策树进行鱼类属于分类实现如下：1234567891011121314'''用决策树分类函数'''def classify(inputTree, featLabels, testVec): firstStr = list(inputTree.keys())[0] # 获取tree的根节点对于的key值 secondDict = inputTree[firstStr] # 通过key得到根节点对应的value # 判断根节点名称获取根节点在label中的先后顺序，这样就知道输入的testVec怎么开始对照树来做分类 featIndex = featLabels.index(firstStr) for key in secondDict.keys(): if testVec[featIndex] == key: if type(secondDict[key]).__name__ == 'dict': classLabel = classify(secondDict[key], featLabels, testVec) else: classLabel = secondDict[key] print(classLabel) return classLabel 调用方法： # 7 用决策树分类函数 myTree = treePlotter.retrieveTree(0) # print(myTree) classify(myTree,label,[1,0]) 运行结果： 分类结果：no surfacing 决策树分类器实现使用算法此步骤可以适用于任何监督学习任务，而使用决策树可以更好地理解数据的内在含义。1234567891011121314151617181920212223'''决策树判断是否是鱼'''def fishTest(): # 1.创建数据和结果标签 myDat, labels = createDataSet() # 计算label分类标签的香农熵 calcShannonEnt(myDat) # 求第0列 为 1/0的列的数据集【排除第0列】 print('1---', splitDataSet(myDat, 0, 1)) print('0---', splitDataSet(myDat, 0, 0)) # 计算最好的信息增益的列 print(chooseBestFeatureToSplit(myDat)) import copy myTree = createTree(myDat, copy.deepcopy(labels)) print(myTree) # [1, 1]表示要取的分支上的节点位置，对应的结果值 print(classify(myTree, labels, [1, 1])) # 画图可视化展现 treePlotter.createPlot(myTree) 调用决策树分类方法： # 9 决策树判断是否是鱼 fishTest() 运行结果如下： 1--- [[1, 1, &#39;yes&#39;], [1, 1, &#39;yes&#39;], [1, 0, &#39;no&#39;]] 0--- [[0, 1, &#39;no&#39;], [0, 1, &#39;no&#39;]] {&#39;no surfacing&#39;: {0: &#39;no&#39;, 1: {&#39;flippers&#39;: {0: &#39;no&#39;, 1: &#39;yes&#39;}}}} yes 可视化结果 决策树实际应用:预测隐形眼镜的测试代码项目概述隐形眼镜类型包括硬材质、软材质以及不适合佩戴隐形眼镜。我们需要使用决策树预测患者需要佩戴的隐形眼镜类型。 开发流程收集数据: 提供的文本文件。 解析数据: 解析 tab 键分隔的数据行 分析数据: 快速检查数据，确保正确地解析数据内容，使用 createPlot() 函数绘制最终的树形图。 训练算法: 使用 createTree() 函数。 测试算法: 编写测试函数验证决策树可以正确分类给定的数据实例。 使用算法: 存储树的数据结构，以便下次使用时无需重新构造树。 收集数据：提供的文本文件 数据读取 文本文件数据格式如下： young myope no reduced no lenses young myope no normal soft young myope yes reduced no lenses young myope yes normal hard young hyper no reduced no lenses young hyper no normal soft young hyper yes reduced no lenses young hyper yes normal hard pre myope no reduced no lenses pre myope no normal soft pre myope yes reduced no lenses pre myope yes normal hard pre hyper no reduced no lenses pre hyper no normal soft pre hyper yes reduced no lenses pre hyper yes normal no lenses presbyopic myope no reduced no lenses presbyopic myope no normal no lenses presbyopic myope yes reduced no lenses presbyopic myope yes normal hard presbyopic hyper no reduced no lenses presbyopic hyper no normal soft presbyopic hyper yes reduced no lenses presbyopic hyper yes normal no lenses 代码实现: 编写测试函数验证决策树可以正确分类给定的数据实例。12345678910111213'''预测隐形眼镜的测试代码'''def ContactLensesTest(): # 加载隐形眼镜相关的 文本文件 数据 fr = open('lenses.txt') # 解析数据，获得 features 数据 lenses = [inst.strip().split(' ') for inst in fr.readlines()] # 得到数据的对应的 Labels lensesLabels = ['age', 'prescript', 'astigmatic', 'tearRate'] # 使用上面的创建决策树的代码，构造预测隐形眼镜的决策树 lensesTree = createTree(lenses, lensesLabels) print(lensesTree) # 画图可视化展现 treePlotter.createPlot(lensesTree) 运行结果 调用方法 # 10 预测隐形眼镜类型 ContactLensesTest() 运行结果 {&#39;tearRate&#39;: {&#39;reduced&#39;: &#39;no lenses&#39;, &#39;normal&#39;: {&#39;astigmatic&#39;: {&#39;no&#39;: {&#39;age&#39;: {&#39;young&#39;: &#39;soft&#39;, &#39;pre&#39;: &#39;soft&#39;, &#39;presbyopic&#39;: {&#39;prescript&#39;: {&#39;myope&#39;: &#39;no lenses&#39;, &#39;hyper&#39;: &#39;soft&#39;}}}}, &#39;yes&#39;: {&#39;prescript&#39;: {&#39;myope&#39;: &#39;hard&#39;, &#39;hyper&#39;: {&#39;age&#39;: {&#39;young&#39;: &#39;hard&#39;, &#39;pre&#39;: &#39;no lenses&#39;, &#39;presbyopic&#39;: &#39;no lenses&#39;}}}}}}}} 决策树可视化 完整代码下载 源码请进QQ群文件下载： 作者声明 本文版权归作者【白宁超】所有，转载请联系作者：1938036263@qq.com，但未经作者同意禁止转载，转载后需在文章页面明显位置给出原文连接，否则保留追究法律责任的权利。]]></content>
      <categories>
        <category>机器学习</category>
        <category>决策树</category>
      </categories>
      <tags>
        <tag>机器学习算法</tag>
        <tag>Python</tag>
        <tag>sklean</tag>
        <tag>文本聚类</tag>
        <tag>决策树</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[一步步教你轻松学KNN模型算法]]></title>
    <url>%2F2018%2F09%2F19%2F%E4%B8%80%E6%AD%A5%E6%AD%A5%E6%95%99%E4%BD%A0%E8%BD%BB%E6%9D%BE%E5%AD%A6KNN%E6%A8%A1%E5%9E%8B%E7%AE%97%E6%B3%95%2F</url>
    <content type="text"><![CDATA[摘要：机器学习算法中KNN属于比较简单的典型算法，既可以做聚类又可以做分类使用。本文通过一个模拟的实际案例进行讲解。整个流程包括：采集数据、数据格式化处理、数据分析、数据归一化处理、构造算法模型、评估算法模型和算法模型的应用。（本文原创，转载必须注明出处.） 1 理论介绍 什么是KNN？ &nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;k-近邻（kNN,k-NearestNeighbor）算法是一种基本分类与回归方法，我们这里只讨论分类问题中的 k-近邻算法。k-近邻算法的输入为实例的特征向量，对应于特征空间的点；输出为实例的类别，可以取多类。k-邻算法假设给定一个训练数据集，其中的实例类别已定。分类时，对新的实例，根据其 k 个最近邻的训练实例的类别，通过多数表决等方式进行预测。因此，k近邻算法不具有显式的学习过程即属于有监督学习范畴。k近邻算法实际上利用训练数据集对特征向量空间进行划分，并作为其分类的“模型”。k值的选择、距离度量以及分类决策规则是k近邻算法的三个基本要素。 KNN算法思想 1 计算已知类别中数据集的点与当前点的距离。[即计算所有样本点跟待分类样本之间的距离] 2 按照距离递增次序排序。[计算完样本距离进行排序] 3 选取与当前点距离最小的k个点。[选取距离样本最近的k个点] 4 确定前k个点所在类别的出现频率。[针对这k个点，统计下各个类别分别有多少个] 5 返回前k个点出现频率最高的类别作为当前点的预测分类。[k个点中某个类别最多，就将样本划归改点] KNN工作原理 1 假设有一个带有标签的样本数据集（训练样本集），其中包含每条数据与所属分类的对应关系。 2 输入没有标签的新数据后，将新数据的每个特征与样本集中数据对应的特征进行比较。 3 计算新数据与样本数据集中每条数据的距离。 4 对求得的所有距离进行排序（从小到大，越小表示越相似）。 5 取前 k （k 一般小于等于 20 ）个样本数据对应的分类标签。 6 求 k 个数据中出现次数最多的分类标签作为新数据的分类。 KNN算法流程 1 搜集数据：数据采集过程，其分为非结构化数据，半结构化数据和数据化数据。诸如：网络爬取，数据库，文件等。 2 准备数据：格式化处理，对不同类别的数据进行统一的格式化处理。诸如：将pdf，word，excel，sql等等统一转化为txt文本。 3 分析数据：主要看看数据特点，有没有缺失值，数据连续性还是离散型，进而选择不同模型。诸如：可视化数据分析 4 训练数据：不适用于KNN，但是在其他一些监督学习中会经常遇到，诸如：朴素贝叶斯分类等。 5 测试算法：评价指标，如计算错误率，准确率，召回率，F度量值等。 6 应用算法：针对完善的模型进行封装重构，然后进行实际应用。 KNN优缺点 优点：精度高、对异常值不敏感、无数据输入假定 缺点：计算复杂度高、空间复杂度好 适用数据范围：数值型和标称型 2 KNN算法实现与分析2.1 数据准备 创建模拟数据集 描述：现在你来了一个新的任务，任务其实非常简单，就是根据吃冰淇淋和喝水的数量判断成都天气冷热程度。你现在要做的就是去成都春熙路街头采访记录一些游客吃了多少冰淇淋，又喝了几瓶水，他觉得成都天气怎么样（这里只考虑二分类问题，假设只有‘非常热’和‘一般热’）。其中特征向量包括两个分别是冰激凌数t1和喝水数t2，标签类别分别是非常热A和一般热B。 现在我们开始行动，随机采访4个游客（暂时不考虑样本数量问题），询问每个游客吃多少冰淇淋和喝多少水（两个整型的特征向量，不考虑特征重要程度），并记录下他们口中的成都天气感受（非常热A与一般热B）。然后通过采访数据训练一个KNN分类器，新的游客只需要说出特征向量自动判别成都天气冷热程度。创建模拟数据集代码如下：12345'''KNN创建数据源，返回数据集和标签'''def create_dataset(): group = array(random.randint(0,10,size=(4,2))) # 数据集 labels = ['A','A','B','B'] # 标签 return group,labels 运行查看数据集的特征向量和分类标签：1234'''1 KNN模拟数据分类算法'''dataset,labels = create_dataset()print('特征集：\n'+str(dataset))print('标签集：\n'+str(labels)) 运行结果： 特征集： [[8 4] [7 1] [1 4] [3 0]] 标签集： [&#39;A&#39;, &#39;A&#39;, &#39;B&#39;, &#39;B&#39;] 分析解读： 本段代码没有实际意义，只是帮助读者理解特征向量和分类标签。可以这么理解，A代表非常热，B代表一般热，属性1代表吃冰淇淋数量，属性2代表喝水的数量。那么样本数据可以解读为： 游客 冰淇淋 喝水 冷热程度 判断描述 小王 8 4 A 小王吃了8个冰淇淋喝了4瓶水，成都天气非常热 小张 7 1 A 小张吃了7个冰淇淋喝了1瓶水，成都天气非常热 小李 1 4 B 小王吃了1个冰淇淋喝了4瓶水，成都天气一般热 小赵 3 0 B 小王吃了3个冰淇淋喝了0瓶水，成都天气一般热 思考： 计算机是不能直接处理自然语言，往往需要将自然语言转化成特征向量，再通过计算机处理。比如这里不是吃喝看天气情况了，而是垃圾邮件自动识别，我们就需要对邮件转化成数值型特征向量再输入计算机进行处理。 规范文件数据集处理 如下是一个规范文件的数据集（已经经过数采集、数据格式化、数据预处理等），特征向量包括3个，样本属于一个多分类的情况。即我们通过周飞行里程数、玩游戏占比、吃冰激凌数量判断一个人的优秀程度。假设1代表普通，2代表比较优秀，3代表非常优秀。（ps：一个人一周都在飞机上度过忙碌的工作，又不太玩游戏，关键还注意饮食，说明优秀是有道理的。） 周飞行里程数（km） 周玩游戏占比（%） 周消耗冰激凌（公升） 样本分类 40920 8.326976 0.953952 3 14488 7.153469 1.673904 2 26052 1.441871 0.805124 1 ... ... ... ... 75136 13.147394 0.428964 1 38344 1.669788 0.134296 1 72993 10.141740 1.032955 1 上面是处理好保存在txt文本的数据，计算机如何去识别并处理这些数据呢？这里我们分别提取特征向量和标签向量。数据集处理代码如下：12345678910111213'''对文件进行格式处理，便于分类器可以理解'''def file_matrix(filename): f = open(filename) arrayLines = f.readlines() returnMat = zeros((len(arrayLines),3)) # 数据集 classLabelVactor = [] # 标签集 index = 0 for line in arrayLines: listFromLine = line.strip().split(' ') # 分析数据，空格处理 returnMat[index,:] = listFromLine[0:3] classLabelVactor.append(int(listFromLine[-1])) index +=1 return returnMat,classLabelVactor 代码说明： 1 zeros(Y,X)：填充矩阵，需要导入NumPy包。Y向量代表样本行数，X向量代表样本特征数即列数。 2 returnMat[index,:]：遍历样本特征向量 运行查看数据集的特征向量和分类标签：12345''' KNN针对文件的分类算法'''filename = os.path.abspath(r'./datasource/datingTestSet2.txt')dataset,labels = file_matrix(filename)print('特征集：\n'+str(dataset))print('标签集：\n'+str(labels)) 运行结果： 特征集： [[4.0920000e+04 8.3269760e+00 9.5395200e-01] [1.4488000e+04 7.1534690e+00 1.6739040e+00] [2.6052000e+04 1.4418710e+00 8.0512400e-01] ... [2.6575000e+04 1.0650102e+01 8.6662700e-01] [4.8111000e+04 9.1345280e+00 7.2804500e-01] [4.3757000e+04 7.8826010e+00 1.3324460e+00]] 标签集： [3, 2, 1, 1, 1, 1, 3, 3, 1, 3, 1, 1, 2, 1, 1, 1, 1, 1, 2, 3, 2, 1, 2, 3, 2, 3, 2, 3, 2, 1, 3, 1, 3, 1, 2, 1, 1, 2, 3, 3, 1, 2, 3, 3, 3, ... 3, 3, 1, 2, 3, 1, 3, 1, 2, 2, 1, 1, 1, 1, 1] 不规范数据集处理 这里我们只是提供一个思路。比如做文本分类算法，如何将一篇篇新闻转化为规范的数值型数据集呢。假设Z政治新闻100篇，T体育新闻100篇，Y娱乐新闻100篇，K科技新闻100篇。我们进行分类： 1 遍历所有文本转化统一的txt格式文件（2.2节会讲到） 2 对全部ZTYK文本进行分词和停用词处理。 3 统计全部样本词频尺寸（可以采用TF-IDF或者深度学习方法处理）。 4 每个样本进行词频统计 最终模拟效果如下： 样本 词1 词2 词3 词4 ... 词n 标签 p1 200 0 100 50 ... 20 Z p2 100 0 80 40 ... 10 Z p3 0 100 5 5 ... 200 T p4 6 230 40 12 ... 670 T p5 0 2 110 57 ... 234 Y ... ... ... ... ... ... ... ... pn 123 45 0 580 ... 24 K 2.2 数据格式化 数据文件转化 自然语言处理、数据挖掘、机器学习技术应用愈加广泛。针对大数据的预处理工作是一项庞杂、棘手的工作。首先数据采集和存储，尤其高质量数据采集往往不是那么简单。采集后的信息文件格式不一，诸如pdf，doc，docx，Excel，ppt等多种形式。然而最常见便是txt、pdf和word类型的文档。这里所谓格式转化主要对pdf和word文档进行文本格式转换成txt。格式一致化以后再进行后续预处理工作。具体详情请参照之前写的数据分析：基于Python的自定义文件格式转换系统一文。 文件格式化处理 这里可以采用多种方式，诸如上文提到的矩阵填充法，当然也可以采用现成的工具。比如百度的Echarts中表格数据转换工具。其支持纯数组的转换，数组+对象，地理坐标等方式，还支持json数据的转化，这对使用百度EChart可视化是非常友好的，也有助于可视化数据分析。文本数据格式效果如下图： [ [&#39;40920 8.326976 0.953952 3&#39;], [&#39;14488 7.153469 1.673904 2&#39;], [&#39;26052 1.441871 0.805124 1&#39;], [&#39;75136 13.147394 0.428964 1&#39;], [&#39;38344 1.669788 0.134296 1&#39;], [&#39;72993 10.141740 1.032955 1&#39;], ... [&#39;35948 6.830792 1.213192 3&#39;], [&#39;42666 13.276369 0.543880 3&#39;], [&#39;67497 8.631577 0.749278 1&#39;], [&#39;35483 12.273169 1.508053 3&#39;], [&#39;50242 3.723498 0.831917 1&#39;], [&#39;63275 8.385879 1.669485 1&#39;], [&#39;5569 4.875435 0.728658 2&#39;], [&#39;15669 0.000000 1.250185 2&#39;], [&#39;28488 10.528555 1.304844 3&#39;], [&#39;6487 3.540265 0.822483 2&#39;], [&#39;37708 2.991551 0.833920 1&#39;] ] 2.3 数据归一化 数据归一化 机器学习、数据挖掘、自然语言处理等数据科学工作中，数据前期准备、数据预处理过程、特征提取等几个步骤比较花费时间。同时，数据预处理的效果也直接影响了后续模型能否有效的工作。然而，目前的很多研究主要集中在模型的构建、优化等方面，对数据预处理的理论研究甚少，很多数据预处理工作仍然是靠工程师的经验进行的。也不是所有数据都需要归一化，诸如 1. 数据类型一致且分布均匀。 2. 概率模型可以不做归一化，如决策树。 数据归一化优点 1. 归一化后加快了梯度下降求最优解的速度; 2. 归一化有可能提高精度; 归一化方法 1 sklearn线性归一化 # 线性函数将原始数据线性化的方法转换到[0, 1]的范围 min_max_scaler = preprocessing.MinMaxScaler() X_train_minmax = min_max_scaler.fit_transform(X_train) X_test_minmax = min_max_scaler.transform(X_test) 2 标准差标准化 # 经过处理的数据符合标准正态分布，即均值为0，标准差为1，其转化函数为： scaler = preprocessing.StandardScaler().fit(X_train) scaler.transform(X_test) 3 非线性归一化 经常用在数据分化比较大的场景，有些数值很大，有些很小。通过一些数学函数，将原始值进行映射。该方法包括 log、指数，正切等。需要根据数据分布的情况，决定非线性函数的曲线，比如log(V, 2)还是log(V, 10)等。 线性归一化方法代码实现1234567891011121314'''数值归一化：特征值转化为0-1之间：newValue = (oldValue-min)/(max-min)'''def norm_dataset(dataset): minVals = dataset.min(0) # 参数0是取得列表中的最小值，而不是行中最小值 maxVals = dataset.max(0) ranges = maxVals - minVals normdataset = zeros(shape(dataset)) # 生成原矩阵一样大小的0矩阵 m = dataset.shape[0] # tile:复制同样大小的矩阵 molecular = dataset - tile(minVals,(m,1)) # 分子： (oldValue-min) Denominator = tile(ranges,(m,1)) # 分母：(max-min) normdataset = molecular/Denominator # 归一化结果。 return normdataset,ranges,minVals 数据归一化前： 归一化的数据结果： [[4.0920000e+04 8.3269760e+00 9.5395200e-01] [1.4488000e+04 7.1534690e+00 1.6739040e+00] [2.6052000e+04 1.4418710e+00 8.0512400e-01] ... [2.6575000e+04 1.0650102e+01 8.6662700e-01] [4.8111000e+04 9.1345280e+00 7.2804500e-01] [4.3757000e+04 7.8826010e+00 1.3324460e+00]] 展开第一条信息“40920 8.326976 0.953952 3”，其中里程40000多，而公升数才0.9.两者根本不在同一个数量级上面，也就是说，如果特征属性相同的情况下，公升数即使变动100倍对里程数的影响也微乎其微。而里程数轻微变化就直接影响公升数的结果。所以我们将其放在同一尺度下进行处理，也就是本文采用的线性缩放方，数据归一化后结果如下： 归一化的数据结果： [[0.44832535 0.39805139 0.56233353] [0.15873259 0.34195467 0.98724416] [0.28542943 0.06892523 0.47449629] ... [0.29115949 0.50910294 0.51079493] [0.52711097 0.43665451 0.4290048 ] [0.47940793 0.3768091 0.78571804]] 分析： 经过上述归一化处理后，各个特征指标都是0-1这样一个范畴中进行比较。当然实际工作中不同特征的权重不同，这个可以通过增加权重方法处理即可，本文不在进行深入讨论。 2.4 数据分析 基于matplotlib的可视化分析 我们对数据处理后，很不容易进行数据分析。毕竟密密麻麻的数字略显冰冷无趣。我们可以将其可视化展示出来，进而查看数据稀疏程度，离散程度等等。我们查看’玩游戏所耗时间百分比’,’每周消耗在冰淇淋的公升数’两个属性的散点图，实现代码如下：12345678910111213141516171819202122232425262728'''散列表分析数据：dataset：数据集datingLabels：标签集Title:列表，标题、横坐标标题、纵坐标标题。'''def analyze_data_plot(dataset,datingLabels,Title): fig = plt.figure() # 将画布划分为1行1列1块 ax = fig.add_subplot(111) ax.scatter(dataset[:,1],dataset[:,2],15.0*array(datingLabels),15.0*array(datingLabels)) # 设置散点图标题和横纵坐标标题 plt.title(Title[0],fontsize=25,fontname='宋体',fontproperties=myfont) plt.xlabel(Title[1],fontsize=15,fontname='宋体',fontproperties=myfont) plt.ylabel(Title[2],fontsize=15,fontname='宋体',fontproperties=myfont) # 设置刻度标记大小,axis='both'参数影响横纵坐标，labelsize刻度大小 plt.tick_params(axis='both',which='major',labelsize=10) # 设置每个坐标轴取值范围 # plt.axis([-1,25,-1,2.0]) # 截图保存图片 # plt.savefig('datasets_plot.png',bbox_inches='tight') # 显示图形 plt.show() 这里注意一个问题，横纵坐标是乱码显示，解决这个问题，添加如下代码： #加入中文显示 import matplotlib.font_manager as fm # 解决中文乱码，本案例使用宋体字 myfont=fm.FontProperties(fname=r&quot;C:\\Windows\\Fonts\\simsun.ttc&quot;) 调用可视化数据分析方法如下：12345''' 文件数据图形化分析数据 '''dataset,labels = file_matrix(filename)noredataset = norm_dataset(dataset)[0] # 数据归一化title = ['约会数据游戏和饮食散列点','玩游戏所耗时间百分比','每周消耗在冰淇淋的公升数']visualplot.analyze_data_plot(noredataset,labels,title) 游戏占比与冰淇淋公升数关系散点图可视化： 折线图代码实现如下：123456789101112131415'''折线图'''def line_chart(xvalues,yvalues): # 绘制折线图,c颜色设置，alpha透明度 plt.plot(xvalues,yvalues,linewidth=0.5,alpha=0.5,c='red') # num_squares数据值，linewidth设置线条粗细 # 设置折线图标题和横纵坐标标题 plt.title("Python绘制折线图",fontsize=30,fontname='宋体',fontproperties=myfont) plt.xlabel('横坐标',fontsize=20,fontname='宋体',fontproperties=myfont) plt.ylabel('纵坐标',fontsize=20,fontname='宋体',fontproperties=myfont) # 设置刻度标记大小,axis='both'参数影响横纵坐标，labelsize刻度大小 plt.tick_params(axis='both',labelsize=14) # 显示图形 plt.show() 游戏占比与冰淇淋公升数关系折线图可视化：（此处折线图明显不合适，只是突出另一种分析方式。） 扩展： 更多matplotlib可视化实现效果图参考文章 70个注意的Python小Notes:完整的matplotlib可视化 基于Echart的可视化分析 我们上面采用的matplotlib可视化效果，采用该方式主要是结合python数据分析绑定比较方便。有些时候我们为了取得更加漂亮的可视化效果，可以选择百度echart进行分析，百度Echart使用简单且文档规范容易上手。我们对原数据进行分析并转化为json代码：1234567891011'''array数据转化json'''def norm_Json(dataset): noredataset = norm_dataset(dataset)[0] # 数据归一化 number1 = np.around(noredataset[:,1], decimals=4) # 获取数据集第二列 number2 = np.around(noredataset[:,2], decimals=4) # 获取数据集第三列 returnMat=zeros((dataset.shape[0],2)) # 二维矩阵 returnMat[:,0] = number1 returnMat[:,1] = number2 file_path = os.path.abspath(r"./datasource/test.json") json.dump(returnMat.tolist(), codecs.open(file_path, 'w', encoding='utf-8'), separators=(',', ':'), sort_keys=True, indent=4) 生成json数据保存在指定文件中，打开文件查看数据如下： [ [ 0.3981, 0.5623 ], [ 0.342, 0.9872 ], [ 0.0689, 0.4745 ], [ 0.6285, 0.2525 ] ... [ 0.4367, 0.429 ], [ 0.3768, 0.7857 ] ] 从百度Echart实例中选择一种散点图并绑定json文件，其html代码如下：1234567891011121314151617181920212223242526272829303132333435363738394041424344454647484950515253545556575859&lt;!DOCTYPE html&gt;&lt;html&gt;&lt;head&gt; &lt;meta charset="UTF-8"&gt; &lt;title&gt;图案例&lt;/title&gt; &lt;script src="https://cdn.bootcss.com/jquery/2.2.0/jquery.min.js"&gt;&lt;/script&gt; &lt;script type="text/javascript" src="./js/echarts.js"&gt;&lt;/script&gt;&lt;/head&gt;&lt;body&gt; &lt;div id="chartmain" style="width:800px; height: 400px; margin:auto; "&gt; &lt;/div&gt; &lt;script type="text/javascript"&gt; //初始化echarts实例 var myChart = echarts.init(document.getElementById('chartmain')); $.getJSON('game-food.json', function (data) &#123; var option = &#123; title: &#123; text: '玩游戏时间占比和饮食数据描述', left: 'center', top: 0 &#125;, visualMap: &#123; min: 15202, max: 159980, dimension: 1, orient: 'vertical', right: 10, top: 'center', text: ['优秀', '一般'], calculable: true, inRange: &#123; color: ['#f2c31a', '#24b7f2'] &#125; &#125;, tooltip: &#123; trigger: 'item', axisPointer: &#123; type: 'cross' &#125; &#125;, xAxis: [&#123; type: 'value' &#125;], yAxis: [&#123; type: 'value' &#125;], series: [&#123; name: 'price-area', type: 'scatter', symbolSize: 5, data: data &#125;] &#125;; myChart.setOption(option);&#125;); &lt;/script&gt;&lt;/body&gt;&lt;/html&gt; json文件读取需要在web运行环境中，单纯的运行效果如下图所示： 数据转化工具 本文采用自己构建的方式进行json文件生成，此外我们也可以采用现有的数据转化工具进行处理。比如百度的表格数据转化工具（2.2节已经介绍了）。 另一个便是在线json验证格式工具:http://www.bejson.com/ 2.5 KNN分类器实现通过数据分析，我们查看数据样本是否偏态分别，数据规模情况等等。针对性进行数据预处理后，编写具体算法模型。本文主要是KNN分类器，其代码如下：12345678910111213141516171819202122232425262728293031323334''' 构造KNN分类器 vecX:输入向量，待测数据 filename: 特征集文件路径 isnorm:是否进行归一化处理 k:k值的选择，默认选择3'''def knn_classifier(vecX,dataset,labels,isnorm='Y',k=3): # 距离计算（方法1） if isnorm == 'Y': normMat,ranges,minVals = norm_dataset(dataset) # 对数据进行归一化处理 normvecX = norm_dataset(vecX) else: normMat = dataset normvecX = vecX m = normMat.shape[0] # tile方法是在列向量vecX，datasetSize次，行向量vecX1次叠加 diffMat = tile(normvecX,(m,1)) - normMat sqDiffMat = diffMat ** 2 sqDistances = sqDiffMat.sum(axis=1) # axis=0 是列相加,axis=1是行相加 distances = sqDistances**0.5 # print('vecX向量到数据集各点距离：\n'+str(distances)) sortedDistIndexs = distances.argsort(axis=0) # 距离排序，升序 # print(sortedDistIndicies) classCount = &#123;&#125; # 统计前k个类别出现频率 for i in range(k): votelabel = labels[sortedDistIndexs[i]] classCount[votelabel] = classCount.get(votelabel,0) + 1 #统计键值 # 类别频率出现最高的点,itemgetter(0)按照key排序，itemgetter(1)按照value排序 sortedClassCount = sorted(classCount.items(),key=operator.itemgetter(1),reverse=True) print(str(vecX)+'KNN的投票决策结果：\n'+str(sortedClassCount[0][0])) return sortedClassCount[0][0] 3 KNN算法模型评估3.1 评价指标介绍 基本知识 混淆矩阵：正元组和负元组的合计 评估度量：（其中P:正样本数 N：负样本数 TP：真正例 TN：真负例 FP：假正例 FN：假负例） 注意：学习器的准确率最好在检验集上估计，检验集的由训练集模型时未使用的含有标记的元组组成数据。 各参数描述如下： TP（真正例/真阳性）：是指被学习器正确学习的正元组，令TP为真正例的个数。 TN（真负例/真阴性）：是指被学习器正确学习的负元组，令TN为真负例的个数。 FP（假正例/假阳性）：是被错误的标记为正元组的负元组。令FP为假正例的个数。 FN（假负例/假阴性）：是被错误的标记为负元组的正元组。令FN为假负例的个数。 准确率：正确识别的元组所占的比例。 评价指标优点 一般采用精确率和召回率作为度量的方法具有以下几个优点： (1) 准确率数值对于小数据不是特别敏感，而精确率和召回率对于这样数据比较敏感。(2) 在相同实验环境下，F度量这种倾向和我们直观感觉是一致的，我们对目标事件很敏感，甚至返回一些垃圾数据也在所不惜。(3) 通过精确率和找回来衡量目标事件和垃圾事件的差异。 模型评估拓展 参见《自然语言处理理论与实战》一书第13章模型评估。 3.2 评估算法模型实现本文只是对错误率进行评估，其也是knn分类器核心指标，实现代码如下：1234567891011121314151617'''测试评估算法模型'''def test_knn_perfor(filename): hoRatio = 0.1 dataset,label = file_matrix(filename) # 获取训练数据和标签 normMat,ranges,minVals = norm_dataset(dataset) # 对数据进行归一化处理 m = normMat.shape[0] numTestVecs = int(m*hoRatio) # 10%的测试数据条数 errorCount = 0.0 # 统计错误分类数 for i in range(numTestVecs): classifierResult = knn_classifier(normMat[i,:],normMat[numTestVecs:m,:],label[numTestVecs:m],3) # 此处分类器可以替换不同分类模型 print('分类结果:'+str(classifierResult)+'\t\t准确结果:'+str(label[i])) if classifierResult != label[i]: errorCount += 1.0 Global.all_FileNum += 1 print('总的错误率为：'+str(errorCount/float(numTestVecs))+"\n总测试数据量: "+str(Global.all_FileNum)) 运行效果如下： [0.44832535 0.39805139 0.56233353]KNN的投票决策结果： 分类结果:3 准确结果:3 [0.15873259 0.34195467 0.98724416]KNN的投票决策结果： 分类结果:2 准确结果:2 ... 分类结果:3 准确结果:3 [0.19385799 0.30474213 0.01919426]KNN的投票决策结果： 分类结果:2 准确结果:2 [0.24463971 0.10813023 0.60259472]KNN的投票决策结果： 分类结果:1 准确结果:1 [0.51022756 0.27138082 0.41804137]KNN的投票决策结果： 分类结果:3 准确结果:1 总的错误率为：0.05 总测试数据量: 100 耗时：0.0300 s 评估结果分析： 本文采用封闭评估的方法，前100条数据作为测试集，后900条数据作为训练集。如上结果最后一条信息表明knn分类器的结果是3，而标准结果是1.knn分类存在错误。将所有错误占比分析出来即错误率。本文错误率5%，即准确率95%. 读者可以选取200:800、300:700等等数据进行测试查看错误率。 4 KNN算法模型的实际应用 knn分类器应用 经过如上的改进最终形成实际应用的算法模型API开发给外部程序使用，调用knn算法代码如下：123456789101112'''调用可用算法'''def show_classifyPerson(filename): resultlist = ['不喜欢','还可以','特别喜欢'] ffMiles = float(input('每年飞行的历程多少公里？\n')) percentTats = float(input('玩游戏时间占百分比多少？\n')) # [751,13,0.4][40920 ,8.326976,0.953952] iceCream = float(input('每周消费冰淇淋多少公升？\n')) dataset,labels = file_matrix(filename) # 数据格式化处理 inArr = array([ffMiles,percentTats,iceCream]) classifierResult = knn_classifier(inArr,dataset,labels,3) # 数据归一化并进行分类 print('预测的约会结果是：'+resultlist[classifierResult-1]) 运行结果如下： 每年飞行的历程多少公里？ 10000 玩游戏时间占百分比多少？ 10 每周消费冰淇淋多少公升？ 0.5 KNN的投票决策结果： 2 预测的约会结果是：还可以 展望 我们还可以采用knn分类器进行实际应用，比如新闻分类系统。大致思路如下： 1 采集数据：选用复旦大学的文本分类新闻语料2 准备数据：数据格式化、分词、停用词处理等3 分析数据：看看数据特点，有没有缺失值，数据连续性还是离散型，进而选择不同模型。诸如：可视化数据分析4 数据转化：采用IF-IDF或者神经网络的方法对词频进行处理，最终转化为机器可以处理的数值型矩阵。5 构建模型：KNN新闻分类器模型构建。6 测试算法：评价指标，如计算错误率，准确率，召回率，F度量值等。7 应用算法：针对完善的模型进行封装重构，然后进行实际的新闻分类应用。 参考文献 归一化学习：https://blog.csdn.net/hyq3235356/article/details/78472307 归一化方法：https://blog.csdn.net/zxd1754771465/article/details/73558103 百度Echart转化工具：http://echarts.baidu.com/spreadsheet.html 在线json验证格式工具:http://www.bejson.com/ 模型评估：http://www.cnblogs.com/baiboy/p/mxpg2.html 完整代码下载源码请进QQ群文件下载： 作者声明 本文版权归作者【白宁超】所有，转载请联系作者：1938036263@qq.com，但未经作者同意禁止转载，转载后需在文章页面明显位置给出原文连接，否则保留追究法律责任的权利。]]></content>
      <categories>
        <category>机器学习</category>
        <category>KNN</category>
      </categories>
      <tags>
        <tag>机器学习算法</tag>
        <tag>Python</tag>
        <tag>sklean</tag>
        <tag>K近邻算法</tag>
        <tag>kNN</tag>
        <tag>文本聚类</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[一步步教你轻松学K-means聚类算法]]></title>
    <url>%2F2018%2F09%2F19%2F%E4%B8%80%E6%AD%A5%E6%AD%A5%E6%95%99%E4%BD%A0%E8%BD%BB%E6%9D%BE%E5%AD%A6K-means%E8%81%9A%E7%B1%BB%E7%AE%97%E6%B3%95%2F</url>
    <content type="text"><![CDATA[摘要：k-均值算法（英文：k-means clustering），属于比较常用的算法之一，文本首先介绍聚类的理论知识包括什么是聚类、聚类的应用、聚类思想、聚类优缺点等等；然后通过k-均值聚类案例实现及其可视化有一个直观的感受，针对算法模型进行分析和结果优化提出了二分k-means算法。最后我们调用机器学习库函数，很短的代码完成聚类算法。（本文原创，转载必须注明出处.） 理论介绍聚类 什么是聚类 统计数据分析的一门技术，在许多领域受到广泛应用，包括机器学习，数据挖掘，模式识别，图像分析以及生物信息。聚类是把相似的对象通过静态分类的方法分成不同的组别或者更多的子集（subset），这样让在同一个子集中的成员对象都有相似的一些属性，常见的包括在坐标系中更加短的空间距离等。 聚类的应用 在商务上，聚类能帮助市场分析人员从客户基本库中发现不同的客户群，并且用购买模式来刻画不同的客户群的特征。在生物学上，聚类能用于推导植物和动物的分类，对基因进行分类，获得对种群中固有结构的认识。聚类在地球观测数据库中相似地区的确定，汽车保险单持有者的分组，及根据房子的类型、价值和地理位置对一个城市中房屋的分组上也可以发挥作用。聚类也能用于对Web上的文档进行分类，以发现信息。诸如此类，聚类有着广泛的实际应用。 K-means（k均值）聚类算法 什么是k-means聚类算法 k-平均算法（英文：k-means clustering）源于信号处理中的一种向量量化方法，现在则更多地作为一种聚类分析方法流行于数据挖掘领域。k-平均聚类的目的是：把 n个点划分到k个聚类中，使得每个点都属于离他最近的均值（此即聚类中心）对应的聚类，以之作为聚类的标准。k-平均聚类与k-近邻之间没有任何关系（后者是另一流行的机器学习技术）。 K-Means 是发现给定数据集的 K 个簇的聚类算法, 之所以称之为 K-均值 是因为它可以发现 K 个不同的簇, 且每个簇的中心采用簇中所含值的均值计算而成.簇个数 K 是用户指定的, 每一个簇通过其质心（centroid）, 即簇中所有点的中心来描述.聚类与分类算法的最大区别在于, 分类的目标类别已知, 而聚类的目标类别是未知的. 发展历史 虽然其思想能够追溯到1957年的Hugo Steinhaus，术语“k-均值”于1967年才被James MacQueen 首次使用。标准算法则是在1957年被Stuart Lloyd作为一种脉冲码调制的技术所提出，但直到1982年才被贝尔实验室公开出版。在1965年，E.W.Forgy发表了本质上相同的方法，所以这一算法有时被称为Lloyd-Forgy方法。更高效的版本则被Hartigan and Wong提出。 算法描述 已知观测集\((x_1,x_2,…,x_n)\)，其中每个观测都是一个 d-维实向量，k-平均聚类要把这 n个观测划分到k个集合中(k≤n),使得组内平方和最小。换句话说，它的目标是找到使得下式满足的聚类\( S_i\)， 其中 \( \mu_i\) 是\(S_i\) 中所有点的均值。 k-means术语 簇: 所有数据的点集合，簇中的对象是相似的。 质心: 簇中所有点的中心（计算所有点的均值而来）. SSE: Sum of Sqared Error（误差平方和）, 它被用来评估模型的好坏，SSE 值越小，表示越接近它们的质心. 聚类效果越 好。由于对误差取了平方，因此更加注重那些远离中心的点（一般为边界点或离群点）。详情见kmeans的评价标准。有关 簇 和 质心 术语更形象的介绍, 请参考下图: k-means应用场景 kmeans，用于数据集内种类属性不明晰，希望能够通过数据挖掘出或自动归类出有相似特点的对象的场景。其商业界的应用场景一般为挖掘出具有相似特点的潜在客户群体以便公司能够重点研究、对症下药。 例如，在2000年和2004年的美国总统大选中，候选人的得票数比较接近或者说非常接近。任一候选人得到的普选票数的最大百分比为50.7%而最小百分比为47.9% 如果1%的选民将手中的选票投向另外的候选人，那么选举结果就会截然不同。 实际上，如果妥善加以引导与吸引，少部分选民就会转换立场。尽管这类选举者占的比例较低，但当候选人的选票接近时，这些人的立场无疑会对选举结果产生非常大的影响。如何找出这类选民，以及如何在有限的预算下采取措施来吸引他们？ 答案就是聚类（Clustering)。 那么，具体如何实施呢？首先，收集用户的信息，可以同时收集用户满意或不满意的信息，这是因为任何对用户重要的内容都可能影响用户的投票结果。然后，将这些信息输入到某个聚类算法中。接着，对聚类结果中的每一个簇（最好选择最大簇 ）， 精心构造能够吸引该簇选民的消息。最后， 开展竞选活动并观察上述做法是否有效。 另一个例子就是产品部门的市场调研了。为了更好的了解自己的用户，产品部门可以采用聚类的方法得到不同特征的用户群体，然后针对不同的用户群体可以对症下药，为他们提供更加精准有效的服务。 k-means算法思想 先随机选取K个对象作为初始的聚类中心。然后计算每个对象与各个种子聚类中心之间的距离，把每个对象分配给距离它最近的聚类中心。聚类中心以及分配给它们的对象就代表一个聚类。一旦全部对象都被分配了，每个聚类的聚类中心会根据聚类中现有的对象被重新计算。这个过程将不断重复直到满足某个终止条件。终止条件可以是以下任何一个： 没有（或最小数目）对象被重新分配给不同的聚类。 没有（或最小数目）聚类中心再发生变化。 误差平方和局部最小。 得到相互分离的球状聚类，在这些聚类中，均值点趋向收敛于聚类中心。 一般会希望得到的聚类大小大致相当，这样把每个观测都分配到离它最近的聚类中心（即均值点）就是比较正确的分配方案。 k-means工作流程 创建 k 个点作为起始质心（通常是随机选择） 当任意一个点的簇分配结果发生改变时（不改变时算法结束） 对数据集中的每个数据点 对每个质心 计算质心与数据点之间的距离 将数据点分配到距其最近的簇 对每一个簇, 计算簇中所有点的均值并将均值作为质心 k-means开发流程 收集数据：使用任意方法 准备数据：需要数值型数据类计算距离, 也可以将标称型数据映射为二值型数据再用于距离计算 分析数据：使用任意方法 训练算法：不适用于无监督学习，即无监督学习不需要训练步骤 测试算法：应用聚类算法、观察结果.可以使用量化的误差指标如误差平方和（后面会介绍）来评价算法的结果. 使用算法：可以用于所希望的任何应用.通常情况下, 簇质心可以代表整个簇的数据来做出决策. k-means评价标准 k-means算法因为手动选取k值和初始化随机质心的缘故，每一次的结果不会完全一样，而且由于手动选取k值，我们需要知道我们选取的k值是否合理，聚类效果好不好，那么如何来评价某一次的聚类效果呢？也许将它们画在图上直接观察是最好的办法，但现实是，我们的数据不会仅仅只有两个特征，一般来说都有十几个特征，而观察十几维的空间对我们来说是一个无法完成的任务。因此，我们需要一个公式来帮助我们判断聚类的性能，这个公式就是SSE (Sum of Squared Error, 误差平方和 ），它其实就是每一个点到其簇内质心的距离的平方值的总和，这个数值对应kmeans函数中clusterAssment矩阵的第一列之和。 SSE值越小表示数据点越接近于它们的质心，聚类效果也越好。 因为对误差取了平方，因此更加重视那些远离中心的点。一种肯定可以降低SSE值的方法是增加簇的个数，但这违背了聚类的目标。聚类的目标是在保持簇数目不变的情况下提高簇的质量。 k-means优缺点 优点: 属于无监督学习，无须准备训练集 原理简单，实现起来较为容易 结果可解释性较好 缺点: 聚类数目k是一个输入参数。选择不恰当的k值可能会导致糟糕的聚类结果。这也是为什么要进行特征检查来决定数据集的聚类数目了。 可能收敛到局部最小值, 在大规模数据集上收敛较慢 对于异常点、离群点敏感 使用数据类型 : 数值型数据 k-means聚类算法实现案例描述我们假设这样的一个案例需求：某公司发布一批新型手机，根据客户热衷度进行投放。公司市场人员收集其中四个地区用户对手机的满意程度（由两个特征决定的）。分析哪个区域对手机产品比较热衷，对应的进行市场销售工作。这里就用到k-means聚类算法。 从文件加载数据集上文中我们收集好四个地区用户对产品满意的特征数据值，转化为向量预先保存到文本中（关于词向量转化及其词袋模型问题，参考：决策树算法模型研究与案例分析一文）。我们加载文件并以数据矩阵形式返回数据集，代码实现如下： 123456789101112'''加载数据集'''def loadDataSet(fileName): dataSet = [] # 初始化一个空列表 fr = open(fileName) for line in fr.readlines(): # 切割每一行的数据 curLine = line.strip().split('\t') # 将数据追加到dataMat，映射所有的元素为 float类型 fltLine = list(map(float,curLine)) dataSet.append(fltLine) return mat(dataSet) 我们打印看下结果： 计算两个向量的欧氏距离上文在k均值算法思想和工作流程都提到过，我们一个重要的方法就是随机设置质心，然后比较每条数据（可以理解为单一客户的特征数据）与质心之间的距离。这里距离公式包括很多，本文采用的是欧式距离计算，其代码实现如下： 123'''欧氏距离计算函数'''def distEclud(vecA, vecB): return sqrt(sum(power(vecA - vecB, 2))) 构建一个包含 K 个随机质心的集合接下来，我们构建随机质心（中心点），这里的K值是经过数据观察随机设置的值，假如k=3，代表我们将数据集分为3个簇，也就是说分为3个部分。我们随机质心在整个数据集的边界之内，这可以通过找到数据集每一维的最小和最大值来完成,然后生成0到1.0之间的随机数并通过取值范围和最小值,以便确保随机点在数据的边界之内。123456789101112131415161718'''随机质心'''def randCent(dataMat, k): # 获取样本数与特征值 m, n = shape(dataMat) # 初始化质心,创建(k,n)个以零填充的矩阵 centroids = mat(zeros((k, n))) # 循环遍历特征值 for j in range(n): # 计算每一列的最小值 minJ = min(dataMat[:, j]) # 计算每一列的范围值 rangeJ = float(max(dataMat[:, j]) - minJ) # 计算每一列的质心,并将值赋给centroids centroids[:, j] = mat(minJ + rangeJ * random.rand(k, 1)) # 返回质心 return centroids 我们测试下k=3的随机质心结果： K-Means 聚类算法我们基于以上算法构建k均值算法，该算法会创建k个质心，然后将每个点分配到最近的质心，再重新计算质心。这个过程重复数次，直到数据点的簇分配结果不再改变位置。返回类质心与点分配结果（多次运行结果可能会不一样，可以试试，原因为随机质心的影响，但总的结果是对的，因为数据足够相似，也可能会陷入局部最小值），代码实现如下：1234567891011121314151617181920212223242526272829303132333435363738394041424344'''创建K个质心,然后将每个点分配到最近的质心,再重新计算质心。这个过程重复数次,直到数据点的簇分配结果不再改变为止'''def kMeans(dataMat, k, distMeas=distEclud, createCent=randCent): # 获取样本数和特征数 m, n = shape(dataMat) # 初始化一个矩阵来存储每个点的簇分配结果 # clusterAssment包含两个列:一列记录簇索引值,第二列存储误差(误差是指当前点到簇质心的距离,后面会使用该误差来评价聚类的效果) clusterAssment = mat(zeros((m, 2))) # 创建质心,随机K个质心 centroids = createCent(dataMat, k) # 初始化标志变量,用于判断迭代是否继续,如果True,则继续迭代 clusterChanged = True while clusterChanged: clusterChanged = False # 遍历所有数据找到距离每个点最近的质心, # 可以通过对每个点遍历所有质心并计算点到每个质心的距离来完成 for i in range(m): minDist = inf # 正无穷 minIndex = -1 for j in range(k): # 计算数据点到质心的距离 # 计算距离是使用distMeas参数给出的距离公式,默认距离函数是distEclud distJI = distMeas(centroids[j, :], dataMat[i, :]) # 如果距离比minDist(最小距离)还小,更新minDist(最小距离)和最小质心的index(索引) if distJI &lt; minDist: minDist = distJI minIndex = j # 如果任一点的簇分配结果发生改变,则更新clusterChanged标志 if clusterAssment[i, 0] != minIndex: # print(clusterAssment[i, 0],minIndex) clusterChanged = True # 更新簇分配结果为最小质心的index(索引),minDist(最小距离)的平方 clusterAssment[i, :] = minIndex, minDist ** 2 # print(centroids) # 遍历所有质心并更新它们的取值 for cent in range(k): # 通过数据过滤来获得给定簇的所有点 ptsInClust = dataMat[nonzero(clusterAssment[:, 0].A == cent)[0]] # 计算所有点的均值,axis=0表示沿矩阵的列方向进行均值计算 centroids[cent, :] = mean(ptsInClust, axis=0)# axis=0列方向 # 返回所有的类质心与点分配结果 return centroids, clusterAssment 测试查看下运行结果： 分析数据：聚类可视化通过上文返回的数据结果，似乎我们还不能直观感受，接下来我们采用可视化分析方法直观感受下，代码实现如下：1234567'''可视化展示'''def kmeanShow(dataMat,centers,clusterAssment): plt.scatter(np.array(dataMat)[:, 0], np.array(dataMat)[:, 1], c=np.array(clusterAssment)[:, 0].T) plt.scatter(centers[:, 0].tolist(), centers[:, 1].tolist(), c="r") plt.show() 测试查看可视化结果： 结果讨论与分析 局部最小值（局部最优的结果，但不是全局最优的结果） 上文可视化结果显示，其中两个簇聚集在一起，也就说说没有达到我们预期的效果。出现这个问题有很多原因，可能是k值取的不合适，可能是距离函数不合适，可能是最初随机选取的质心靠的太近，也可能是数据本身分布的问题。 为了解决这个问题，我们可以对生成的簇进行后处理，一种方法是将具有最大SSE值的簇划分成两个簇。具体实现时可以将最大簇包含的点过滤出来并在这些点上运行K-均值算法，令k设为2。 为了保持簇总数不变，可以将某两个簇进行合并。从上图中很明显就可以看出，应该将上图下部两个出错的簇质心进行合并。那么问题来了，我们可以很容易对二维数据上的聚类进行可视化， 但是如果遇到40维的数据应该如何去做？ 有两种可以量化的办法：合并最近的质心，或者合并两个使得SSE增幅最小的质心。 第一种思路通过计算所有质心之间的距离， 然后合并距离最近的两个点来实现。第二种方法需要合并两个簇然后计算总SSE值。必须在所有可能的两个簇上重复上述处理过程，直到找到合并最佳的两个簇为止。 因为上述后处理过程实在是有些繁琐，所以有更厉害的大佬提出了另一个称之为二分K-均值（bisecting K-Means）的算法. 二分 K-Means 聚类算法算法描述该算法首先将所有点作为一个簇，然后将该簇一分为二。之后选择其中一个簇继续进行划分，选择哪一个簇进行划分取决于对其划分时候可以最大程度降低 SSE（平方和误差）的值。上述基于 SSE 的划分过程不断重复，直到得到用户指定的簇数目为止。 二分 K-Means 聚类算法伪代码将所有点看成一个簇 当簇数目小于 k 时 对于每一个簇 计算总误差 在给定的簇上面进行 KMeans 聚类（k=2） 计算将该簇一分为二之后的总误差 选择使得误差最小的那个簇进行划分操作 另一种做法是选择 SSE 最大的簇进行划分，直到簇数目达到用户指定的数目位置。 二分 K-Means 聚类算法代码根据算法思想，我们基于k均值算法做了少许的改动，代码实现如下：1234567891011121314151617181920212223242526272829303132333435363738394041424344454647'''在给定数据集,所期望的簇数目和距离计算方法的条件下,函数返回聚类结果'''def biKmeans(dataMat, k, distMeas=distEclud): m, n = shape(dataMat) # 创建一个矩阵来存储数据集中每个点的簇分配结果及平方误差 clusterAssment = mat(zeros((m, 2))) # 计算整个数据集的质心,并使用一个列表来保留所有的质心 centroid0 = mean(dataMat, axis=0).tolist()[0] centList = [centroid0] # [-0.15772275000000002, 1.2253301166666664] # 遍历数据集中所有点来计算每个点到质心的误差值 for j in range(m): clusterAssment[j, 1] = distMeas(mat(centroid0), dataMat[j, :]) ** 2 # 对簇不停的进行划分,直到得到想要的簇数目为止 while (len(centList) &lt; k): # 初始化最小SSE为无穷大,用于比较划分前后的SSE lowestSSE = inf # 通过考察簇列表中的值来获得当前簇的数目,遍历所有的簇来决定最佳的簇进行划分 for i in range(len(centList)): # 对每一个簇,将该簇中的所有点堪称一个小的数据集 ptsInCurrCluster = dataMat[nonzero(clusterAssment[:, 0].A == i)[0], :] # 将ptsInCurrCluster输入到函数kMeans中进行处理,k=2, # kMeans会生成两个质心(簇),同时给出每个簇的误差值 centroidMat, splitClustAss = kMeans(ptsInCurrCluster, 2, distMeas) # 将误差值与剩余数据集的误差之和作为本次划分的误差 sseSplit = sum(splitClustAss[:, 1]) sseNotSplit = sum(clusterAssment[nonzero(clusterAssment[:, 0].A != i)[0], 1]) print('sseSplit, and notSplit: ', sseSplit, sseNotSplit) # 如果本次划分的SSE值最小,则本次划分被保存 if (sseSplit + sseNotSplit) &lt; lowestSSE: bestCentToSplit = i bestNewCents = centroidMat bestClustAss = splitClustAss.copy() lowestSSE = sseSplit + sseNotSplit # 找出最好的簇分配结果 # 调用kmeans函数并且指定簇数为2时,会得到两个编号分别为0和1的结果簇 bestClustAss[nonzero(bestClustAss[:, 0].A == 1)[0], 0] = len(centList) # 更新为最佳质心 bestClustAss[nonzero(bestClustAss[:, 0].A == 0)[0], 0] = bestCentToSplit print('the bestCentToSplit is: ', bestCentToSplit) print('the len of bestClustAss is: ', len(bestClustAss)) # 更新质心列表 # 更新原质心list中的第i个质心为使用二分kMeans后bestNewCents的第一个质心 centList[bestCentToSplit] = bestNewCents[0, :].tolist()[0] # 添加bestNewCents的第二个质心 centList.append(bestNewCents[1, :].tolist()[0]) # 重新分配最好簇下的数据(质心)以及SSE clusterAssment[nonzero(clusterAssment[:, 0].A == bestCentToSplit)[0], :] = bestClustAss return mat(centList), clusterAssment 测试二分 KMeans 聚类算法经过改进后，我们运行biKmeans函数得到可视化结果如下： 总结：如此我们得到预想的结果，解决了局部最优的问题，聚类会收敛到全局最小值。而原始的 kMeans() 函数偶尔会陷入局部最小值。 调用机器学习库sklearn实现k-means 聚类加载数据集1234567# 加载数据集dataMat = []fr = open("./testSet2.txt") # 注意，这个是相对路径for line in fr.readlines(): curLine = line.strip().split('\t') fltLine = list(map(float,curLine)) # 映射所有的元素为 float（浮点数）类型 dataMat.append(fltLine) 训练k-means算法模型1234km = KMeans(n_clusters=3) # 初始化km.fit(dataMat) # 拟合km_pred = km.predict(dataMat) # 预测centers = km.cluster_centers_ # 质心 可视化结果123plt.scatter(np.array(dataMat)[:, 1], np.array(dataMat)[:, 0], c=km_pred)plt.scatter(centers[:, 1], centers[:, 0], c="r")plt.show() 聚类结果 参考文献 scikit中文社区：http://sklearn.apachecn.org/cn/0.19.0/ 中文维基百科：https://zh.wikipedia.org/wiki/K-%E5%B9%B3%E5%9D%87%E7%AE%97%E6%B3%95 GitHub：https://github.com/BaiNingchao/MachineLearning-1 图书：《机器学习实战》 图书：《自然语言处理理论与实战》 完整代码下载 源码请进【机器学习和自然语言QQ群：436303759】文件下载： 作者声明 本文版权归作者【白宁超】所有，转载请联系作者：1938036263@qq.com，但未经作者同意禁止转载，转载后需在文章页面明显位置给出原文连接，否则保留追究法律责任的权利。]]></content>
      <categories>
        <category>机器学习</category>
        <category>K-Means</category>
      </categories>
      <tags>
        <tag>K-均值算法</tag>
        <tag>k-means</tag>
        <tag>机器学习算法</tag>
        <tag>文本分类</tag>
        <tag>Python</tag>
        <tag>sklean</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[一步步教你轻松学逻辑回归模型算法]]></title>
    <url>%2F2018%2F09%2F19%2F%E4%B8%80%E6%AD%A5%E6%AD%A5%E6%95%99%E4%BD%A0%E8%BD%BB%E6%9D%BE%E5%AD%A6%E9%80%BB%E8%BE%91%E5%9B%9E%E5%BD%92%E6%A8%A1%E5%9E%8B%E7%AE%97%E6%B3%95%2F</url>
    <content type="text"><![CDATA[摘要：逻辑回归（Logistic regression）即逻辑模型，属于常见的一种分类算法。本文将从理论介绍开始，搞清楚什么是逻辑回归、回归系数、算法思想、工作原理及其优缺点等。进一步通过两个实际案例深化理解逻辑回归，以及在工程应用进行实现。（本文原创，转载必须注明出处.） 理论介绍逻辑回归和Sigmoid 函数 逻辑回归 回归：假设现在有一些数据点，我们用一条直线对这些点进行拟合（这条直线称为最佳拟合直线），这个拟合的过程就叫做回归。 逻辑回归（Logistic Regression）是一种用于解决二分类（0 or 1）问题的机器学习方法，用于估计某种事物的可能性。比如某用户购买某商品的可能性，某病人患有某种疾病的可能性，以及某广告被用户点击的可能性等。 注意，这里用的是“可能性”，而非数学上的“概率”，logisitc回归的结果并非数学定义中的概率值，不可以直接当做概率值来用。该结果往往用于和其他特征值加权求和，而非直接相乘。 Sigmoid 函数 Sigmoid函数是一个常见的S型数学函数，在信息科学中，由于其单增以及反函数单增等性质，Sigmoid函数常被用作神经网络的阈值函数，将变量映射到0,1之间。在逻辑回归、人工神经网络中有着广泛的应用。Sigmoid函数的数学形式是： 对x求导可以推出如下结论： 下图给出了 Sigmoid 函数在不同坐标尺度下的两条曲线图。当 x 为 0 时，Sigmoid 函数值为 0.5 。随着 x 的增大，对应的 Sigmoid 值将逼近于 1 ; 而随着 x 的减小， Sigmoid 值将逼近于 0 。如果横坐标刻度足够大， Sigmoid 函数看起来很像一个阶跃函数。 因此，为了实现 Logistic 回归分类器，我们可以在每个特征上都乘以一个回归系数，然后把所有结果值相加，将这个总和代入 Sigmoid 函数中，进而得到一个范围在 0~1 之间的数值。任何大于 0.5 的数据被分入 1 类，小于 0.5 即被归入 0 类。所以，Logistic 回归也是一种概率估计，比如这里Sigmoid 函数得出的值为0.5，可以理解为给定数据和参数，数据被分入 1 类的概率为0.5。(注意：针对二分类问题，0.5不是唯一确定分类的值，你可以根据需求调整这个概率值。) 逻辑回归与线性回归的关系 逻辑回归（Logistic Regression）与线性回归（Linear Regression）都是一种广义线性模型（generalized linear model）。逻辑回归假设因变量 y 服从伯努利分布，而线性回归假设因变量 y 服从高斯分布。 因此与线性回归有很多相同之处，去除Sigmoid映射函数的话，逻辑回归算法就是一个线性回归。可以说，逻辑回归是以线性回归为理论支持的，但是逻辑回归通过Sigmoid函数引入了非线性因素，因此可以轻松处理0/1分类问题。 最优化方法的回归系数Sigmoid 函数的输入记为 z ，由下面公式得到: 如果采用向量的写法，上述公式可以写成 Sigmoid 函数计算公式向量形式\( z=w^Tx\)，它表示将这两个数值向量对应元素相乘然后全部加起来即得到 z 值。其中的向量 x 是分类器的输入数据，向量 w 也就是我们要找到的最佳参数（系数），从而使得分类器尽可能地精确。为了寻找该最佳参数，需要用到最优化理论的一些知识。我们这里使用的是——梯度上升法（Gradient Ascent）。 梯度上升与梯度下降 梯度 对于梯度这个词一些人比较陌生，我们先看看维基百科的解释：在向量微积分中，标量场（向量场）中某一点的梯度指向在这点标量场增长最快的方向（当然要比较的话必须固定方向的长度），梯度的绝对值是长度为1的方向中函数最大的增加率，也就是说\( |\nabla f|=\max_{|v|=1} {\nabla_v f}\)，其中 \( \nabla_v\) 代表方向导数。 在单变量的实值函数的情况，梯度只是导数，或者，对于一个线性函数，也就是线的斜率。 梯度一词有时用于斜度，也就是一个曲面沿着给定方向的倾斜程度。可以通过取向量梯度和所研究的方向的内积来得到斜度。梯度的数值有时也被称为梯度。（更多梯度相关知识参照维基百科词条） 梯度形式化描述 考虑一座高度在 (x, y)点是 H(x, y)的山。H这一点的梯度是在该点坡度（或者说斜度）最陡的方向。梯度的大小告诉我们坡度到底有多陡。这个现象可以如下数学的表示。山的高度函数 H的梯度点积一个单位向量给出了表面在该向量的方向上的斜率。这称为方向导数。 理解梯度 为了大家更容易理解什么是梯度，我们介意向量的概念，向量是一个矢量具有大小和方向的。同样，梯度也可以类比为具备大小和方向的这么一个概念。其两者比较如下：（这里严格意义上讲是不成立的，便于大家理解。） 向量 = 值 + 方向 梯度 = 向量 梯度 = 梯度值 + 梯度方向 梯度上升 要找到某函数的最大值，最好的方法是沿着该函数的梯度方向探寻。如果梯度记为 ▽ ，则函数 f(x, y) 的梯度由下式表示: \nabla f(x,y) = \begin{pmatrix} {\frac{\partial f(x,y)}{\partial x}}, {\frac{\partial f(x,y)}{\partial y}} \end{pmatrix}这个梯度意味着要沿 x 的方向移动\( {\frac{\partial f(x,y)}{\partial x}} \)，沿 y 的方向移动\({\frac{\partial f(x,y)}{\partial x}}\)。其中，函数f(x, y) 必须要在待计算的点上有定义并且可微。下图是一个具体的例子。 上图展示的，梯度上升算法到达每个点后都会重新估计移动的方向。从 P0 开始，计算完该点的梯度，函数就根据梯度移动到下一点 P1。在 P1 点，梯度再次被重新计算，并沿着新的梯度方向移动到 P2 。如此循环迭代，直到满足停止条件。迭代过程中，梯度算子总是保证我们能选取到最佳的移动方向。 上图中的梯度上升算法沿梯度方向移动了一步。可以看到，梯度算子总是指向函数值增长最快的方向。这里所说的是移动方向，而未提到移动量的大小。该量值称为步长，记作 α 。用向量来表示的话，梯度上升算法的迭代公式如下: 例如：y = w0 + w1x1 + w2x2 + ... + wnxn 梯度：参考上图的例子，二维图像，x方向代表第一个系数，也就是 w1，y方向代表第二个系数也就是 w2，这样的向量就是梯度。 α：上面的梯度算法的迭代公式中的阿尔法，这个代表的是移动步长（step length）。移动步长会影响最终结果的拟合程度，最好的方法就是随着迭代次数更改移动步长。步长通俗的理解，100米，如果我一步走10米，我需要走10步；如果一步走20米，我只需要走5步。这里的一步走多少米就是步长的意思。 ▽f(w)：代表沿着梯度变化的方向，也可以理解该方向求导。 该公式将一直被迭代执行，直至达到某个停止条件为止，比如迭代次数达到某个指定值或者算法达到某个可以允许的误差范围。 梯度上升与梯度下降的区别 梯度下降是大家听的最多的，本质上梯度下降与梯度上升算法是一样的，只是公司中加法变减法，梯度下降的公式如下： 在求极值的问题中，有梯度上升和梯度下降两个最优化方法。梯度上升用于求最大值，梯度下降用于求最小值。如logistic回归的目标函数：代表的是概率，我们想求概率最大值，即对数似然函数的最大值，所以使用梯度上升算法。而线性回归的代价函数：代表的则是误差，我们想求误差最小值，所以用梯度下降算法。 逻辑回归分类核心思想根据现有数据对分类边界建立回归公司，以此进行分类。回归即最佳拟合。 逻辑回归工作原理每个回归系数初始化为 1 重复 R 次: 计算整个数据集的梯度 使用 步长 x 梯度 更新回归系数的向量 返回回归系数 逻辑回归算法流程收集数据: 采用任意方法收集数据 准备数据: 由于需要进行距离计算，因此要求数据类型为数值型。另外，结构化数据格式则最佳。 分析数据: 采用任意方法对数据进行分析。 训练算法: 大部分时间将用于训练，训练的目的是为了找到最佳的分类回归系数。 测试算法: 一旦训练步骤完成，分类将会很快。 使用算法: 首先，我们需要输入一些数据，并将其转换成对应的结构化数值；接着，基于训练好的回归系数就可以对这些数值进行简单的回归计算，判定它们属于哪个类别； 逻辑回归优缺点优点: 计算代价不高，易于理解和实现。 缺点: 容易欠拟合，分类精度可能不高。 适用数据类型: 数值型和标称型数据。 案例分析1：Logistic回归在简单数据集上的分类案例描述在一个简单的数据集上，采用梯度上升法找到 Logistic 回归分类器在此数据集上的最佳回归系数 开发流程 收集数据: 可以使用任何方法 准备数据: 由于需要进行距离计算，因此要求数据类型为数值型。另外，结构化数据格式则最佳 分析数据: 画出决策边界 训练算法: 使用梯度上升找到最佳参数 测试算法: 使用 Logistic 回归进行分类 使用算法: 对简单数据集中数据进行分类 数据采集本文采用100行的测试集文本。其中前两列是特征1，和特征2，第三类是对应的标签。（这里特征1，特征2作为测试使用没有实际意义，你可以理解为特征1 是水里游的，特征2是有鱼鳞。类别判断是否为鱼类。） 读取文本文件，加载数据集和类标签，这里将特征集第一列加1，便于后续回归系数的计算：12345678910111213'''加载数据集和类标签'''def loadDataSet(file_name): # dataMat为原始数据， labelMat为原始数据的标签 dataMat,labelMat = [],[] fr = open(file_name) for line in fr.readlines(): lineArr = line.strip().split(',') if len(lineArr) == 1: continue # 这里如果就一个空的元素，则跳过本次循环 # 为了方便计算，我们将每一行的开头添加一个 1.0 作为 X0 dataMat.append([1.0, float(lineArr[0]), float(lineArr[1])]) labelMat.append(int(lineArr[2])) return dataMat, labelMat 梯度上升训练算法模型 梯度上升算法 使用梯度上升训练算法模型，其代码实现如下：1234567891011121314151617181920''' 正常的梯度上升法，得到的最佳回归系数 '''def gradAscent(dataMatIn, classLabels): dataMatrix = mat(dataMatIn) # 转换为 NumPy 矩阵 # 转化为矩阵[[0,1,0,1,0,1.....]]，并转制[[0],[1],[0].....] # transpose() 行列转置函数 # 将行向量转化为列向量 =&gt; 矩阵的转置 labelMat = mat(classLabels).transpose() # 首先将数组转换为 NumPy 矩阵，然后再将行向量转置为列向量 # m-&gt;数据量，样本数 n-&gt;特征数 m, n = shape(dataMatrix) # 矩阵的行数和列数 # print(m,n) alpha = 0.001 # alpha代表向目标移动的步长 maxCycles = 500 # 迭代次数 weights = ones((n, 1)) # 代表回归系数,ones((n,1)) 长度和特征数相同矩阵全是1 for k in range(maxCycles): h = sigmoid(dataMatrix * weights) # 矩阵乘法 # labelMat是实际值 error = (labelMat - h) # 向量相减 # 0.001* (3*m)*(m*1) 表示在每一个列上的一个误差情况，最后得出 x1,x2,xn的系数的偏移量 weights = weights + alpha * dataMatrix.transpose() * error # 矩阵乘法，最后得到回归系数 return array(weights) 其中sigmoid函数实现如下：123''' sigmoid跳跃函数 '''def sigmoid(ZVar): return 1.0 / (1 + exp(-ZVar)) 代码分析：函数的两个参数是数据加载返回的特征集和标签类集合。对数据集进行mat矩阵话转化，而类标签集进行矩阵之后转置，便于行列式的计算。然后设定步长，和迭代次数。整个特征矩阵与回归系数乘积求sigmoid值，最后返回回归系数的值。运行结果如下： [[ 4.12414349] [ 0.48007329] [-0.6168482 ]] 思考？步长和迭代次数的初始值如何设定？ 随机梯度上升算法 梯度上升算法在每次更新回归系数时都需要遍历整个数据集，该方法在处理 100 个左右的数据集时尚可，但如果有数十亿样本和成千上万的特征，那么该方法的计算复杂度就太高了。一种改进方法是一次仅用一个样本点来更新回归系数，该方法称为 随机梯度上升算法。由于可以在新样本到来时对分类器进行增量式更新，因而随机梯度上升算法是一个在线学习(online learning)算法。与 “在线学习” 相对应，一次处理所有数据被称作是 “批处理” （batch） 。其伪代码是： 所有回归系数初始化为 1 对数据集中每个样本 计算该样本的梯度 使用 alpha x gradient 更新回归系数值 返回回归系数值 随机梯度上升算法的代码实现如下：1234567891011121314''' 随机梯度上升'''# 梯度上升与随机梯度上升的区别？梯度下降在每次更新数据集时都需要遍历整个数据集，计算复杂都较高；随机梯度下降一次只用一个样本点来更新回归系数def stocGradAscent0(dataMatrix, classLabels): m, n = shape(dataMatrix) alpha = 0.01 weights = ones(n) # 初始化长度为n的数组，元素全部为 1 for i in range(m): # sum(dataMatrix[i]*weights)为了求 f(x)的值，f(x)=a1*x1+b2*x2+..+nn*xn h = sigmoid(sum(dataMatrix[i] * weights)) # 计算真实类别与预测类别之间的差值，然后按照该差值调整回归系数 error = classLabels[i] - h # 0.01*(1*1)*(1*n) weights = array(weights) + alpha * error * array(mat(dataMatrix[i])) return array(weights.transpose()) 可以看到，随机梯度上升算法与梯度上升算法在代码上很相似，但也有一些区别: 第一，后者的变量 h 和误差 error 都是向量，而前者则全是数值；第二，前者没有矩阵的转换过程，所有变量的数据类型都是 NumPy 数组。 判断优化算法优劣的可靠方法是看它是否收敛，也就是说参数是否达到了稳定值，是否还会不断地变化？下图展示了随机梯度上升算法在 200 次迭代过程中回归系数的变化情况。其中的系数2，也就是 X2 只经过了 50 次迭代就达到了稳定值，但系数 1 和 0 则需要更多次的迭代。如下图所示: 针对波动问题，我们改进了之前的随机梯度上升算法，具体代码实现如下:12345678910111213141516171819''' 改进版的随机梯度上升，使用随机的一个样本来更新回归系数'''def stocGradAscent1(dataMatrix, classLabels, numIter=150): m, n = shape(dataMatrix) weights = ones(n) # 创建与列数相同的矩阵的系数矩阵 # 随机梯度, 循环150,观察是否收敛 for j in range(numIter): dataIndex = list(range(m)) # [0, 1, 2 .. m-1] for i in range(m): # i和j的不断增大，导致alpha的值不断减少，但是不为0 alpha = 4 / (1.0 + j + i) + 0.0001 # alpha随着迭代不断减小非0 # random.uniform(x, y) 随机生成下一个实数，它在[x,y]范围内 Index = int(random.uniform(0, len(dataIndex))) # sum(dataMatrix[i]*weights)为了求 f(x)的值， f(x)=a1*x1+b2*x2+..+nn*xn h = sigmoid(sum(dataMatrix[dataIndex[Index]] * weights)) error = classLabels[dataIndex[Index]] - h weights = weights + alpha * error *array(mat(dataMatrix[dataIndex[Index]])) del (dataIndex[Index]) # print(weights.transpose()) return weights.transpose() 上面的改进版随机梯度上升算法改了两处代码。 改进为 alpha 的值。alpha 在每次迭代的时候都会调整，这回缓解上面波动图的数据波动或者高频波动。另外，虽然 alpha 会随着迭代次数不断减少，但永远不会减小到 0，因为我们在计算公式中添加了一个常数项。 修改为 randIndex 更新，这里通过随机选取样本拉来更新回归系数。这种方法将减少周期性的波动。这种方法每次随机从列表中选出一个值，然后从列表中删掉该值（再进行下一次迭代）。 分析数据：画出决策边界边界可视化的代码实现如下：12345678910111213141516171819202122232425262728''' 数据可视化展示 '''def plotBestFit(dataArr, labelMat, weights): n = shape(dataArr)[0] xcord1,xcord2,ycord1,ycord2 = [],[],[],[] for i in range(n): if int(labelMat[i]) == 1: xcord1.append(dataArr[i, 1]) ycord1.append(dataArr[i, 2]) else: xcord2.append(dataArr[i, 1]) ycord2.append(dataArr[i, 2]) fig = plt.figure() ax = fig.add_subplot(111) ax.scatter(xcord1, ycord1, s=30, c='red', marker='s') ax.scatter(xcord2, ycord2, s=30, c='green') x = arange(-3.0, 3.0, 0.1) """ dataMat.append([1.0, float(lineArr[0]), float(lineArr[1])]) w0*x0+w1*x1+w2*x2=f(x) x0最开始就设置为1， x2就是我们画图的y值，而f(x)被我们磨合误差给算到w0,w1,w2身上去了 所以： w0+w1*x+w2*y=0 =&gt; y = (-w0-w1*x)/w2 """ y = (-weights[0] - weights[1] * x) / weights[2] ax.plot(x, y) plt.xlabel('X') plt.ylabel('Y') plt.show() 运行结果分别是： 梯度上升算法可视化结果图1-1： 随机梯度上升算法可视化结果： 优化随机梯度上升算法可视化结果： 结果分析： 图1-1的梯度上升算法在每次更新回归系数时都需要遍历整个数据集，虽然分类结果还不错该方法的计算复杂度就太高了。图1-2的随机梯度上升算法虽然分类效果不是很好（分类1/3左右），但是其迭代次数远远小于图1-1迭代次数（500次）。整体性能有所改进，但是其存在局部波动现象。基于此改进后的图1-3效果显示好很多。 测试算法: 使用Logistic回归进行分类代码实现如下：123456789'''数据集决策可视化'''def simpleTest(file_name): # 1.收集并准备数据 dataMat, labelMat = loadDataSet(file_name) # 2.训练模型， f(x)=a1*x1+b2*x2+..+nn*xn中 (a1,b2, .., nn).T的矩阵值 dataArr = array(dataMat) weights = stocGradAscent1(dataArr, labelMat) # 数据可视化 plotBestFit(dataArr, labelMat, weights) 案例分析2：从病毒性流感预测病人的死亡情况案例描述使用 Logistic 回归来预测病毒性流感预测病人的死亡问题。这个数据集中包含了医院检测病毒性流感的一些指标，有的指标比较主观，有的指标难以测量，例如人的疼痛级别。 开发流程 收集数据: 给定数据文件 准备数据: 用 Python 解析文本文件并填充缺失值 分析数据: 可视化并观察数据 训练算法: 使用优化算法，找到最佳的系数 测试算法: 为了量化回归的效果，需要观察错误率。根据错误率决定是否回退到训练阶段， 通过改变迭代的次数和步长的参数来得到更好的回归系数 使用算法: 实现一个简单的命令行程序来收集马的症状并输出预测结果并非难事， 这可以作为留给大家的一道习题 收集数据: 给定数据文件训练数据已经给出，这里对文件处理即可，代码如下：12345678910111213'''加载数据集和类标签2'''def loadDataSet2(file_name): frTrain = open(file_name) trainingSet,trainingLabels = [],[] for line in frTrain.readlines(): currLine = line.strip().split(',') # print(len(currLine)) lineArr = [] for i in range(len(currLine)-1): lineArr.append(float(currLine[i])) trainingSet.append(lineArr) trainingLabels.append(float(currLine[len(currLine)-1])) return trainingSet,trainingLabels 准备数据: 用 Python 解析文本文件并填充缺失值 处理数据中的缺失值 假设有100个样本和20个特征，这些数据都是机器收集回来的。若机器上的某个传感器损坏导致一个特征无效时该怎么办？此时是否要扔掉整个数据？这种情况下，另外19个特征怎么办？ 它们是否还可以用？答案是肯定的。因为有时候数据相当昂贵，扔掉和重新获取都是不可取的，所以必须采用一些方法来解决这个问题。下面给出了一些可选的做法： 使用可用特征的均值来填补缺失值； 使用特殊值来填补缺失值，如 -1； 忽略有缺失值的样本； 使用有相似样本的均值添补缺失值； 使用另外的机器学习算法预测缺失值。 现在，我们对下一节要用的数据集进行预处理，使其可以顺利地使用分类算法。在预处理需要做两件事:所有的缺失值必须用一个实数值来替换，因为我们使用的 NumPy 数据类型不允许包含缺失值。我们这里选择实数 0 来替换所有缺失值，恰好能适用于 Logistic 回归。这样做的直觉在于，我们需要的是一个在更新时不会影响系数的值。回归系数的更新公式如下:weights = weights + alpha * error * dataMatrix[dataIndex[randIndex]]如果 dataMatrix 的某个特征对应值为 0，那么该特征的系数将不做更新，即:weights = weights另外，由于 Sigmoid(0) = 0.5 ，即它对结果的预测不具有任何倾向性，因此我们上述做法也不会对误差造成任何影响。基于上述原因，将缺失值用 0 代替既可以保留现有数据，也不需要对优化算法进行修改。此外，该数据集中的特征取值一般不为 0，因此在某种意义上说它也满足 “特殊值” 这个要求。如果在测试数据集中发现了一条数据的类别标签已经缺失，那么我们的简单做法是将该条数据丢弃。这是因为类别标签与特征不同，很难确定采用某个合适的值来替换。采用 Logistic 回归进行分类时这种做法是合理的，而如果采用类似 kNN 的方法，则保留该条数据显得更加合理。 训练算法: 使用优化算法，找到最佳的系数训练算法模型代码如下：12345678910111213141516'''测试Logistic算法分类'''def testClassier(): # 使用改进后的随机梯度上升算法 求得在此数据集上的最佳回归系数 trainWeights file_name = './HorseColicTraining.txt' trainingSet,trainingLabels = loadDataSet2(file_name) trainWeights = stocGradAscent1(array(trainingSet), trainingLabels, 500) # 根据特征向量预测结果 teststr = '2.000000,1.000000,38.300000,40.000000,24.000000,1.000000,1.000000,3.000000,1.000000,3.000000,3.000000,1.000000,0.000000,0.000000,0.000000,1.000000,1.000000,33.000000,6.700000,0.000000,0.000000' currLine = teststr.strip().split(',') lineArr = [] for i in range(len(currLine)): lineArr.append(float(currLine[i])) res = classifyVector(array(lineArr), trainWeights) # 打印预测结果 reslut = ['死亡','存活'] print('预测结果是：',int(res)) 分类函数代码如下：123456'''分类函数，根据回归系数和特征向量来计算 Sigmoid的值,大于0.5函数返回1，否则返回0'''def classifyVector(featuresV, weights): prob = sigmoid(sum(featuresV * weights)) print(prob) if prob &gt; 0.9: return 1.0 else: return 0.0 测试算法：使用决策树执行分类为了量化回归的效果，需要观察错误率。根据错误率决定是否回退到训练阶段，通过改变迭代的次数和步长的参数来得到更好的回归系数1234567891011121314151617181920212223242526272829'''打开测试集和训练集,并对数据进行格式化处理'''def colicTest(): file_name = './HorseColicTraining.txt' trainingSet,trainingLabels = loadDataSet2(file_name) # 使用改进后的随机梯度上升算法 求得在此数据集上的最佳回归系数 trainWeights trainWeights = stocGradAscent1(array(trainingSet), trainingLabels, 500) frTest = open('./HorseColicTest.txt') errorCount = 0 ; numTestVec = 0.0 # 读取 测试数据集 进行测试，计算分类错误的样本条数和最终的错误率 for line in frTest.readlines(): numTestVec += 1.0 currLine = line.strip().split(',') lineArr = [] for i in range(21): lineArr.append(float(currLine[i])) if int(classifyVector(array(lineArr), trainWeights)) != int( currLine[21]): errorCount += 1 errorRate = (float(errorCount) / numTestVec) print("逻辑回归算法测试集的错误率为: %f" % errorRate) return errorRate# 调用 colicTest() 10次并求结果的平均值def multiTest(): numTests = 10;errorSum = 0.0 for k in range(numTests): errorSum += colicTest() print("迭代 %d 次后的平均错误率是: %f" % (numTests, errorSum / float(numTests))) 其运行结果如下： 逻辑回归算法测试集的错误率为: 0.298507 参考文献 scikit中文社区：http://sklearn.apachecn.org/cn/0.19.0/ 中文维基百科：https://zh.wikipedia.org/wiki/%E9%82%8F%E8%BC%AF%E8%BF%B4%E6%AD%B8 GitHub：https://github.com/BaiNingchao/MachineLearning-1 图书：《机器学习实战》 图书：《自然语言处理理论与实战》 完整代码下载 源码请进【机器学习和自然语言QQ群：436303759】文件下载： 作者声明 本文版权归作者【白宁超】所有，转载请联系作者：1938036263@qq.com，但未经作者同意禁止转载，转载后需在文章页面明显位置给出原文连接，否则保留追究法律责任的权利。]]></content>
      <categories>
        <category>机器学习</category>
        <category>逻辑回归</category>
      </categories>
      <tags>
        <tag>机器学习算法</tag>
        <tag>文本分类</tag>
        <tag>Python</tag>
        <tag>逻辑回归</tag>
        <tag>Logistic regression</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[一步步教你轻松学朴素贝叶斯模型算法Sklearn深度篇3]]></title>
    <url>%2F2018%2F09%2F19%2F%E4%B8%80%E6%AD%A5%E6%AD%A5%E6%95%99%E4%BD%A0%E8%BD%BB%E6%9D%BE%E5%AD%A6%E6%9C%B4%E7%B4%A0%E8%B4%9D%E5%8F%B6%E6%96%AF%E6%A8%A1%E5%9E%8B%E7%AE%97%E6%B3%95Sklearn%E6%B7%B1%E5%BA%A6%E7%AF%873%2F</url>
    <content type="text"><![CDATA[摘要：朴素贝叶斯模型是机器学习常用的模型算法之一，其在文本分类方面简单易行，且取得不错的分类效果。所以很受欢迎，对于朴素贝叶斯的学习，本文首先介绍理论知识即朴素贝叶斯相关概念和公式推导，为了加深理解，采用一个维基百科上面性别分类例子进行形式化描述。然后通过编程实现朴素贝叶斯分类算法，并在屏蔽社区言论、垃圾邮件、个人广告中获取区域倾向等几个方面进行应用，包括创建数据集、数据预处理、词集模型和词袋模型、朴素贝叶斯模型训练和优化等。然后结合复旦大学新闻语料进行朴素贝叶斯的应用。最后，大家熟悉其原理和实现之后，采用机器学习sklearn包进行实现和优化。由于篇幅较长，采用理论理解、案例实现、sklearn优化三个部分进行学习。（本文原创，转载必须注明出处.） 复旦新闻语料：朴素贝叶斯中文文本分类项目概述本节介绍朴素贝叶斯分类算法模型在中文领域中的应用。我们对新闻语料进行多文本分类操作，本文选择艺术、文学、教育、哲学、历史五个类别的训练文本，然后采用新的测试语料进行分类预测。 收集数据数据集是从复旦新闻语料库中抽取出来的，考虑学习使用，样本选择并不大。主要抽选艺术、文学、教育、哲学、历史五个类别各10篇文章。全部数据文档50篇。具体情况不同对收集数据要求不同，你也可以选择网络爬取，数据库导出等。这文档读取时候可能会遇到gbk，utf-8等格式共存的情况，这里建议采用BatUTF8Conv.exe（点击下载）工具，进行utf-8格式批量转化。 准备数据创建数据集代码如下：123456789101112131415161718192021222324252627282930313233343536373839404142'''创建数据集和类标签'''def loadDataSet(): docList = [];classList = [] # 文档列表、类别列表 dirlist = ['C3-Art','C4-Literature','C5-Education','C6-Philosophy','C7-History'] for j in range(5): for i in range(1, 11): # 总共10个文档 # 切分，解析数据，并归类为 1 类别 wordList = textParse(open('./fudan/%s/%d.txt' % (dirlist[j],i),encoding='UTF-8').read()) docList.append(wordList) classList.append(j) # print(i,'\t','./fudan/%s/%d.txt' % (dirlist[j],i),'\t',j) return docList,classList''' 利用jieba对文本进行分词，返回切词后的list '''def textParse(str_doc): # 正则过滤掉特殊符号、标点、英文、数字等。 import re r1 = '[a-zA-Z0-9’!"#$%&amp;\'()*+,-./:;&lt;=&gt;?@，。?★、…【】《》？“”‘’！[\\]^_`&#123;|&#125;~]+' str_doc=re.sub(r1, '', str_doc) # 创建停用词列表 stwlist = set([line.strip() for line in open('./stopwords.txt', 'r', encoding='utf-8').readlines()]) sent_list = str_doc.split('\n') # word_2dlist = [rm_tokens(jieba.cut(part), stwlist) for part in sent_list] # 分词并去停用词 word_2dlist = [rm_tokens([word+"/"+flag+" " for word, flag in pseg.cut(part) if flag in ['n','v','a','ns','nr','nt']], stwlist) for part in sent_list] # 带词性分词并去停用词 word_list = list(itertools.chain(*word_2dlist)) # 合并列表 return word_list''' 去掉一些停用词、数字、特殊符号 '''def rm_tokens(words, stwlist): words_list = list(words) for i in range(words_list.__len__())[::-1]: word = words_list[i] if word in stwlist: # 去除停用词 words_list.pop(i) elif len(word) == 1: # 去除单个字符 words_list.pop(i) elif word == " ": # 去除空字符 words_list.pop(i) return words_list 代码分析：loadDataSet()方法是遍历读取文件夹，并对每篇文档进行处理，最后返回全部文档集的列表和类标签。textParse()方法是对每篇文档字符串进行数据预处理，我们首选使用正则方法保留文本数据，然后进行带有词性的中文分词和词性选择，rm_tokens()是去掉一些停用词、数字、特殊符号。最终返回相对干净的数据集和标签集。 分析数据前面两篇文章都介绍了，我们需要把文档进行向量化表示，首先构建全部文章的单词集合，实现代码如下：1234567'''获取所有文档单词的集合'''def createVocabList(dataSet): vocabSet = set([]) for document in dataSet: vocabSet = vocabSet | set(document) # 操作符 | 用于求两个集合的并集 # print(len(vocabSet),len(set(vocabSet))) return list(vocabSet) 基于文档模型的基础上，我们将特征向量转化为数据矩阵向量，这里使用的词袋模型，构造与实现方法如下：1234567'''文档词袋模型，创建矩阵数据'''def bagOfWords2VecMN(vocabList, inputSet): returnVec = [0] * len(vocabList) for word in inputSet: if word in vocabList: returnVec[vocabList.index(word)] += 1 return returnVec 对矩阵数据可以采用可视化分析方法或者结合NLTK进行数据分析，检查数据分布情况和特征向量构成情况及其特征选择作为参考。 训练算法我们在前面两篇文章介绍了朴素贝叶斯模型训练方法，我们在该方法下稍微改动就得到如下实现：12345678910111213141516171819202122232425'''朴素贝叶斯模型训练数据优化'''def trainNB0(trainMatrix, trainCategory): numTrainDocs = len(trainMatrix) # 总文件数 numWords = len(trainMatrix[0]) # 总单词数 p1Num=p2Num=p3Num=p4Num=p5Num = ones(numWords) # 各类为1的矩阵 p1Denom=p2Denom=p3Denom=p4Denom=p5Denom = 2.0 # 各类特征和 num1=num2=num3=num4=num5 = 0 # 各类文档数目 pNumlist=[p1Num,p2Num,p3Num,p4Num,p5Num] pDenomlist =[p1Denom,p2Denom,p3Denom,p4Denom,p5Denom] Numlist = [num1,num2,num3,num4,num5] for i in range(numTrainDocs): # 遍历每篇训练文档 for j in range(5): # 遍历每个类别 if trainCategory[i] == j: # 如果在类别下的文档 pNumlist[j] += trainMatrix[i] # 增加词条计数值 pDenomlist[j] += sum(trainMatrix[i]) # 增加该类下所有词条计数值 Numlist[j] +=1 # 该类文档数目加1 pVect,pi = [],[] for index in range(5): pVect.append(log(pNumlist[index] / pDenomlist[index])) pi.append(Numlist[index] / float(numTrainDocs)) return pVect, pi 构建分类函数，其优化后的代码实现如下：123456789101112'''朴素贝叶斯分类函数,将乘法转换为加法'''def classifyNB(vec2Classify, pVect,pi): # 计算公式 log(P(F1|C))+log(P(F2|C))+....+log(P(Fn|C))+log(P(C)) bnpi = [] # 文档分类到各类的概率值列表 for x in range(5): bnpi.append(sum(vec2Classify * pVect[x]) + log(pi[x])) # print([bnp for bnp in bnpi]) # 分类集合 reslist = ['Art','Literature','Education','Philosophy','History'] # 根据最大概率，选择索引值 index = [bnpi.index(res) for res in bnpi if res==max(bnpi)] return reslist[index[0]] # 返回分类值 测试算法我们加载构建的数据集方法，然后创建单词集合，集合词袋模型进行特征向量化，构建训练模型和分类方法，最终我们从复旦新闻语料中选择一篇未加入训练集的教育类文档，进行开放测试，具体代码如下：1234567891011121314151617181920'''朴素贝叶斯新闻分类应用'''def testingNB(): # 1. 加载数据集 dataSet,Classlabels = loadDataSet() # 2. 创建单词集合 myVocabList = createVocabList(dataSet) # 3. 计算单词是否出现并创建数据矩阵 trainMat = [] for postinDoc in dataSet: trainMat.append(bagOfWords2VecMN(myVocabList, postinDoc)) with open('./word-bag.txt','w') as f: for i in trainMat: f.write(str(i)+'\r\n') # 4. 训练数据 pVect,pi= trainNB0(array(trainMat), array(Classlabels)) # 5. 测试数据 testEntry = textParse(open('./fudan/test/C5-1.txt',encoding='UTF-8').read()) thisDoc = array(bagOfWords2VecMN(myVocabList, testEntry)) print(testEntry[:10], '分类结果是: ', classifyNB(thisDoc, pVect,pi)) 实现结果如下： Building prefix dict from the default dictionary ... Loading model from cache C:\Users\ADMINI~1\AppData\Local\Temp\jieba.cache Loading model cost 0.892 seconds. Prefix dict has been built succesfully. [&#39;全国/n &#39;, &#39;举办/v &#39;, &#39;电影/n &#39;, &#39;新华社/nt &#39;, &#39;北京/ns &#39;, &#39;国家教委/nt &#39;, &#39;广播电影电视部/nt &#39;, &#39;文化部/n &#39;, &#39;联合/v &#39;, &#39;决定/v &#39;] 分类结果是: Literature 耗时：29.4882 s 结果分析：我们运行分类器得出结果易知，预测结果是文化类，且运行时间为29s。首先分析为什么预测错误，这里面主要是训练集样本比较少和特征选择的原因。运行时间是由于将特征矩阵存储本地后，后面直接读取文本，相当于加载缓存，大大缩短运行时间。但是这里还有值得优化的地方，比如每次运行都会加载训练模型，大大消耗时间，我们能不能训练模型加载一次，多次调用呢？当然是可以的，这个问题下文继续优化。我们重点关注下特征选择问题 特征选择问题讨论 做文本分类的时候，遇到特征矩阵1.5w。在测试篇幅小的文章总是分类错误？这个时候如何做特征选择？是不是说去掉特征集中频率极高和极低的一部分，对结果有所提升？ 答：你说的这个情况是很普遍的现象，篇幅小的文章，特征小，所以模型更容易判断出错！去掉高频和低频通常是可以使得训练的模型泛化能力变强 比如：艺术，文化，历史，教育。界限本来就不明显，比如测试数据“我爱艺术，艺术是我的全部”。结果会分类为文化。其实这个里面还有就是不同特征词的权重问题，采用tf-idf优化下应该会好一些？ 答：我个人觉得做文本特征提取，还是需要自己去分析文本本身内容的文字特点，你可以把每一类的文本的实体提取出来，然后统计一下每个词在每一类上的数量，看看数量分布，也许可以发现一些数据特点 我就是按照这个思路做的，还有改进时候的停用词，其实可以分析特征文本，针对不同业务，使用自定义的停用词要比通用的好还有提前各类见最具表征性的词汇加权，凸显本类的权重是吧？ 答：比如，艺术类文章中，哪些词出现较多，哪些词出现少，再观察这些词的词性主要是哪些，这样可能会对你制定提取特征规则方式的时候提供一定的思路参考，我可以告诉你的是，有些词绝对会某一类文章出出现多，然后在其他类文章出现很少，这一类的词就是文章的特征词 那样的思路可以是：对某类文章单独构建类内的词汇表再进行选择。最后对类间词汇表叠加就ok了。 答：词汇表有个缺点就是，不能很好的适应新词 改进思路呢 答：我给你一个改进思路：你只提取每个文本中的名词、动词、形容词、地名，用这些词的作为文本的特征来训练试一试，用文本分类用主题模型（LDA）来向量化文本，再训练模型试一试。如果效果还是不够好，再将文本向量用PCA进行一次特征降维，然后再训练模型试一试，按常理来说，效果应该会有提高 还有我之前个人写的程序分类效果不理想，后来改用sklearn内置BN运行依旧不理想。适当改进了特征提取，还是不理想。估计每类10篇文章的训练数据太少了 答：文本本身特征提取就相对难一些，再加上训练数据少，训练出来的模型效果可想而已，正常的 sklearn：朴素贝叶斯分类调用数据准备和数据预处理 加载文档数据集和分类集 数据准备和数据预处理上文已经介绍了，本节增加了一个全局变量存储词汇表，目的是写入到本地文本里，本地读取词汇集，避免每次都做特征向量时加载训练集，提高运行时间。1234567891011121314151617181920212223242526myVocabList = [] # 设置词汇表的全局变量'''创建数据集和类标签'''def loadDataSet(): docList = [];classList = [] # 文档列表、类别列表、文本特征 dirlist = ['C3-Art','C4-Literature','C5-Education','C6-Philosophy','C7-History'] for j in range(5): for i in range(1, 11): # 总共10个文档 # 切分，解析数据，并归类为 1 类别 wordList = textParse(open('./fudan/%s/%d.txt' % (dirlist[j],i),encoding='UTF-8').read()) docList.append(wordList) classList.append(j) # print(i,'\t','./fudan/%s/%d.txt' % (dirlist[j],i),'\t',j) # print(len(docList),len(classList),len(fullText)) global myVocabList myVocabList = createVocabList(docList) # 创建单词集合 return docList,classList,myVocabList''' 利用jieba对文本进行分词，返回切词后的list '''def textParse(str_doc): #与上文方法一致 ''' 去掉一些停用词、数字、特殊符号 '''def rm_tokens(words, stwlist): #与上文方法一致 文档数据集和分类集在本地读写操作12345678910111213141516171819202122232425262728293031323334353637383940414243444546# 本地存储数据集和标签def storedata(): # 3. 计算单词是否出现并创建数据矩阵 # trainMat =[[0,1,2,3],[2,3,1,5],[0,1,4,2]] # 训练集 # classList = [0,1,2] #类标签 docList,classList,myVocabList = loadDataSet() # 计算单词是否出现并创建数据矩阵 trainMat = [] for postinDoc in docList: trainMat.append(bagOfWords2VecMN(myVocabList, postinDoc)) res = "" for i in range(len(trainMat)): res +=' '.join([str(x) for x in trainMat[i]])+' '+str(classList[i])+'\n' # print(res[:-1]) # 删除最后一个换行符 with open('./word-bag.txt','w') as fw: fw.write(res[:-1]) with open('./wordset.txt','w') as fw: fw.write(' '.join([str(v) for v in myVocabList]))# 读取本地数据集和标签 def grabdata(): f = open('./word-bag.txt') # 读取本地文件 arrayLines = f.readlines() # 行向量 tzsize = len(arrayLines[0].split(' '))-1 # 列向量，特征个数减1即数据集 returnMat = zeros((len(arrayLines),tzsize)) # 0矩阵数据集 classLabelVactor = [] # 标签集，特征最后一列 index = 0 for line in arrayLines: # 逐行读取 listFromLine = line.strip().split(' ') # 分析数据，空格处理 # print(listFromLine) returnMat[index,:] = listFromLine[0:tzsize] # 数据集 classLabelVactor.append(int(listFromLine[-1])) # 类别标签集 index +=1 # print(returnMat,classLabelVactor) myVocabList=writewordset() return returnMat,classLabelVactor,myVocabList def writewordset(): f1 = open('./wordset.txt') myVocabList =f1.readline().split(' ') for w in myVocabList: if w=='': myVocabList.remove(w) return myVocabList 获取文档集合和构建词袋模型1234567891011121314151617'''获取所有文档单词的集合'''def createVocabList(dataSet): vocabSet = set([]) for document in dataSet: vocabSet = vocabSet | set(document) # 操作符 | 用于求两个集合的并集 # print(len(vocabSet),len(set(vocabSet))) return list(vocabSet)'''文档词袋模型，创建矩阵数据'''def bagOfWords2VecMN(vocabList, inputSet): returnVec = [0] * len(vocabList) for word in inputSet: if word in vocabList: returnVec[vocabList.index(word)] += 1 return returnVec 高斯朴素贝叶斯GaussianNB 实现了运用于分类的高斯朴素贝叶斯算法。特征的可能性(即概率)假设为高斯分布: 参数\(\sigma_y ,\mu_y\)使用最大似然法估计。 高斯朴素贝叶斯实现方法代码： &#39;&#39;&#39;高斯朴素贝叶斯&#39;&#39;&#39; def MyGaussianNB(trainMat=&#39;&#39;,Classlabels=&#39;&#39;,testDoc=&#39;&#39;): # -----sklearn GaussianNB------- # 训练数据 X = np.array(trainMat) Y = np.array(Classlabels) # 高斯分布 clf = GaussianNB() clf.fit(X, Y) # 测试预测结果 index = clf.predict(testDoc) # 返回索引 reslist = [&#39;Art&#39;,&#39;Literature&#39;,&#39;Education&#39;,&#39;Philosophy&#39;,&#39;History&#39;] print(reslist[index[0]]) 多项朴素贝叶斯MultinomialNB 实现了服从多项分布数据的朴素贝叶斯算法，也是用于文本分类(这个领域中数据往往以词向量表示，尽管在实践中 tf-idf 向量在预测时表现良好)的两大经典朴素贝叶斯算法之一。 分布参数由每类 y 的 \theta_y=(\theta_{y1},\ldots,\theta_{yn}) 向量决定， 式中 n 是特征的数量(对于文本分类，是词汇量的大小)\( \theta_{yi}\)是样本中属于类 y 中特征 i 概率\(P(x_i \mid y)\)。参数\( \theta_y\)使用平滑过的最大似然估计法来估计，即相对频率计数: 式中N_{yi}=\sum_{x \in T} x_i 是训练集 T 中 特征 i 在类 y 中出现的次数，N_{yi}=\sum_{x \in T} y_i是类 y 中出现所有特征的计数总和。先验平滑因子\(alpha \ge 0\)应用于在学习样本中没有出现的特征，以防在将来的计算中出现0概率输出。 把 \(\alpha = 1\)被称为拉普拉斯平滑(Lapalce smoothing)，而 \(\alpha &lt; 1\)被称为利德斯通(Lidstone smoothing)。 多项朴素贝叶斯实现方法代码：12345678910111213'''多项朴素贝叶斯'''def MyMultinomialNB(trainMat='',Classlabels='',testDoc=''): # -----sklearn MultinomialNB------- # 训练数据 X = np.array(trainMat) Y = np.array(Classlabels) # 多项朴素贝叶斯 clf = MultinomialNB() clf.fit(X, Y) # 测试预测结果 index = clf.predict(testDoc) # 返回索引 reslist = ['Art','Literature','Education','Philosophy','History'] print(reslist[index[0]]) 伯努利朴素贝叶斯BernoulliNB 实现了用于多重伯努利分布数据的朴素贝叶斯训练和分类算法，即有多个特征，但每个特征 都假设是一个二元 (Bernoulli, boolean) 变量。 因此，这类算法要求样本以二元值特征向量表示；如果样本含有其他类型的数据， 一个 BernoulliNB 实例会将其二值化(取决于 binarize 参数)。伯努利朴素贝叶斯的决策规则基于 与多项分布朴素贝叶斯的规则不同 伯努利朴素贝叶斯明确地惩罚类 y 中没有出现作为预测因子的特征 i ，而多项分布分布朴素贝叶斯只是简单地忽略没出现的特征。在文本分类的例子中，词频向量(word occurrence vectors)(而非词数向量(word count vectors))可能用于训练和用于这个分类器。 BernoulliNB 可能在一些数据集上可能表现得更好，特别是那些更短的文档。 如果时间允许，建议对两个模型都进行评估。伯努利朴素贝叶斯代码实现如下：12345678910111213'''伯努利朴素贝叶斯'''def MyBernoulliNB(trainMat='',Classlabels='',testDoc=''): # -----sklearn BernoulliNB------- # 训练数据 X = np.array(trainMat) Y = np.array(Classlabels) # 多项朴素贝叶斯 clf = BernoulliNB() clf.fit(X, Y) # 测试预测结果 index = clf.predict(testDoc) # 返回索引 reslist = ['Art','Literature','Education','Philosophy','History'] print(reslist[index[0]]) 各种贝叶斯模型分类测试代码实现如下：12345678910def testingNB(): # 加载数据集和单词集合 trainMat,Classlabels,myVocabList = grabdata() # 读取训练结果 # 测试数据 testEntry = textParse(open('./fudan/test/C6-2.txt',encoding='UTF-8').read()) testDoc = np.array(bagOfWords2VecMN(myVocabList, testEntry)) # 测试数据 # 测试预测结果 MyGaussianNB(trainMat,Classlabels,testDoc) MyMultinomialNB(trainMat,Classlabels,testDoc) MyBernoulliNB(trainMat,Classlabels,testDoc) 运行结果： Building prefix dict from the default dictionary ... Loading model from cache C:\Users\ADMINI~1\AppData\Local\Temp\jieba.cache Loading model cost 1.014 seconds. Prefix dict has been built succesfully. 高斯朴素贝叶斯：Education 多项朴素贝叶斯分类结果：Art 伯努利朴素贝叶斯分类结果：Literature 耗时：2.3996 s 参考文献 scikit中文社区：http://sklearn.apachecn.org/cn/0.19.0/ 中文维基百科：https://zh.wikipedia.org/wiki/ 文本分类特征选择：https://www.cnblogs.com/june0507/p/7601001.html GitHub：https://github.com/BaiNingchao/MachineLearning-1 图书：《机器学习实战》 图书：《自然语言处理理论与实战》 完整代码下载 源码请进【机器学习和自然语言QQ群：436303759】文件下载： 作者声明 本文版权归作者【白宁超】所有，转载请联系作者：1938036263@qq.com，但未经作者同意禁止转载，转载后需在文章页面明显位置给出原文连接，否则保留追究法律责任的权利。]]></content>
      <categories>
        <category>机器学习</category>
        <category>朴素贝叶斯</category>
      </categories>
      <tags>
        <tag>文本分类</tag>
        <tag>Python</tag>
        <tag>Naive Bayes</tag>
        <tag>ML</tag>
        <tag>sklearn</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[一步步教你轻松学朴素贝叶斯模型算法实现篇2]]></title>
    <url>%2F2018%2F09%2F19%2F%E4%B8%80%E6%AD%A5%E6%AD%A5%E6%95%99%E4%BD%A0%E8%BD%BB%E6%9D%BE%E5%AD%A6%E6%9C%B4%E7%B4%A0%E8%B4%9D%E5%8F%B6%E6%96%AF%E6%A8%A1%E5%9E%8B%E7%AE%97%E6%B3%95%E5%AE%9E%E7%8E%B0%E7%AF%872%2F</url>
    <content type="text"><![CDATA[摘要：朴素贝叶斯模型是机器学习常用的模型算法之一，其在文本分类方面简单易行，且取得不错的分类效果。所以很受欢迎，对于朴素贝叶斯的学习，本文首先介绍理论知识即朴素贝叶斯相关概念和公式推导，为了加深理解，采用一个维基百科上面性别分类例子进行形式化描述。然后通过编程实现朴素贝叶斯分类算法，并在屏蔽社区言论、垃圾邮件、个人广告中获取区域倾向等几个方面进行应用，包括创建数据集、数据预处理、词集模型和词袋模型、朴素贝叶斯模型训练和优化等。然后结合复旦大学新闻语料进行朴素贝叶斯的应用。最后，大家熟悉其原理和实现之后，采用机器学习sklearn包进行实现和优化。由于篇幅较长，采用理论理解、案例实现、sklearn优化三个部分进行学习。（本文原创，转载必须注明出处.） 案例场景1: 屏蔽社区留言板的侮辱性言论项目概述构建一个快速过滤器来屏蔽在线社区留言板上的侮辱性言论。如果某条留言使用了负面或者侮辱性的语言，那么就将该留言标识为内容不当。对此问题建立两个类别: 侮辱类和非侮辱类，使用 1 和 0 分别表示。 本案例开发流程如下： 收集数据: 可以是文本数据、数据库数据、网络爬取的数据、自定义数据等等 数据预处理: 对采集数据进行格式化处理，文本数据的格式一致化，网络数据的分析抽取等，包括中文分词、停用词处理、词袋模型、构建词向量等。 分析数据: 检查词条确保解析的正确性，根据特征进行模型选择、特征抽取等。 训练算法: 从词向量计算概率 测试算法: 根据现实情况修改分类器 使用算法: 对社区留言板言论进行分类 收集数据本案例我们采用自定义的数据集，我们选择6条社区评论，然后进行数据处理后以list形式存储在文档列表postingList中。其中每个词代表一个特征。将每条评论进行分类（即1代表侮辱性文字,0代表非侮辱文字）存在在类别列表classVec中。最后返回数据集和类标签。代码实现如下：12345678910'''创建数据集：单词列表postingList, 所属类别classVec'''def loadDataSet(): postingList = [['my', 'dog', 'has', 'flea', 'problems', 'help', 'please'], ['maybe', 'not', 'take', 'him', 'to', 'dog', 'park', 'stupid'], ['my', 'dalmation', 'is', 'so', 'cute', 'I', 'love', 'him'], ['stop', 'posting', 'stupid', 'worthless', 'garbage'], ['mr', 'licks', 'ate', 'my', 'steak', 'how', 'to', 'stop', 'him'], ['quit', 'buying', 'worthless', 'dog', 'food', 'stupid']] classVec = [0, 1, 0, 1, 0, 1] # 1代表侮辱性文字,0代表非侮辱文字 return postingList, classVec 代码分析：postingList列表存储6条评论信息，classVec列表存储每条信息类别（1代表侮辱性文字,0代表非侮辱文字）。最后返回文档列表和类别列表。 数据预处理数据预处理包括对样本进行分词、词性筛选、停用词处理等，最后形成规范化干净的数据样本。由于本案例收集数据时默认进行了数据预处理，所以本节不在介绍（复旦新闻语料文本分类案例会详细介绍）。目前，我们采集的数据还是文本类型，计算机还不能直接处理，需要将文本数据转化成词向量进行处理。这里面需要获取特征的词汇集合（如果暂时不理解，先看看代码实现，下面会进行形式化描述）。其实现过程如下：1234567'''获取所有单词的集合:返回不含重复元素的单词列表'''def createVocabList(dataSet): vocabSet = set([]) for document in dataSet: vocabSet = vocabSet | set(document) # 操作符 | 用于求两个集合的并集 # print(vocabSet) return list(vocabSet) 代码分析：方法参数dataSet即加载数据集返回的文档列表。vocabSet是定义的不重复的数据集合。然后for循环对文档列表每条数据进行遍历处理，将不重复的词汇添加到vocabSet中，最终形成整个文档的词汇集，然后以list形式返回。 上面的方法已经获取了整个文档词汇集合，接着构建数据矩阵，代码实现如下：123456789101112'''词集模型构建数据矩阵'''def setOfWords2Vec(vocabList, inputSet): # 创建一个和词汇表等长的向量，并将其元素都设置为0 returnVec = [0] * len(vocabList) # 遍历文档中的所有单词，如果出现了词汇表中的单词，则将输出的文档向量中的对应值设为1 for word in inputSet: if word in vocabList: returnVec[vocabList.index(word)] = 1 else: print("单词: %s 不在词汇表之中!" % word) # print(returnVec) return returnVec 代码分析：本方法提供两个参数分别是整个训练文档词汇集（即全部训练文档6条评论不重复的单词集合），输入的数据列表。以整个词汇集等长的0向量。我们遍历输入数据列表，如果词特征在词汇集则标记1，不在词汇集保持为0.最后返回词向量矩阵。 与词集模型对应的，有个词袋模型。两者都是构建词向量，只是方式不一样，词袋模型也是推荐使用的词向量化方法，其实现如下：12345678'''文档词袋模型构建数据矩阵'''def bagOfWords2VecMN(vocabList, inputSet): returnVec = [0] * len(vocabList) for word in inputSet: if word in vocabList: returnVec[vocabList.index(word)] += 1 # print(returnVec) return returnVec 分析数据运行词集模型setOfWords2Vec(vocabList, dataSet[0])运行结果如下： [&#39;dog&#39;, &#39;to&#39;, &#39;take&#39;, &#39;park&#39;, &#39;licks&#39;, &#39;has&#39;, &#39;help&#39;, &#39;stupid&#39;, &#39;him&#39;, &#39;so&#39;, &#39;not&#39;, &#39;love&#39;, &#39;buying&#39;, &#39;problems&#39;, &#39;cute&#39;, &#39;stop&#39;, &#39;steak&#39;, &#39;how&#39;, &#39;flea&#39;, &#39;maybe&#39;, &#39;food&#39;, &#39;I&#39;, &#39;please&#39;, &#39;dalmation&#39;, &#39;mr&#39;, &#39;posting&#39;, &#39;ate&#39;, &#39;garbage&#39;, &#39;worthless&#39;, &#39;my&#39;, &#39;is&#39;, &#39;quit&#39;] [1, 0, 0, 0, 0, 1, 1, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 1, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 1, 0, 0] 结果分析：我们将dataSet[0]即第一条信息[‘my’, ‘dog’, ‘has’, ‘flea’, ‘problems’, ‘help’, ‘please’]构建词集模型，词特征集为[‘dog’, ‘to’, ‘take’, ‘park’, ‘licks’, ‘has’, ‘help’, ‘stupid’, ‘him’, ‘so’, ‘not’, ‘love’, ‘buying’, ‘problems’, ‘cute’, ‘stop’, ‘steak’, ‘how’, ‘flea’, ‘maybe’, ‘food’, ‘I’, ‘please’, ‘dalmation’, ‘mr’, ‘posting’, ‘ate’, ‘garbage’, ‘worthless’, ‘my’, ‘is’, ‘quit’]。结果显示[1, 0, 0, 0, 0, 1, 1, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 1, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 1, 0, 0]。即词特征集dog在dataSet[0]中，标记为1，to不在则保留原始的0.以此类推。我们也可以查看dataSet[1]等数据结果。 数据样本分析仅仅如上所述？当然不是，本例子中数据量比较小，容易分析。当数据量比较大，特征数以万计之时，人工分析就显得捉襟见肘了。我们可以采用图形化分析方法，根据具体业务需求，可以选择基于python自带的matplotlib可视化分析、或者其他图形可视化工具进行平面或多维数据分析，然后便于特征的选择。 如果是中文分词，我们还可以对词性进行分析，然后选择相应的词性特征，比如名词、动词、地名、人名、机构名等等，对虚词、助词等进行过滤，一方面达到数据降维另一方面防止模型训练拟合化等问题。 训练模型现在已经知道了一个词是否出现在一篇文档中，也知道该文档所属的类别。接下来我们重写贝叶斯准则，将之前的 x, y 替换为 w. 粗体的 w 表示这是一个向量，即它由多个值组成。在这个例子中，数值个数与词汇表中的词个数相同。 p(c_i|w)= \frac{p(w \mid c_i)p(c)} {p(w)}我们使用上述公式，对每个类计算该值，然后比较这两个概率值的大小。根据上述公式可知，我们右边的式子等同于左边的式子，由于对于每个\(c_i\)，\(P(w)\)是固定的。并且我们只需要比较左边式子值的大小来决策分类，那么我们就可以简化为通过比较右边分子值得大小来做决策分类。首先可以通过类别 i (侮辱性留言或者非侮辱性留言)中的文档数除以总的文档数来计算概率\(p(c_i)\)。接下来计算\(p(w|c_i)\)，这里就要用到朴素贝叶斯假设。如果将 w 展开为一个个独立特征，那么就可以将上述概率写作\(p(w_0,w_1,w_2…w_n|c_i)\)。这里假设所有词都互相独立，该假设也称作条件独立性假设（例如 A 和 B 两个人抛骰子，概率是互不影响的，也就是相互独立的，A 抛 2点的同时 B 抛 3 点的概率就是 1/6 * 1/6），它意味着可以使用\( p(w_0|c_i)p(w_1|c_i)p(w_2|;c_i)…p(w_n|c_i)\)来计算上述概率，这样就极大地简化了计算的过程。具体代码实现如下：12345678910111213141516171819202122232425262728'''朴素贝叶斯分类器训练函数'''def _trainNB0(trainMatrix, trainCategory): numTrainDocs = len(trainMatrix) # 文件数 numWords = len(trainMatrix[0]) # 单词数 # 侮辱性文件的出现概率，即trainCategory中所有的1的个数， # 代表的就是多少个侮辱性文件，与文件的总数相除就得到了侮辱性文件的出现概率 pAbusive = sum(trainCategory) / float(numTrainDocs) # 构造单词出现次数列表 p0Num = zeros(numWords) # [0,0,0,.....] p1Num = zeros(numWords) # [0,0,0,.....] p0Denom = 0.0;p1Denom = 0.0 # 整个数据集单词出现总数 for i in range(numTrainDocs): # 遍历所有的文件，如果是侮辱性文件，就计算此侮辱性文件中出现的侮辱性单词的个数 if trainCategory[i] == 1: p1Num += trainMatrix[i] #[0,1,1,....]-&gt;[0,1,1,...] p1Denom += sum(trainMatrix[i]) else: # 如果不是侮辱性文件，则计算非侮辱性文件中出现的侮辱性单词的个数 p0Num += trainMatrix[i] p0Denom += sum(trainMatrix[i]) # 类别1，即侮辱性文档的[P(F1|C1),P(F2|C1),P(F3|C1),P(F4|C1),P(F5|C1)....]列表 # 即 在1类别下，每个单词出现次数的占比 p1Vect = p1Num / p1Denom# [1,2,3,5]/90-&gt;[1/90,...] # 类别0，即正常文档的[P(F1|C0),P(F2|C0),P(F3|C0),P(F4|C0),P(F5|C0)....]列表 # 即 在0类别下，每个单词出现次数的占比 p0Vect = p0Num / p0Denom return p0Vect, p1Vect, pAbusive 代码分析：本方法参数分别是文档特征向量矩阵和文档类别向量矩阵。首先计算侮辱性文档占总文档的概率，然后计算正常文档下特征词的概率向量和侮辱性特征词的向量，为了更好理解上面的代码我们看下运行p0V,p1V,pAb=_trainNB0(trainMatrix,Classlabels)结果： 词汇表集 [&#39;I&#39;, &#39;cute&#39;, &#39;help&#39;, &#39;dalmation&#39;, &#39;please&#39;, &#39;has&#39;, &#39;my&#39;, &#39;him&#39;, &#39;worthless&#39;, &#39;problems&#39;, &#39;so&#39;, &#39;mr&#39;, &#39;flea&#39;, &#39;love&#39;, &#39;take&#39;, &#39;stupid&#39;, &#39;dog&#39;, &#39;park&#39;, &#39;how&#39;, &#39;quit&#39;, &#39;buying&#39;, &#39;posting&#39;, &#39;steak&#39;, &#39;maybe&#39;, &#39;to&#39;, &#39;is&#39;, &#39;ate&#39;, &#39;not&#39;, &#39;garbage&#39;, &#39;food&#39;, &#39;stop&#39;, &#39;licks&#39;] 各条评论特征向量，其中1,3,5条为类别0；2,4,6条为类别1 [0, 0, 1, 0, 1, 1, 1, 0, 0, 1, 0, 0, 1, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0] [0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 1, 1, 1, 1, 0, 0, 0, 0, 0, 1, 1, 0, 0, 1, 0, 0, 0, 0] [1, 1, 0, 1, 0, 0, 1, 1, 0, 0, 1, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0] [0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 1, 0, 1, 0] [0, 0, 0, 0, 0, 0, 1, 1, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 1, 0, 1, 0, 1, 0, 0, 0, 1, 1] [0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 1, 1, 0, 0, 1, 1, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0] 类别0下特征词条件概率 [0.04166667 0.04166667 0.04166667 0.04166667 0.04166667 0.04166667 0.125 0.08333333 0. 0.04166667 0.04166667 0.04166667 0.04166667 0.04166667 0. 0. 0.04166667 0. 0.04166667 0. 0. 0. 0.04166667 0. 0.04166667 0.04166667 0.04166667 0. 0. 0. 0.04166667 0.04166667] 类别1下特征词条件概率 [0. 0. 0. 0. 0. 0. 0. 0.05263158 0.10526316 0. 0. 0. 0. 0. 0.05263158 0.15789474 0.10526316 0.05263158 0. 0.05263158 0.05263158 0.05263158 0. 0.05263158 0.05263158 0. 0. 0.05263158 0.05263158 0.05263158 0.05263158 0. ] 0.5 结果分析：结合结果我们去理解上面的训练模型代码。首先最后一个是0.5代表侮辱性文档占全部文档的50%即一半，实际上我们标记3个正常评论词条，3个非正常的，这个显然正确。其次，第一次词I在类别1中出现0次，在类别0中出现1次。对应的条件概率分别是0.04166667和0 测试算法在利用贝叶斯分类器对文档进行分类时，要计算多个概率的乘积以获得文档属于某个类别的概率，即计算\(p(w_0|1)p(w_1|1)p(w_2|1)\)。如果其中一个概率值为 0，那么最后的乘积也为 0。为降低这种影响，可以将所有词的出现数初始化为 1，并将分母初始化为 2 （取1 或 2 的目的主要是为了保证分子和分母不为0，大家可以根据业务需求进行更改）。另一个遇到的问题是下溢出，这是由于太多很小的数相乘造成的。当计算乘积 \( p(w_0|c_i)p(w_1|c_i)p(w_2|c_i)…p(w_n|c_i)\)时，由于大部分因子都非常小，所以程序会下溢出或者得到不正确的答案。（用 Python 尝试相乘许多很小的数，最后四舍五入后会得到 0）。一种解决办法是对乘积取自然对数。在代数中有 ln(a * b) = ln(a) + ln(b), 于是通过求对数可以避免下溢出或者浮点数舍入导致的错误。同时，采用自然对数进行处理不会有任何损失。 下图给出了函数 f(x) 与 ln(f(x)) 的曲线。可以看出，它们在相同区域内同时增加或者减少，并且在相同点上取到极值。它们的取值虽然不同，但不影响最终结果。 根据朴素贝叶斯公式，我们观察分子\(p(w_i|c_i)P(c_i)\)进行条件概率连乘时候，由于有条件概率极小或者为0，最后导致结果为0 ，显然不符合我们预期结果，因此对训练模型进行优化，其优化代码如下：123456789101112131415161718192021222324252627'''训练数据优化版本'''def trainNB0(trainMatrix, trainCategory): numTrainDocs = len(trainMatrix) # 总文件数 numWords = len(trainMatrix[0]) # 总单词数 pAbusive = sum(trainCategory) / float(numTrainDocs) # 侮辱性文件的出现概率 # 构造单词出现次数列表,p0Num 正常的统计,p1Num 侮辱的统计 # 避免单词列表中的任何一个单词为0，而导致最后的乘积为0，所以将每个单词的出现次数初始化为 1 p0Num = ones(numWords)#[0,0......]-&gt;[1,1,1,1,1.....],ones初始化1的矩阵 p1Num = ones(numWords) # 整个数据集单词出现总数，2.0根据样本实际调查结果调整分母的值（2主要是避免分母为0，当然值可以调整） # p0Denom 正常的统计 # p1Denom 侮辱的统计 p0Denom = 2.0 p1Denom = 2.0 for i in range(numTrainDocs): if trainCategory[i] == 1: p1Num += trainMatrix[i] # 累加辱骂词的频次 p1Denom += sum(trainMatrix[i]) # 对每篇文章的辱骂的频次 进行统计汇总 else: p0Num += trainMatrix[i] p0Denom += sum(trainMatrix[i]) # 类别1，即侮辱性文档的[log(P(F1|C1)),log(P(F2|C1)),log(P(F3|C1)),log(P(F4|C1)),log(P(F5|C1))....]列表,取对数避免下溢出或浮点舍入出错 p1Vect = log(p1Num / p1Denom) # 类别0，即正常文档的[log(P(F1|C0)),log(P(F2|C0)),log(P(F3|C0)),log(P(F4|C0)),log(P(F5|C0))....]列表 p0Vect = log(p0Num / p0Denom) return p0Vect, p1Vect, pAbusive 我们再看生成条件概率结果如下： [-2.56494936 -2.15948425 -3.25809654 -2.56494936 -3.25809654 -3.25809654 -2.56494936 -2.56494936 -3.25809654 -2.56494936 -3.25809654 -3.25809654 -2.56494936 -2.56494936 -2.56494936 -3.25809654 -2.56494936 -2.56494936 -2.56494936 -2.56494936 -1.87180218 -2.56494936 -3.25809654 -2.56494936 -2.56494936 -2.56494936 -2.56494936 -3.25809654 -3.25809654 -2.56494936 -3.25809654 -2.56494936] [-3.04452244 -2.35137526 -2.35137526 -3.04452244 -2.35137526 -2.35137526 -3.04452244 -3.04452244 -1.94591015 -2.35137526 -2.35137526 -2.35137526 -3.04452244 -2.35137526 -3.04452244 -1.65822808 -1.94591015 -3.04452244 -3.04452244 -3.04452244 -3.04452244 -3.04452244 -2.35137526 -3.04452244 -3.04452244 -3.04452244 -3.04452244 -2.35137526 -2.35137526 -3.04452244 -2.35137526 -3.04452244] 0.5 使用算法对社区留言板言论进行分类 构建朴素贝叶斯分类函数 将乘法转换为加法乘法： 加法： 12345678910'''def classifyNB(vec2Classify, p0Vec, p1Vec, pClass1): # 计算公式 log(P(F1|C))+log(P(F2|C))+....+log(P(Fn|C))+log(P(C)) # 使用 NumPy 数组来计算两个向量相乘的结果，这里的相乘是指对应元素相乘，即先将两个向量中的第一个元素相乘，然后将第2个元素相乘，以此类推。这里的 vec2Classify * p1Vec 的意思就是将每个词与其对应的概率相关联起来 p1 = sum(vec2Classify * p1Vec) + log(pClass1) p0 = sum(vec2Classify * p0Vec) + log(1.0 - pClass1) if p1 &gt; p0: return 1 else: return 0 测试朴素贝叶斯算法 结合上面分析流程和实现方法，我们综合测试朴素贝叶斯对评论信息分类如下：123456789101112131415161718192021'''朴素贝叶斯算法屏蔽社区留言板的侮辱性言论的应用'''def testingNB(): # 1. 加载数据集 dataSet, Classlabels = loadDataSet() # 2. 创建单词集合 myVocabList = createVocabList(dataSet) # 3. 计算单词是否出现并创建数据矩阵 trainMat = [] for postinDoc in dataSet: # 返回m*len(myVocabList)的矩阵， 记录的都是0，1信息 trainMat.append(setOfWords2Vec(myVocabList, postinDoc)) # print('test',len(array(trainMat)[0])) # 4. 训练数据 p0V, p1V, pAb = trainNB0(array(trainMat), array(Classlabels)) # 5. 测试数据 testEntry = ['love', 'my', 'dalmation'] thisDoc = array(setOfWords2Vec(myVocabList, testEntry)) print(testEntry, '分类结果是: ', classifyNB(thisDoc, p0V, p1V, pAb)) testEntry = ['stupid', 'garbage'] thisDoc = array(setOfWords2Vec(myVocabList, testEntry)) print(testEntry, '分类结果是: ', classifyNB(thisDoc, p0V, p1V, pAb)) 运行结果如下： [&#39;love&#39;, &#39;my&#39;, &#39;dalmation&#39;] 分类结果是: 0 [&#39;stupid&#39;, &#39;garbage&#39;] 分类结果是: 1 案例场景2: 对社区留言板言论进行分类项目概述我们运行朴素贝叶斯分类进行电子邮件垃圾过滤。在文档分类中，整个文档（如一封电子邮件）是实例，而电子邮件中的某些元素则构成特征。我们可以观察文档中出现的词，并把每个词作为一个特征，而每个词的出现或者不出现作为该特征的值，这样得到的特征数目就会跟词汇表中的词的数目一样多。 本项目开发流程如下： 收集数据: 提供文本文件 准备数据: 将文本文件解析成词条向量 分析数据: 检查词条确保解析的正确性 训练算法: 使用我们之前建立的 trainNB() 函数 测试算法: 使用朴素贝叶斯进行交叉验证 使用算法: 构建一个完整的程序对一组文档进行分类，将错分的文档输出到屏幕上 收集数据并预处理邮件格式内容如下： 对邮件进行读取实现如下：123'''读取文本'''def testParseTest(): print(textParse(open('./email/ham/1.txt').read())) 准备数据对读取的文本进行词条向量化，其实现如下：123456'''接收一个大字符串并将其解析为字符串列表'''def textParse(bigString): import re # 使用正则表达式来切分句子，其中分隔符是除单词、数字外的任意字符串 listOfTokens = re.split(r'\W*', bigString) return [tok.lower() for tok in listOfTokens if len(tok) &gt; 2] 分析数据这个部分在案例场景1进行了详细描述，此处不在赘述。 训练算法此处，我们去调用在场景1优化过的朴素贝叶斯训练模型trainNB0() 函数，这里也是一劳永逸的方法。还可以对数据预处理等进行封装。 测试算法本测试方法中使用的数据集，即文档可以参见下文代码下载。采用方法跟场景1基本类似，这里不作代码解析。具体实现代码如下：1234567891011121314151617181920212223242526272829303132333435363738'''对贝叶斯垃圾邮件分类器进行自动化处理。'''def spamTest(): docList = [];classList = [];fullText = [] # 文档列表、类别列表、文本特征 for i in range(1, 26): # 总共25个文档 # 切分，解析数据，并归类为 1 类别 wordList = textParse(open('./email/spam/%d.txt' % i).read()) docList.append(wordList) classList.append(1) # 切分，解析数据，并归类为 0 类别 wordList = textParse(open('./email/ham/%d.txt' % i,encoding='UTF-8').read()) docList.append(wordList) classList.append(0) fullText.extend(wordList) # 创建词汇表 vocabList = createVocabList(docList) trainingSet = list(range(50)) # 词汇表文档索引 testSet = [] # 随机取 10 个邮件用来测试 for i in range(10): # random.uniform(x, y) 随机生成一个范围为 x - y 的实数 randIndex = int(random.uniform(0, len(trainingSet))) testSet.append(trainingSet[randIndex]) # 随机抽取测试样本 del(trainingSet[randIndex]) # 训练集中删除选择为测试集的文档 trainMat = [];trainClasses = [] # 训练集合训练标签 for docIndex in trainingSet: trainMat.append(setOfWords2Vec(vocabList, docList[docIndex])) trainClasses.append(classList[docIndex]) p0V, p1V, pSpam = trainNB0(array(trainMat), array(trainClasses)) errorCount = 0 for docIndex in testSet: wordVector = setOfWords2Vec(vocabList, docList[docIndex]) if classifyNB(array(wordVector), p0V, p1V, pSpam) != classList[docIndex]: errorCount += 1 print('the errorCount is: ', errorCount) print('the testSet length is :', len(testSet)) print('the error rate is :', float(errorCount)/len(testSet)) 运行结果如下： the errorCount is: 2 the testSet length is : 10 the error rate is : 0.2 案例场景3: 使用朴素贝叶斯分类器从个人广告中获取区域倾向项目概述广告商往往想知道关于一个人的一些特定人口统计信息，以便能更好地定向推销广告。我们将分别从美国的两个城市中选取一些人，通过分析这些人发布的信息，来比较这两个城市的人们在广告用词上是否不同。如果结论确实不同，那么他们各自常用的词是哪些，从人们的用词当中，我们能否对不同城市的人所关心的内容有所了解。 开发流程如下： 收集数据: 从 RSS 源收集内容，这里需要对 RSS 源构建一个接口 准备数据: 将文本文件解析成词条向量 分析数据: 检查词条确保解析的正确性 训练算法: 使用我们之前建立的 trainNB0() 函数 测试算法: 观察错误率，确保分类器可用。可以修改切分程序，以降低错误率，提高分类结果 使用算法: 构建一个完整的程序，封装所有内容。给定两个 RSS 源，改程序会显示最常用的公共词 收集数据从 RSS 源收集内容，这里需要对 RSS 源构建一个接口，也就是导入 RSS 源，我们使用 python 下载文本，在 点击下载地址 下浏览相关文档，安装 feedparse，首先解压下载的包，并将当前目录切换到解压文件所在的文件夹，然后在 python 提示符下输入：python setup.py install 准备数据 文档词袋模型 我们将每个词的出现与否作为一个特征，这可以被描述为 词集模型(set-of-words model)。如果一个词在文档中出现不止一次，这可能意味着包含该词是否出现在文档中所不能表达的某种信息，这种方法被称为 词袋模型(bag-of-words model)。在词袋中，每个单词可以出现多次，而在词集中，每个词只能出现一次。为适应词袋模型，需要对函数 setOfWords2Vec() 稍加修改，修改后的函数为 bagOfWords2Vec() 。 如下给出了基于词袋模型的朴素贝叶斯代码。它与函数 setOfWords2Vec() 几乎完全相同，唯一不同的是每当遇到一个单词时，它会增加词向量中的对应值，而不只是将对应的数值设为 1 。 这部分在场景1中已经构建完成，并进行了阐述。 分析数据这个部分在案例场景1进行了详细描述，此处不在赘述。 训练算法此处，我们去调用在场景1优化过的朴素贝叶斯训练模型trainNB0() 函数，这里也是一劳永逸的方法。还可以对数据预处理等进行封装。 测试算法观察错误率，确保分类器可用。可以修改切分程序，以降低错误率，提高分类结果。其具体实现如下： 12345678910111213141516171819202122232425262728293031323334353637383940414243444546'''RSS源分类器及高频词去除函数'''def calcMostFreq(vocabList,fullText): import operator freqDict=&#123;&#125; for token in vocabList: #遍历词汇表中的每个词 freqDict[token]=fullText.count(token) #统计每个词在文本中出现的次数 sortedFreq=sorted(freqDict.items(),key=operator.itemgetter(1),reverse=True) #根据每个词出现的次数从高到底对字典进行排序 return sortedFreq[:30] #返回出现次数最高的30个单词def localWords(feed1,feed0): # import feedparser # feedparser是python中最常用的RSS程序库 docList=[];classList=[];fullText=[] minLen=min(len(feed1['entries']),len(feed0['entries'])) # entries内容无法抓取，网站涉及反爬虫技术 print(len(feed1['entries']),len(feed0['entries'])) for i in range(minLen): wordList=textParse(feed1['entries'][i]['summary']) #每次访问一条RSS源 docList.append(wordList) fullText.extend(wordList) classList.append(1) wordList=textParse(feed0['entries'][i]['summary']) docList.append(wordList) fullText.extend(wordList) classList.append(0) vocabList=createVocabList(docList) top30Words=calcMostFreq(vocabList,fullText) for pairW in top30Words: if pairW[0] in vocabList:vocabList.remove(pairW[0]) #去掉出现次数最高的那些词 trainingSet=range(2*minLen);testSet=[] for i in range(20): randIndex=int(random.uniform(0,len(trainingSet))) testSet.append(trainingSet[randIndex]) del(trainingSet[randIndex]) trainMat=[];trainClasses=[] for docIndex in trainingSet: trainMat.append(bagOfWords2VecMN(vocabList,docList[docIndex])) trainClasses.append(classList[docIndex]) p0V,p1V,pSpam=trainNB0(array(trainMat),array(trainClasses)) errorCount=0 for docIndex in testSet: wordVector=bagOfWords2VecMN(vocabList,docList[docIndex]) if classifyNB(array(wordVector),p0V,p1V,pSpam)!=classList[docIndex]: errorCount+=1 print('the error rate is:',float(errorCount)/len(testSet)) return vocabList,p0V,p1V 运行结果： ny = feedparser.parse(&#39;http://newyork.craigslist.org/stp/index.rss&#39;) sf = feedparser.parse(&#39;http://sfbay.craigslist.org/stp/index.rss&#39;) # print(ny) vocabList,pSF,pNY=localWords(ny,sf) 由于如上两个地址抓取，得到feed0[‘entries’]为空，所以没有进行结果分析，读者可以试用其他rss地址进行处理。如下是采用之前网站反爬虫抓取前的分析结果： vocabList,pSF,pNY=bayes.localWords(ny,sf) the error rate is: 0.2 vocabList,pSF,pNY=bayes.localWords(ny,sf) the error rate is: 0.3 vocabList,pSF,pNY=bayes.localWords(ny,sf) the error rate is: 0.55 参考文献 scikit中文社区：http://sklearn.apachecn.org/cn/0.19.0/ 中文维基百科：https://zh.wikipedia.org/wiki/ 文本分类特征选择：https://www.cnblogs.com/june0507/p/7601001.html GitHub：https://github.com/BaiNingchao/MachineLearning-1 图书：《机器学习实战》 图书：《自然语言处理理论与实战》 完整代码下载 源码请进【机器学习和自然语言QQ群：436303759】文件下载： 作者声明 本文版权归作者【白宁超】所有，转载请联系作者：1938036263@qq.com，但未经作者同意禁止转载，转载后需在文章页面明显位置给出原文连接，否则保留追究法律责任的权利。]]></content>
      <categories>
        <category>机器学习</category>
        <category>朴素贝叶斯</category>
      </categories>
      <tags>
        <tag>文本分类</tag>
        <tag>Python</tag>
        <tag>Naive Bayes</tag>
        <tag>ML</tag>
        <tag>实战案例</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[一步步教你轻松学朴素贝叶斯模型算法理论篇1]]></title>
    <url>%2F2018%2F09%2F19%2F%E4%B8%80%E6%AD%A5%E6%AD%A5%E6%95%99%E4%BD%A0%E8%BD%BB%E6%9D%BE%E5%AD%A6%E6%9C%B4%E7%B4%A0%E8%B4%9D%E5%8F%B6%E6%96%AF%E6%A8%A1%E5%9E%8B%E7%AE%97%E6%B3%95%E7%90%86%E8%AE%BA%E7%AF%871%2F</url>
    <content type="text"><![CDATA[摘要：朴素贝叶斯模型是机器学习常用的模型算法之一，其在文本分类方面简单易行，且取得不错的分类效果。所以很受欢迎，对于朴素贝叶斯的学习，本文首先介绍理论知识即朴素贝叶斯相关概念和公式推导，为了加深理解，采用一个维基百科上面性别分类例子进行形式化描述。然后通过编程实现朴素贝叶斯分类算法，并在屏蔽社区言论、垃圾邮件、个人广告中获取区域倾向等几个方面进行应用，包括创建数据集、数据预处理、词集模型和词袋模型、朴素贝叶斯模型训练和优化等。然后结合复旦大学新闻语料进行朴素贝叶斯的应用。最后，大家熟悉其原理和实现之后，采用机器学习sklearn包进行实现和优化。由于篇幅较长，采用理论理解、案例实现、sklearn优化三个部分进行学习。（本文原创，转载必须注明出处.） 朴素贝叶斯理论朴素贝叶斯概述朴素贝叶斯是一种构建分类器的简单方法。该分类器模型会给问题实例分配用特征值表示的类标签，类标签取自有限集合。所有朴素贝叶斯分类器都假定样本每个特征与其他特征都不相关。 特征独立理解的例子：如果一种水果其具有红，圆，直径大概3英寸等特征，该水果可以被判定为是苹果。尽管这些特征相互依赖或者有些特征由其他特征决定，然而朴素贝叶斯分类器认为这些属性在判定该水果是否为苹果的概率分布上独立的。 尽管是带着这些朴素思想和过于简单化的假设，但朴素贝叶斯分类器在很多复杂的现实情形中仍能够获取相当好的效果。朴素贝叶斯分类器的一个优势在于只需要根据少量的训练数据估计出必要的参数（变量的均值和方差）。 朴素贝叶斯模型朴素贝叶斯方法是基于贝叶斯定理的一组有监督学习算法，即“简单”地假设每对特征之间相互独立。 给定一个类别 \(y\) 和一个从\(x_1\)&gt;到\(x_n\) 的相关的特征向量，贝叶斯定理阐述了以下关系: 使用简单(naive)的假设-每对特征之间都相互独立: 对于所有的 math: i ，这个关系式可以简化为 由于在给定的输入中\( P(x_1, \dots, x_n)\) 是一个常量，我们使用下面的分类规则: 我们可以使用最大后验概率(Maximum A Posteriori, MAP) 来估计 \(P(y)\)和\(P(x_i\mid y)\); 前者是训练集中类别 y 的相对频率。各种各样的的朴素贝叶斯分类器的差异大部分来自于处理 \( P(x_i \mid y)\) 分布时的所做的假设不同。尽管其假设过于简单，在很多实际情况下，朴素贝叶斯工作得很好，特别是文档分类和垃圾邮件过滤。相比于其他更复杂的方法，朴素贝叶斯学习器和分类器非常快。 朴素贝叶斯算法思想假设有一个数据集，它由两类数据组成，数据分布如下图所示： 我们现在用\(p_1(x,y)\) 表示数据点 (x,y) 属于类别 1（图中用圆点表示的类别）的概率，用 \(p_2(x,y)\) 表示数据点 (x,y) 属于类别 2（图中三角形表示的类别）的概率，那么对于一个新数据点 (x,y)，可以用下面的规则来判断它的类别： 如果\( p_1(x,y)&gt;p_2(x,y)\)，那么类别为1 如果 \( p_1(x,y)&lt;p_2(x,y)\)，那么类别为2 也就是说，我们会选择高概率对应的类别。这就是贝叶斯决策理论的核心思想，即选择具有最高概率的决策。 朴素贝叶斯工作原理提取所有文档中的词条并进行去重 获取文档的所有类别 计算每个类别中的文档数目 对每篇训练文档: 对每个类别: 如果词条出现在文档中--&gt;增加该词条的计数值（for循环或者矩阵相加） 增加所有词条的计数值（此类别下词条总数） 对每个类别: 对每个词条: 将该词条的数目除以总词条数目得到的条件概率（P(词条|类别)） 返回该文档属于每个类别的条件概率（P(类别|文档的所有词条)） 朴素贝叶斯算法流程收集数据: 可以使用任何方法。 准备数据: 需要数值型或者布尔型数据。 分析数据: 有大量特征时，绘制特征作用不大，此时使用直方图效果更好。 训练算法: 计算不同的独立特征的条件概率。 测试算法: 计算错误率。 使用算法: 一个常见的朴素贝叶斯应用是文档分类。可以在任意的分类场景中使用朴素贝叶斯分类器，不一定非要是文本。 朴素贝叶斯优缺点优点: 在数据较少的情况下仍然有效，可以处理多类别问题。 缺点: 对于输入数据的准备方式较为敏感。 适用数据类型: 标称型数据。 案例描述：形式化理解朴素贝叶斯性别分类问题描述通过一些测量的特征，包括身高、体重、脚的尺寸，判定一个人是男性还是女性。 训练数据 性别 身高(英尺) 体重(磅) 脚的尺寸(英寸) 男 6 180 12 男 5.92 190 11 男 5.58 170 12 男 5.92 165 10 女 5 100 6 女 5.5 150 8 女 5.42 130 7 女 5.75 150 9 假设训练集样本的特征满足高斯分布，得到下表： 性别 均值(身高) 方差(身高) 均值(体重) 方差(体重) 均值(脚的尺寸) 方差(脚的尺寸) 男性 5.855 3.5033e-02 176.25 1.2292e+02 11.25 9.1667e-01 女性 5.4175 9.7225e-02 132.5 5.5833e+02 7.5 1.6667e+00 我们认为两种类别是等概率的，也就是P(male)= P(female) = 0.5。在没有做辨识的情况下就做这样的假设并不是一个好的点子。但我们通过数据集中两类样本出现的频率来确定P(C)，我们得到的结果也是一样的。 测试数据以下给出一个待分类是男性还是女性的样本。 性别 身高(英尺) 体重(磅) 脚的尺寸(英尺) sample 6 130 8 我们希望得到的是男性还是女性哪类的后验概率大。男性的后验概率通过下面式子来求取 女性的后验概率通过下面式子来求取 证据因子（通常是常数）用来对各类的后验概率之和进行归一化. 证据因子是一个常数（在正态分布中通常是正数），所以可以忽略。接下来我们来判定这样样本的性别。 其中 是训练集样本的正态分布参数. 注意，这里的值大于1也是允许的 – 这里是概率密度而不是概率，因为身高是一个连续的变量. 集样本的正态分布参数. 注意，这里的值大于1也是允许的 – 这里是概率密度而不是概率，因为身高是一个连续的变量. 模型预测结果由于女性后验概率的分子比较大，所以我们预计这个样本是女性。 参考文献 scikit中文社区：http://sklearn.apachecn.org/cn/0.19.0/ 中文维基百科：https://zh.wikipedia.org/wiki/ 文本分类特征选择：https://www.cnblogs.com/june0507/p/7601001.html GitHub：https://github.com/BaiNingchao/MachineLearning-1 图书：《机器学习实战》 图书：《自然语言处理理论与实战》 完整代码下载 源码请进【机器学习和自然语言QQ群：436303759】文件下载： 作者声明 本文版权归作者【白宁超】所有，转载请联系作者：1938036263@qq.com，但未经作者同意禁止转载，转载后需在文章页面明显位置给出原文连接，否则保留追究法律责任的权利。]]></content>
      <categories>
        <category>机器学习</category>
        <category>朴素贝叶斯</category>
      </categories>
      <tags>
        <tag>文本分类</tag>
        <tag>Python</tag>
        <tag>Naive Bayes</tag>
        <tag>ML</tag>
        <tag>自然语言处理</tag>
        <tag>理论学习</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[Hexo-GitHub搭建个人博客配置教程]]></title>
    <url>%2F2018%2F09%2F19%2FHexo-GitHub%E6%90%AD%E5%BB%BA%E4%B8%AA%E4%BA%BA%E5%8D%9A%E5%AE%A2%E9%85%8D%E7%BD%AE%E6%95%99%E7%A8%8B%2F</url>
    <content type="text"><![CDATA[摘要：创建一个自定义个人博客，即可以便于知识的记录，又可以分享知识。然而，诸多技术社区虽有便捷的优点，同时也存在限制性和专业化的问题。自己从头写网站成本较高，故而作者采用github建站，既可以支持markdown文档编写，又可以与github账号打通，便于资料上传保存。仅仅建站完成还是不够美观和功能扩展。这里github结合诸多插件可以实现，本文重点介绍Hexo的配置操作，具体以下实现可以根据需要选择。（本文原创，转载注明出处.） 前提准备 安装Node.js Node.js下载地址：https://nodejs.org/en/download/ 安装Git软件 Git软件下载地址：https://git-scm.com/download 安装hexo框架 初始化hexo Hexo官方网站：https://hexo.io/zh-cn/在电脑合适的位置新建一个文件夹存放博客。本文中取名为MyBlog文件夹。控制台命令行使用cd命令进入到Blog文件夹，输入以下命令进行初始化： hexo init # 初始化 安装依赖包: hexo install # 安装依赖包 测试本地运行 hexo g # 等同于hexo generate，生成静态文件 hexo s # 等同于hexo server，在本地服务器运行 部署到Coding以及GitHub上 注册、登录、创建仓库、打开_config.yml到最后deploy选项： # Deployment ## Docs: https://hexo.io/docs/deployment.html deploy: type: git repo: github: https://github.com/DimpleFeng/dimplefeng.github.io.git,master coding: https://git.coding.net/DimpleFeng/test.git,master 部署部署之前需要安装git部署插件，否则会提示Deployer not found错误。 npm install hexo-deployer-git --save 安装完毕后控制台输入: hexo g -d hexo s 随后访问你的以下网址（注意替换）：yourName.github.io 写一篇新的博文 两种方法： 在博文根目录的Source文件夹的post文件夹下直接新建一个md文件 在博文根目录打来PowerShell，然后输入hexo new ‘你的标题’回车在你的post文件夹下就新建了一个博文，打开编辑即可。然后使用hexo g -d部署到线上。 $ hexo clean $ hexo g -d 修改主题 主题官网：https://hexo.io/themes/ Administrator@PC-20160724ASED MINGW64 /e/MyBlog $ git clone https://github.com/theme-next/hexo-theme-next themes/next 修改站点配置文件_config.yml # Extensions ## Plugins: https://hexo.io/plugins/ ## Themes: https://hexo.io/themes/ theme: next next四种主题选择，打开 主题配置文件 找到Scheme Settings # Schemes # scheme: Muse # scheme: Mist # scheme: Pisces scheme: Gemini 设置语言 修改站点配置文件_config.yml:language: zh-Hans 目录 新建一个页面，命名为tags。命令如下：hexo new page “tags”。在myBlog/source下会新生成一个新的文件夹tags，在该文件夹下会有一个index.md文件 --- title: 标签测试文章 date: 2018-09-17 20:31:20 type: tags tags: - Test - Tag --- 新建一个页面，命名为categories。命令如下：hexo new page “categories”。在myBlog/source下会新生成一个新的文件夹categories，在该文件夹下会有一个index.md文件 --- title: categories date: 2018-09-17 20:31:40 type: categories --- 新建一个页面，命名为comments。命令如下：hexo new page “comments”。在myBlog/source下会新生成一个新的文件夹comments，在该文件夹下会有一个index.md文件 --- title: comments date: 2018年9月18日16:16:39 type: &quot;comments&quot; comments: true --- 在菜单中添加链接。编辑主题的 themes/next/_config.yml ，添加tags到menu中，如下: menu: home: / archives: /archives/ categories: /categories/ tags: /tags/ 高级设置 设置现在更多 &lt;!--more--&gt; 头像设置 打开 主题配置文件_config.yml 找到Sidebar Avatar字段 # Sidebar Avatar url: ../images/header.jpg 这是头像的路径，只需把你的头像命名为header.jpg（随便命名）放入themes/next/source/images中，将avatar的路径名改成你的头像名就OK啦！ 设置RSS 1、先安装 hexo-generator-feed 插件 $ npm install hexo-generator-feed --save 2、打开 站点配置文件 找到Extensions在下面添加 # RSS订阅 feed: type: atom path: atom.xml limit: 20 hub: content: content_limit: 140 content_limit_delim: &#39; &#39; 3、打开 主题配置文件 找到rss，设置为 rss: /atom.xml 添加搜索功能 1、安装 hexo-generator-searchdb 插件 $ npm install hexo-generator-searchdb --save 2、打开 站点配置文件 找到Extensions在下面添加 # 搜索 search: path: search.xml field: post format: html limit: 10000 3、打开 主题配置文件 找到Local search，将enable设置为true 修改文章内链接文本样式 打开文件 themes/next/source/css/_common/components/post/post.styl，在末尾添加 .post-body p a { color: #0593d3; border-bottom: none; border-bottom: 1px solid #0593d3; &amp;:hover { color: #fc6423; border-bottom: none; border-bottom: 1px solid #fc6423; } } 其中选择 .post-body 是为了不影响标题，选择 p 是为了不影响首页“阅读全文”的显示样式,颜色可以自己定义。 设置网站缩略图标 把logo图片（png或jpg格式，不是favicon.ico）放在themes/next/source/images里，然后打开 主题配置文件 找到favicon，将small、medium、apple_touch_icon三个字段的值都设置成/images/图片名.jpg就可以了，其他字段都注释掉。 favicon: small: /images/logo.png medium: /images/logo.png apple_touch_icon: /images/logo.png 添加评论 添加站点访问计数 去掉文章目录标题的自动编号 我们自己写文章的时候一般都会自己带上标题编号，但是默认的主题会给我们带上编号，很是别扭，如何去掉呢？打开主题配置文件，找到 # Table Of Contents in the Sidebar toc: enable: true # Automatically add list number to toc. number: false # If true, all words will placed on next lines if header width longer then sidebar width. wrap: false 设置Fork me on Github 第一步选取适合自己的样式代码:https://github.com/blog/273-github-ribbons &lt;a href=&quot;https://github.com/you&quot;&gt;&lt;img style=&quot;position: absolute; top: 0; right: 0; border: 0;&quot; src=&quot;https://s3.amazonaws.com/github/ribbons/forkme_right_red_aa0000.png&quot; alt=&quot;Fork me on GitHub&quot;&gt;&lt;/a&gt; 在主题中进行配置/root/blog/themes/next/layout/_layout.swig文件中进行配置 /root表示的是根目录. next表示的是当前你使用的主题的样式. 具体的配置直接图片中展示: 注意的是: href 后面是自己的github的地址,记得修改哦! 文章的输入密码访问 第一步修改主题下面的文件,主要的是修改的主题下面的文件:themes-&gt;next-&gt;layout-&gt;_partials-&gt;head-&gt;head.swig &lt;script&gt; (function(){ if(&#39;{{ page.password }}&#39;){ if (prompt(&#39;请输入文章密码&#39;) !== &#39;{{ page.password }}&#39;){ alert(&#39;密码错误！&#39;); history.back(); } } })(); &lt;/script&gt; 放置位置 实现点击的桃心效果 添加打js代码地址: http://7u2ss1.com1.z0.glb.clouddn.com/love.js新建js代码放置,在/theme/next/source/js/src这个路劲下面,新建love.js,将上面的代码复制进去.配置 _layout.swig文件,在 themes/next/layout/_layout.swig 文件, 最后部分添加: &lt;!-- 页面点击小红心 --&gt; &lt;script type=&quot;text/javascript&quot; src=&quot;/js/src/love.js&quot;&gt;&lt;/script&gt; 在_layout.swig位置的设置展示: Hexo之站点地图的搭建sitemap.xml 创建sitemap站点：hexo new page sitemap npm install hexo-generator-sitemap --save npm install hexo-generator-baidu-sitemap --save 如上设置,出现,sitemap.xml和baidusitemap.xml 表示站点文件生成. 之后就是百度站点地图的验证百度站长平台进行验证: https://ziyuan.baidu.com/dashboard/index 第一次会输入一些信息,姓名,职位等信息. 后面就是添加站点:网站的根目录在那里呢？ 在你的博客的本地根目录的Source文件夹内。 具体参照：https://blog.csdn.net/qq_32454537/article/details/79482914 以下功能配置及其参照文章 设置代码高亮主题 设置字体 侧边栏社交链接 开启打赏功能 友情链接 订阅微信公众号具体配置参照文章：http://theme-next.iissnan.com/theme-settings.html 修改文章后面标签的图标在主题下: themes/next/layout/_macro/post.swig文件:修改模板 /themes/next/layout/_macro/post.swig，搜索 rel=”tag”&gt;#，将 # 换成Hexo的个性化配置(一) https://blog.csdn.net/kunkun5love/article/details/79130956 配置文章分享功能https://blog.csdn.net/lanuage/article/details/78991798 配置访问统计 主题中查找 busuanzi_count 如果你使用的是NexT主题（其他主题类似），打开/theme/next/layout/_partial/footer.swig文件，拷贝下面的代码至文件的开头。 fatal: bad config file line 1 in .git/config 删除hexo路径下的.deploy_git后，问题解决了。http://ishareflower.com/2015-11-18/Git-deployment.html 配置ssh https://blog.csdn.net/Greenovia/article/details/60576985 代码高亮显示 https://blog.csdn.net/u011240016/article/details/79422448 分享功能https://blog.csdn.net/cl534854121/article/details/76121105 作者声明 本文版权归作者【白宁超】所有，转载请联系作者：1938036263@qq.com，但未经作者同意禁止转载，转载后需在文章页面明显位置给出原文连接，否则保留追究法律责任的权利。]]></content>
      <categories>
        <category>工具</category>
      </categories>
      <tags>
        <tag>hexo</tag>
      </tags>
  </entry>
</search>
